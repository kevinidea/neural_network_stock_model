Current working directory
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml
source kevin/venv/bin/activate
which python3
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/bin/python3
2024-08-13 14:36:44,481	PANIC scripts.py:900 -- `--address` is a required flag unless starting a head node with `--head`.
Error: `{}` is a required flag unless starting a head node with `{}`.
Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)
Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)
INFO:preprocess_data_nn.py:

Loading and preprocessing data...

DEBUG:preprocess_data_nn.py:          date   permno
626    1980-01  10006.0
5399   1980-01  10057.0
11398  1980-01  10137.0
12828  1980-01  10145.0
13984  1980-01  10153.0
DEBUG:preprocess_data_nn.py:--------------------------------------------------
INFO:main_restricted.py:preprocessed df: (667724, 161)
INFO:preprocess_data_nn.py:

Applying secondary data preprocessing..

INFO:main_restricted.py:secondary preprocessed df: (667724, 161)
INFO:main_restricted.py:df sample:     permno       pdate        ym  gvkey  sic2    absacc       acc    aeavol  ...      roaa      roea   roavola       ret        mve_m      retq  pyear     date
0  10006.0  1980-01-01  198001.0   1010    37  0.083420  0.083420  1.001090  ...  0.048684  0.141715  0.004512  0.211679   303420.750 -0.055806   1980  1980-01
1  10057.0  1980-01-01  198001.0   1098    36  0.088951  0.088951 -0.613146  ...  0.092434  0.174252  0.035698  0.282297   111423.125 -0.069431   1980  1980-01
2  10137.0  1980-01-01  198001.0   1279    49  0.041008  0.041008 -0.491307  ...  0.034895  0.097554  0.006254 -0.032258   617349.500 -0.108065   1980  1980-01
3  10145.0  1980-01-01  198001.0   1300    99  0.050486  0.050486 -0.256932  ...  0.049028  0.122729  0.004320  0.150127  1415193.000 -0.085950   1980  1980-01
4  10153.0  1980-01-01  198001.0   1308    13       NaN       NaN  1.631801  ...  0.049860  0.109950  0.009149 -0.122744   429488.500 -0.285199   1980  1980-01

[5 rows x 161 columns]
INFO:main_restricted.py:Train year start: 1980
INFO:main_restricted.py:Prediction data years: [1989, 1994, 1996, 2000, 2009, 2013]
INFO:main_restricted.py:

Loop through all the prediction years and build optimized model for each year

INFO:main_restricted.py:

Transform data

INFO:transform_data_nn.py:Train data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987]
INFO:transform_data_nn.py:Train_data: (95838, 161)

INFO:transform_data_nn.py:Test data years: [1988]
INFO:transform_data_nn.py:Test_data: (16210, 161)

INFO:transform_data_nn.py:Retrain data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988]
INFO:transform_data_nn.py:Retrain_data: (112048, 161)

INFO:transform_data_nn.py:Prediction data years: [1989]
INFO:transform_data_nn.py:Prediction_data: (16366, 161)

INFO:main_restricted.py:

Generate X and y with train_data and test_data

/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide
  T = new_sum / new_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide
  new_unnormalized_variance -= correction**2 / new_sample_count
INFO:main_restricted.py:
            x_train_tf: torch.Size([95838, 138])
            y_train_tf: torch.Size([95838])

            x_test_tf: torch.Size([16210, 138])
            y_test_tf: torch.Size([16210])

        
INFO:main_restricted.py:

Generate X and y with retrain_data and prediction_data

/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide
  T = new_sum / new_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide
  new_unnormalized_variance -= correction**2 / new_sample_count
INFO:main_restricted.py:
            x_retrain_tf: torch.Size([112048, 138])
            y_retrain_tf: torch.Size([112048])

            x_prediction_tf: torch.Size([16366, 138])
            y_prediction_tf: torch.Size([16366])

        
INFO:main_restricted.py:

Create dataset

INFO:main_restricted.py:Create train_dataset
INFO:main_restricted.py:Create test_dataset
INFO:main_restricted.py:Create retrain_dataset
INFO:main_restricted.py:Create prediction_dataset
INFO:main_restricted.py:

Hyperparameters tuning with Ray Tune

INFO:main_restricted.py:Training data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987]
INFO:main_restricted.py:Testing data year: 1988
INFO:main_restricted.py:

            ray_results_path: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
            num_samples: 150
            max_num_epochs: 100
            num_cpus: 24
            cpus_per_trial: 1
            num_gpus: 0
            gpus_per_trial: 0
            continuous_dim: 137
            num_embeddings: 5713
            device: cpu
            
2024-08-13 14:49:47,713	INFO worker.py:1753 -- Started a local Ray instance.
2024-08-13 14:49:47,890	INFO packaging.py:530 -- Creating a file package for local directory '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src'.
2024-08-13 14:49:47,941	INFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_35fa27def23cedb5.zip' (5.11MiB) to Ray cluster...
2024-08-13 14:49:47,955	INFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_35fa27def23cedb5.zip'.
2024-08-13 14:49:50,089	WARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
2024-08-13 15:43:30,334	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-13_14-49-50' in 0.6760s.
INFO:model_data_nn.py:Best trial config: {'continuous_dim': 137, 'hidden_dim': 45, 'num_layers': 1, 'num_embeddings': 5713, 'embedding_dim': 2, 'dropout_rate': 0.33, 'lr': 1.9413068598102374e-06, 'weight_decay': 0.00012163913593146424, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 8}
INFO:model_data_nn.py:Best trial training loss: 0.05182269093907972
INFO:model_data_nn.py:Best trial testing loss: 0.05974308100504204
INFO:main_restricted.py:Ray Tune results have been saved to: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
INFO:main_restricted.py:Best trial directory: /tmp/ray/session_2024-08-13_14-49-45_079161_1685331/artifacts/2024-08-13_14-49-50/train_fnn_2024-08-13_14-49-50/driver_artifacts/train_fnn_f70ce_00132_132_batch_size=8,dropout_rate=0.3300,embedding_dim=2,hidden_dim=45,lr=0.0000,num_layers=1,weight_decay=0.000_2024-08-13_14-49-50
INFO:main_restricted.py:

Retrain a new model with data in years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988]

            Using the optimized hyperparameters: {'continuous_dim': 137, 'hidden_dim': 45, 'num_layers': 1, 'num_embeddings': 6323, 'embedding_dim': 2, 'dropout_rate': 0.33, 'lr': 1.9413068598102374e-06, 'weight_decay': 0.00012163913593146424, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 8}

/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
INFO:model_data_nn.py:Epoch 1/100, metrics: {'avg_train_loss': 0.061048198041973104, 'avg_test_loss': 0.0645964423420758}
INFO:model_data_nn.py:Epoch 2/100, metrics: {'avg_train_loss': 0.05972233945757674, 'avg_test_loss': 0.06396193066539055}
INFO:model_data_nn.py:Epoch 3/100, metrics: {'avg_train_loss': 0.05895491250054295, 'avg_test_loss': 0.06364017756182867}
INFO:model_data_nn.py:Epoch 4/100, metrics: {'avg_train_loss': 0.05844832452838754, 'avg_test_loss': 0.06332747463511534}
INFO:model_data_nn.py:Epoch 5/100, metrics: {'avg_train_loss': 0.05812885374328573, 'avg_test_loss': 0.06328344095852463}
INFO:model_data_nn.py:Epoch 6/100, metrics: {'avg_train_loss': 0.05783949904051051, 'avg_test_loss': 0.06335737809886152}
INFO:model_data_nn.py:Epoch 7/100, metrics: {'avg_train_loss': 0.05773584799151149, 'avg_test_loss': 0.06327546099808526}
INFO:model_data_nn.py:Epoch 8/100, metrics: {'avg_train_loss': 0.057551586896649694, 'avg_test_loss': 0.06317977155756774}
INFO:model_data_nn.py:Epoch 9/100, metrics: {'avg_train_loss': 0.05732302003136709, 'avg_test_loss': 0.06313383717791797}
INFO:model_data_nn.py:Epoch 10/100, metrics: {'avg_train_loss': 0.05720646921380859, 'avg_test_loss': 0.06337093373563484}
INFO:model_data_nn.py:Epoch 11/100, metrics: {'avg_train_loss': 0.05700240155159769, 'avg_test_loss': 0.06351072326409954}
INFO:model_data_nn.py:Epoch 12/100, metrics: {'avg_train_loss': 0.05694061458720664, 'avg_test_loss': 0.06317377908479418}
INFO:model_data_nn.py:Epoch 13/100, metrics: {'avg_train_loss': 0.05683389408735164, 'avg_test_loss': 0.06339083426110337}
INFO:model_data_nn.py:Epoch 14/100, metrics: {'avg_train_loss': 0.05665610015588994, 'avg_test_loss': 0.06321310152810428}
INFO:model_data_nn.py:Epoch 15/100, metrics: {'avg_train_loss': 0.05657971945596125, 'avg_test_loss': 0.06375592514642224}
INFO:model_data_nn.py:Epoch 16/100, metrics: {'avg_train_loss': 0.05647476306110486, 'avg_test_loss': 0.06340131791864312}
INFO:model_data_nn.py:Epoch 17/100, metrics: {'avg_train_loss': 0.05641783105361277, 'avg_test_loss': 0.06329133749560782}
INFO:model_data_nn.py:Epoch 18/100, metrics: {'avg_train_loss': 0.05624983472463897, 'avg_test_loss': 0.06427431715978264}
INFO:model_data_nn.py:Epoch 19/100, metrics: {'avg_train_loss': 0.05617426496861399, 'avg_test_loss': 0.063329719333274}
INFO:model_data_nn.py:Epoch 20/100, metrics: {'avg_train_loss': 0.05605165979337356, 'avg_test_loss': 0.06383339447043981}
INFO:model_data_nn.py:Epoch 21/100, metrics: {'avg_train_loss': 0.05596320106330131, 'avg_test_loss': 0.06338942946649029}
INFO:model_data_nn.py:Epoch 22/100, metrics: {'avg_train_loss': 0.05584798038088648, 'avg_test_loss': 0.06290105935142905}
INFO:model_data_nn.py:Epoch 23/100, metrics: {'avg_train_loss': 0.0557712390720307, 'avg_test_loss': 0.06337501647923587}
INFO:model_data_nn.py:Epoch 24/100, metrics: {'avg_train_loss': 0.055701045700085994, 'avg_test_loss': 0.06383843140443105}
INFO:model_data_nn.py:Epoch 25/100, metrics: {'avg_train_loss': 0.05565262693166487, 'avg_test_loss': 0.0635107686742685}
INFO:model_data_nn.py:Epoch 26/100, metrics: {'avg_train_loss': 0.05563762367102541, 'avg_test_loss': 0.06356823786306591}
INFO:model_data_nn.py:Epoch 27/100, metrics: {'avg_train_loss': 0.05549325251819124, 'avg_test_loss': 0.06377338820691507}
INFO:model_data_nn.py:Epoch 28/100, metrics: {'avg_train_loss': 0.0555181450272734, 'avg_test_loss': 0.06409428408949791}
INFO:model_data_nn.py:Epoch 29/100, metrics: {'avg_train_loss': 0.05528320435512179, 'avg_test_loss': 0.0636506363042136}
INFO:model_data_nn.py:Epoch 30/100, metrics: {'avg_train_loss': 0.055261838432007375, 'avg_test_loss': 0.0633677652075874}
INFO:model_data_nn.py:Epoch 31/100, metrics: {'avg_train_loss': 0.05523809136358987, 'avg_test_loss': 0.06421071600284108}
INFO:model_data_nn.py:Epoch 32/100, metrics: {'avg_train_loss': 0.05508129791617681, 'avg_test_loss': 0.06427071268321129}
INFO:model_data_nn.py:Epoch 33/100, metrics: {'avg_train_loss': 0.055070066496753924, 'avg_test_loss': 0.06450073913200408}
INFO:model_data_nn.py:Epoch 34/100, metrics: {'avg_train_loss': 0.054995686419830964, 'avg_test_loss': 0.0635404846341261}
INFO:model_data_nn.py:Epoch 35/100, metrics: {'avg_train_loss': 0.05504338918938839, 'avg_test_loss': 0.06369525033212244}
INFO:model_data_nn.py:Epoch 36/100, metrics: {'avg_train_loss': 0.05496160137608986, 'avg_test_loss': 0.06314851414368562}
INFO:model_data_nn.py:Epoch 37/100, metrics: {'avg_train_loss': 0.05480060987444312, 'avg_test_loss': 0.06358855134292705}
INFO:model_data_nn.py:Epoch 38/100, metrics: {'avg_train_loss': 0.054828358458141754, 'avg_test_loss': 0.0637550140366428}
INFO:model_data_nn.py:Epoch 39/100, metrics: {'avg_train_loss': 0.05481507147318365, 'avg_test_loss': 0.06527255647458438}
INFO:model_data_nn.py:Epoch 40/100, metrics: {'avg_train_loss': 0.05468513429099788, 'avg_test_loss': 0.06525346601517545}
INFO:model_data_nn.py:Epoch 41/100, metrics: {'avg_train_loss': 0.05467907550871085, 'avg_test_loss': 0.06497935910118818}
INFO:model_data_nn.py:Epoch 42/100, metrics: {'avg_train_loss': 0.05465152945480727, 'avg_test_loss': 0.06427396958266436}
INFO:model_data_nn.py:Epoch 43/100, metrics: {'avg_train_loss': 0.0545716456313858, 'avg_test_loss': 0.06472292160278482}
INFO:model_data_nn.py:Epoch 44/100, metrics: {'avg_train_loss': 0.05453077096898467, 'avg_test_loss': 0.0634700969233244}
INFO:model_data_nn.py:Epoch 45/100, metrics: {'avg_train_loss': 0.05448659682129997, 'avg_test_loss': 0.0640922619604787}
INFO:model_data_nn.py:Epoch 46/100, metrics: {'avg_train_loss': 0.05434634926525165, 'avg_test_loss': 0.0649095406242121}
INFO:model_data_nn.py:Epoch 47/100, metrics: {'avg_train_loss': 0.0544691788867224, 'avg_test_loss': 0.06471948074140492}
INFO:model_data_nn.py:Epoch 48/100, metrics: {'avg_train_loss': 0.05435969682761151, 'avg_test_loss': 0.06442411410640962}
INFO:model_data_nn.py:Epoch 49/100, metrics: {'avg_train_loss': 0.05416708652446723, 'avg_test_loss': 0.06454514438126652}
INFO:model_data_nn.py:Epoch 50/100, metrics: {'avg_train_loss': 0.05436229021508551, 'avg_test_loss': 0.06559454754915794}
INFO:model_data_nn.py:Epoch 51/100, metrics: {'avg_train_loss': 0.05415215724317982, 'avg_test_loss': 0.06415113677085903}
INFO:model_data_nn.py:Epoch 52/100, metrics: {'avg_train_loss': 0.05430257334873681, 'avg_test_loss': 0.06478196346858299}
INFO:model_data_nn.py:Epoch 53/100, metrics: {'avg_train_loss': 0.054168840810881566, 'avg_test_loss': 0.06442563688436674}
INFO:model_data_nn.py:Epoch 54/100, metrics: {'avg_train_loss': 0.054101943317647824, 'avg_test_loss': 0.06425416083116073}
INFO:model_data_nn.py:Epoch 55/100, metrics: {'avg_train_loss': 0.054000549324249615, 'avg_test_loss': 0.06463708534059756}
INFO:model_data_nn.py:Epoch 56/100, metrics: {'avg_train_loss': 0.05399870019445711, 'avg_test_loss': 0.0653052608646864}
INFO:model_data_nn.py:Epoch 57/100, metrics: {'avg_train_loss': 0.05387346428741801, 'avg_test_loss': 0.06446470762432288}
INFO:model_data_nn.py:Epoch 58/100, metrics: {'avg_train_loss': 0.053876931073529616, 'avg_test_loss': 0.0650013289594147}
INFO:model_data_nn.py:Epoch 59/100, metrics: {'avg_train_loss': 0.05388940963333912, 'avg_test_loss': 0.0642312628266885}
INFO:model_data_nn.py:Epoch 60/100, metrics: {'avg_train_loss': 0.053802239815669034, 'avg_test_loss': 0.06379643661110687}
INFO:model_data_nn.py:Epoch 61/100, metrics: {'avg_train_loss': 0.05377195295276145, 'avg_test_loss': 0.06556726369587113}
INFO:model_data_nn.py:Epoch 62/100, metrics: {'avg_train_loss': 0.05380181306380301, 'avg_test_loss': 0.06386889316021435}
INFO:model_data_nn.py:Epoch 63/100, metrics: {'avg_train_loss': 0.053708220208040114, 'avg_test_loss': 0.06482144888002928}
INFO:model_data_nn.py:Epoch 64/100, metrics: {'avg_train_loss': 0.05374778556642553, 'avg_test_loss': 0.06378035463769634}
INFO:model_data_nn.py:Epoch 65/100, metrics: {'avg_train_loss': 0.05370211012283568, 'avg_test_loss': 0.06455023286471331}
INFO:model_data_nn.py:Epoch 66/100, metrics: {'avg_train_loss': 0.05357516328669211, 'avg_test_loss': 0.06517283408788788}
INFO:model_data_nn.py:Epoch 67/100, metrics: {'avg_train_loss': 0.05352677921868118, 'avg_test_loss': 0.06504264721300504}
INFO:model_data_nn.py:Epoch 68/100, metrics: {'avg_train_loss': 0.05370489550384486, 'avg_test_loss': 0.06454207599520381}
INFO:model_data_nn.py:Epoch 69/100, metrics: {'avg_train_loss': 0.05348524179676291, 'avg_test_loss': 0.06485168419173852}
INFO:model_data_nn.py:Epoch 70/100, metrics: {'avg_train_loss': 0.05351889523098095, 'avg_test_loss': 0.06566532665885483}
INFO:model_data_nn.py:Epoch 71/100, metrics: {'avg_train_loss': 0.053483605556773235, 'avg_test_loss': 0.06594848998195017}
INFO:model_data_nn.py:Epoch 72/100, metrics: {'avg_train_loss': 0.05335133710714891, 'avg_test_loss': 0.06528349370351526}
INFO:model_data_nn.py:Early stopping at epoch 72
INFO:main_restricted.py:Making prediction for data in year: 1989
INFO:main_restricted.py:Prediction data shape: (16366,)
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src/main_restricted.py:332: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  prediction_data['pred'] = predictions
INFO:main_restricted.py:Root Mean Squared Error for Prediction in 1989: 0.25549960470126165
INFO:main_restricted.py:Prediction Stats:                retq          pred
count  16366.000000  16366.000000
mean       0.032052     -0.031278
std        0.251212      0.048025
min       -0.945313     -0.331772
25%       -0.090909     -0.059610
50%        0.016642     -0.027191
75%        0.132440      0.001554
max        3.923078      0.142486
INFO:main_restricted.py:

Transform data

INFO:transform_data_nn.py:Train data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992]
INFO:transform_data_nn.py:Train_data: (177144, 161)

INFO:transform_data_nn.py:Test data years: [1993]
INFO:transform_data_nn.py:Test_data: (17602, 161)

INFO:transform_data_nn.py:Retrain data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993]
INFO:transform_data_nn.py:Retrain_data: (194746, 161)

INFO:transform_data_nn.py:Prediction data years: [1994]
INFO:transform_data_nn.py:Prediction_data: (19550, 161)

INFO:main_restricted.py:

Generate X and y with train_data and test_data

/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide
  T = new_sum / new_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide
  new_unnormalized_variance -= correction**2 / new_sample_count
INFO:main_restricted.py:
            x_train_tf: torch.Size([177144, 138])
            y_train_tf: torch.Size([177144])

            x_test_tf: torch.Size([17602, 138])
            y_test_tf: torch.Size([17602])

        
INFO:main_restricted.py:

Generate X and y with retrain_data and prediction_data

/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide
  T = new_sum / new_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide
  new_unnormalized_variance -= correction**2 / new_sample_count
INFO:main_restricted.py:
            x_retrain_tf: torch.Size([194746, 138])
            y_retrain_tf: torch.Size([194746])

            x_prediction_tf: torch.Size([19550, 138])
            y_prediction_tf: torch.Size([19550])

        
INFO:main_restricted.py:

Create dataset

INFO:main_restricted.py:Create train_dataset
INFO:main_restricted.py:Create test_dataset
INFO:main_restricted.py:Create retrain_dataset
INFO:main_restricted.py:Create prediction_dataset
INFO:main_restricted.py:

Hyperparameters tuning with Ray Tune

INFO:main_restricted.py:Training data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992]
INFO:main_restricted.py:Testing data year: 1993
INFO:main_restricted.py:

            ray_results_path: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
            num_samples: 150
            max_num_epochs: 100
            num_cpus: 24
            cpus_per_trial: 1
            num_gpus: 0
            gpus_per_trial: 0
            continuous_dim: 137
            num_embeddings: 7594
            device: cpu
            
2024-08-13 16:35:48,216	INFO worker.py:1753 -- Started a local Ray instance.
2024-08-13 16:35:48,270	INFO packaging.py:530 -- Creating a file package for local directory '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src'.
2024-08-13 16:35:48,329	INFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_35fa27def23cedb5.zip' (5.11MiB) to Ray cluster...
2024-08-13 16:35:48,343	INFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_35fa27def23cedb5.zip'.
2024-08-13 16:35:49,924	WARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
2024-08-13 17:05:10,231	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-13_16-35-49' in 0.3613s.
INFO:model_data_nn.py:Best trial config: {'continuous_dim': 137, 'hidden_dim': 5, 'num_layers': 5, 'num_embeddings': 7594, 'embedding_dim': 10, 'dropout_rate': 0.26, 'lr': 1.2203829203073189e-05, 'weight_decay': 2.060332487434688e-06, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 64}
INFO:model_data_nn.py:Best trial training loss: 0.0778246453037956
INFO:model_data_nn.py:Best trial testing loss: 0.09196809194037232
INFO:main_restricted.py:Ray Tune results have been saved to: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
INFO:main_restricted.py:Best trial directory: /tmp/ray/session_2024-08-13_16-35-45_712615_1685331/artifacts/2024-08-13_16-35-49/train_fnn_2024-08-13_16-35-49/driver_artifacts/train_fnn_c5d7d_00090_90_batch_size=64,dropout_rate=0.2600,embedding_dim=10,hidden_dim=5,lr=0.0000,num_layers=5,weight_decay=0.000_2024-08-13_16-35-50
INFO:main_restricted.py:

Retrain a new model with data in years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993]

            Using the optimized hyperparameters: {'continuous_dim': 137, 'hidden_dim': 5, 'num_layers': 5, 'num_embeddings': 8208, 'embedding_dim': 10, 'dropout_rate': 0.26, 'lr': 1.2203829203073189e-05, 'weight_decay': 2.060332487434688e-06, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 64}

INFO:model_data_nn.py:Epoch 1/100, metrics: {'avg_train_loss': 0.08185998561444896, 'avg_test_loss': 0.06221542231969876}
INFO:model_data_nn.py:Epoch 2/100, metrics: {'avg_train_loss': 0.08106615774169378, 'avg_test_loss': 0.0627096748083002}
INFO:model_data_nn.py:Epoch 3/100, metrics: {'avg_train_loss': 0.0810180904691516, 'avg_test_loss': 0.06289831167878279}
INFO:model_data_nn.py:Epoch 4/100, metrics: {'avg_train_loss': 0.08099965399460601, 'avg_test_loss': 0.06291382463673263}
INFO:model_data_nn.py:Epoch 5/100, metrics: {'avg_train_loss': 0.08095297457149435, 'avg_test_loss': 0.06301850403409476}
INFO:model_data_nn.py:Epoch 6/100, metrics: {'avg_train_loss': 0.08096024420548335, 'avg_test_loss': 0.06301263077610653}
INFO:model_data_nn.py:Epoch 7/100, metrics: {'avg_train_loss': 0.08093746633799764, 'avg_test_loss': 0.062997646401545}
INFO:model_data_nn.py:Epoch 8/100, metrics: {'avg_train_loss': 0.08093985479832048, 'avg_test_loss': 0.06297083454377024}
INFO:model_data_nn.py:Epoch 9/100, metrics: {'avg_train_loss': 0.08093161205837673, 'avg_test_loss': 0.0630009946157681}
INFO:model_data_nn.py:Epoch 10/100, metrics: {'avg_train_loss': 0.08092865867529218, 'avg_test_loss': 0.06295891213565578}
INFO:model_data_nn.py:Epoch 11/100, metrics: {'avg_train_loss': 0.08090161914183445, 'avg_test_loss': 0.06303558240224626}
INFO:model_data_nn.py:Epoch 12/100, metrics: {'avg_train_loss': 0.08089413780616174, 'avg_test_loss': 0.06292000531030247}
INFO:model_data_nn.py:Epoch 13/100, metrics: {'avg_train_loss': 0.0808688682564617, 'avg_test_loss': 0.06286733515645845}
INFO:model_data_nn.py:Epoch 14/100, metrics: {'avg_train_loss': 0.08087085302059467, 'avg_test_loss': 0.06289640465580852}
INFO:model_data_nn.py:Epoch 15/100, metrics: {'avg_train_loss': 0.08087793035698439, 'avg_test_loss': 0.06294463498797877}
INFO:model_data_nn.py:Epoch 16/100, metrics: {'avg_train_loss': 0.08086234504353307, 'avg_test_loss': 0.06284687511951607}
INFO:model_data_nn.py:Epoch 17/100, metrics: {'avg_train_loss': 0.08082813599785542, 'avg_test_loss': 0.06274382194832843}
INFO:model_data_nn.py:Epoch 18/100, metrics: {'avg_train_loss': 0.08078634584007845, 'avg_test_loss': 0.06267330588870286}
INFO:model_data_nn.py:Epoch 19/100, metrics: {'avg_train_loss': 0.08079666241741372, 'avg_test_loss': 0.06263810236713076}
INFO:model_data_nn.py:Epoch 20/100, metrics: {'avg_train_loss': 0.08075653384748864, 'avg_test_loss': 0.06265667445495043}
INFO:model_data_nn.py:Epoch 21/100, metrics: {'avg_train_loss': 0.08073412302274069, 'avg_test_loss': 0.06253890730014522}
INFO:model_data_nn.py:Epoch 22/100, metrics: {'avg_train_loss': 0.08075537442925884, 'avg_test_loss': 0.062467666151111614}
INFO:model_data_nn.py:Epoch 23/100, metrics: {'avg_train_loss': 0.080707725584458, 'avg_test_loss': 0.06246035681806164}
INFO:model_data_nn.py:Epoch 24/100, metrics: {'avg_train_loss': 0.08069711425240635, 'avg_test_loss': 0.06230469946171236}
INFO:model_data_nn.py:Epoch 25/100, metrics: {'avg_train_loss': 0.08065300899386935, 'avg_test_loss': 0.062256270173474466}
INFO:model_data_nn.py:Epoch 26/100, metrics: {'avg_train_loss': 0.08055845174061613, 'avg_test_loss': 0.06221806828322169}
INFO:model_data_nn.py:Epoch 27/100, metrics: {'avg_train_loss': 0.08057298206520327, 'avg_test_loss': 0.06207682667117493}
INFO:model_data_nn.py:Epoch 28/100, metrics: {'avg_train_loss': 0.08054765731213831, 'avg_test_loss': 0.06204492302635819}
INFO:model_data_nn.py:Epoch 29/100, metrics: {'avg_train_loss': 0.08051371416609727, 'avg_test_loss': 0.06196138995328273}
INFO:model_data_nn.py:Epoch 30/100, metrics: {'avg_train_loss': 0.0804823069857099, 'avg_test_loss': 0.06199832418263933}
INFO:model_data_nn.py:Epoch 31/100, metrics: {'avg_train_loss': 0.08045579193626518, 'avg_test_loss': 0.062031546790225836}
INFO:model_data_nn.py:Epoch 32/100, metrics: {'avg_train_loss': 0.0804351653437143, 'avg_test_loss': 0.06185643562401821}
INFO:model_data_nn.py:Epoch 33/100, metrics: {'avg_train_loss': 0.08038957218071942, 'avg_test_loss': 0.0618843265589984}
INFO:model_data_nn.py:Epoch 34/100, metrics: {'avg_train_loss': 0.08037201544045815, 'avg_test_loss': 0.06185718671436988}
INFO:model_data_nn.py:Epoch 35/100, metrics: {'avg_train_loss': 0.08038396398946496, 'avg_test_loss': 0.06188337559343066}
INFO:model_data_nn.py:Epoch 36/100, metrics: {'avg_train_loss': 0.08028704442945968, 'avg_test_loss': 0.0617020900689942}
INFO:model_data_nn.py:Epoch 37/100, metrics: {'avg_train_loss': 0.08026474301582649, 'avg_test_loss': 0.06175448456353027}
INFO:model_data_nn.py:Epoch 38/100, metrics: {'avg_train_loss': 0.08025736832669168, 'avg_test_loss': 0.06170295088192801}
INFO:model_data_nn.py:Epoch 39/100, metrics: {'avg_train_loss': 0.08023698773433471, 'avg_test_loss': 0.06171278475047229}
INFO:model_data_nn.py:Epoch 40/100, metrics: {'avg_train_loss': 0.08015152493113362, 'avg_test_loss': 0.06159650131122641}
INFO:model_data_nn.py:Epoch 41/100, metrics: {'avg_train_loss': 0.08013104661603573, 'avg_test_loss': 0.06153956357560127}
INFO:model_data_nn.py:Epoch 42/100, metrics: {'avg_train_loss': 0.08005620737944011, 'avg_test_loss': 0.061529425882850014}
INFO:model_data_nn.py:Epoch 43/100, metrics: {'avg_train_loss': 0.08009204850210652, 'avg_test_loss': 0.061683396592711895}
INFO:model_data_nn.py:Epoch 44/100, metrics: {'avg_train_loss': 0.0800189393077151, 'avg_test_loss': 0.061615115022469386}
INFO:model_data_nn.py:Epoch 45/100, metrics: {'avg_train_loss': 0.08001112978400897, 'avg_test_loss': 0.06161723278000269}
INFO:model_data_nn.py:Epoch 46/100, metrics: {'avg_train_loss': 0.07999748181806415, 'avg_test_loss': 0.06157492645377038}
INFO:model_data_nn.py:Epoch 47/100, metrics: {'avg_train_loss': 0.07993138774453046, 'avg_test_loss': 0.06146940819651278}
INFO:model_data_nn.py:Epoch 48/100, metrics: {'avg_train_loss': 0.07993914535725924, 'avg_test_loss': 0.06167389597938536}
INFO:model_data_nn.py:Epoch 49/100, metrics: {'avg_train_loss': 0.07987024912024057, 'avg_test_loss': 0.06133720127476099}
INFO:model_data_nn.py:Epoch 50/100, metrics: {'avg_train_loss': 0.07984407903916796, 'avg_test_loss': 0.06154923883017177}
INFO:model_data_nn.py:Epoch 51/100, metrics: {'avg_train_loss': 0.07978413117844992, 'avg_test_loss': 0.061368506179599006}
INFO:model_data_nn.py:Epoch 52/100, metrics: {'avg_train_loss': 0.07973333052619754, 'avg_test_loss': 0.06137507523294368}
INFO:model_data_nn.py:Epoch 53/100, metrics: {'avg_train_loss': 0.07977198208158714, 'avg_test_loss': 0.06129450923184943}
INFO:model_data_nn.py:Epoch 54/100, metrics: {'avg_train_loss': 0.07968445303301859, 'avg_test_loss': 0.06135702897411059}
INFO:model_data_nn.py:Epoch 55/100, metrics: {'avg_train_loss': 0.07956479866863433, 'avg_test_loss': 0.061300182380269165}
INFO:model_data_nn.py:Epoch 56/100, metrics: {'avg_train_loss': 0.07958179880129534, 'avg_test_loss': 0.06125074086309064}
INFO:model_data_nn.py:Epoch 57/100, metrics: {'avg_train_loss': 0.07960955181479316, 'avg_test_loss': 0.06128998822684771}
INFO:model_data_nn.py:Epoch 58/100, metrics: {'avg_train_loss': 0.07959368650389395, 'avg_test_loss': 0.0614146659260287}
INFO:model_data_nn.py:Epoch 59/100, metrics: {'avg_train_loss': 0.07948714084029296, 'avg_test_loss': 0.06128749272061719}
INFO:model_data_nn.py:Epoch 60/100, metrics: {'avg_train_loss': 0.07946802729668487, 'avg_test_loss': 0.06134020393483}
INFO:model_data_nn.py:Epoch 61/100, metrics: {'avg_train_loss': 0.07940086044669935, 'avg_test_loss': 0.06123851214724234}
INFO:model_data_nn.py:Epoch 62/100, metrics: {'avg_train_loss': 0.07941378827006565, 'avg_test_loss': 0.061355274837171916}
INFO:model_data_nn.py:Epoch 63/100, metrics: {'avg_train_loss': 0.07939501812792996, 'avg_test_loss': 0.06128642607626377}
INFO:model_data_nn.py:Epoch 64/100, metrics: {'avg_train_loss': 0.07936894789002566, 'avg_test_loss': 0.06128610051815319}
INFO:model_data_nn.py:Epoch 65/100, metrics: {'avg_train_loss': 0.07928691195773499, 'avg_test_loss': 0.06123341542053846}
INFO:model_data_nn.py:Epoch 66/100, metrics: {'avg_train_loss': 0.07928396748681353, 'avg_test_loss': 0.06109561466800621}
INFO:model_data_nn.py:Epoch 67/100, metrics: {'avg_train_loss': 0.079286526853095, 'avg_test_loss': 0.06116305540614073}
INFO:model_data_nn.py:Epoch 68/100, metrics: {'avg_train_loss': 0.07915003282948103, 'avg_test_loss': 0.0611129674932682}
INFO:model_data_nn.py:Epoch 69/100, metrics: {'avg_train_loss': 0.07914335387933419, 'avg_test_loss': 0.061159947464011266}
INFO:model_data_nn.py:Epoch 70/100, metrics: {'avg_train_loss': 0.07909413085384619, 'avg_test_loss': 0.06110894864157232}
INFO:model_data_nn.py:Epoch 71/100, metrics: {'avg_train_loss': 0.07916922748571337, 'avg_test_loss': 0.06119654122496547}
INFO:model_data_nn.py:Epoch 72/100, metrics: {'avg_train_loss': 0.07899693661430002, 'avg_test_loss': 0.061044430016278246}
INFO:model_data_nn.py:Epoch 73/100, metrics: {'avg_train_loss': 0.07905717808716513, 'avg_test_loss': 0.06128978955687261}
INFO:model_data_nn.py:Epoch 74/100, metrics: {'avg_train_loss': 0.07897965598209743, 'avg_test_loss': 0.06096857873528125}
INFO:model_data_nn.py:Epoch 75/100, metrics: {'avg_train_loss': 0.07898307910996057, 'avg_test_loss': 0.06108463827971052}
INFO:model_data_nn.py:Epoch 76/100, metrics: {'avg_train_loss': 0.07886038597717264, 'avg_test_loss': 0.06091493147796665}
INFO:model_data_nn.py:Epoch 77/100, metrics: {'avg_train_loss': 0.07894308652905141, 'avg_test_loss': 0.06097349330624626}
INFO:model_data_nn.py:Epoch 78/100, metrics: {'avg_train_loss': 0.07885971022702455, 'avg_test_loss': 0.06101383217093018}
INFO:model_data_nn.py:Epoch 79/100, metrics: {'avg_train_loss': 0.07884136249141659, 'avg_test_loss': 0.060902103069512284}
INFO:model_data_nn.py:Epoch 80/100, metrics: {'avg_train_loss': 0.07878755811200203, 'avg_test_loss': 0.060902052388520415}
INFO:model_data_nn.py:Epoch 81/100, metrics: {'avg_train_loss': 0.07873225224098432, 'avg_test_loss': 0.060944553455520495}
INFO:model_data_nn.py:Epoch 82/100, metrics: {'avg_train_loss': 0.07865442043778968, 'avg_test_loss': 0.060871192878051324}
INFO:model_data_nn.py:Epoch 83/100, metrics: {'avg_train_loss': 0.07864404077728002, 'avg_test_loss': 0.06096308551777422}
INFO:model_data_nn.py:Epoch 84/100, metrics: {'avg_train_loss': 0.07856988068731266, 'avg_test_loss': 0.06079328077193958}
INFO:model_data_nn.py:Epoch 85/100, metrics: {'avg_train_loss': 0.07856516219629005, 'avg_test_loss': 0.06087173495648636}
INFO:model_data_nn.py:Epoch 86/100, metrics: {'avg_train_loss': 0.07857013911677477, 'avg_test_loss': 0.06083040761158747}
INFO:model_data_nn.py:Epoch 87/100, metrics: {'avg_train_loss': 0.0784745823009029, 'avg_test_loss': 0.06081986100126813}
INFO:model_data_nn.py:Epoch 88/100, metrics: {'avg_train_loss': 0.07847762589552915, 'avg_test_loss': 0.060900536667117304}
INFO:model_data_nn.py:Epoch 89/100, metrics: {'avg_train_loss': 0.07838437433509471, 'avg_test_loss': 0.06078607683964804}
INFO:model_data_nn.py:Epoch 90/100, metrics: {'avg_train_loss': 0.07842785090680757, 'avg_test_loss': 0.06081482482879283}
INFO:model_data_nn.py:Epoch 91/100, metrics: {'avg_train_loss': 0.07831274937191718, 'avg_test_loss': 0.060771410523919885}
INFO:model_data_nn.py:Epoch 92/100, metrics: {'avg_train_loss': 0.07827407637284059, 'avg_test_loss': 0.06077910733281398}
INFO:model_data_nn.py:Epoch 93/100, metrics: {'avg_train_loss': 0.07825798494833167, 'avg_test_loss': 0.06072020165476145}
INFO:model_data_nn.py:Epoch 94/100, metrics: {'avg_train_loss': 0.07824676735345017, 'avg_test_loss': 0.06080980181657508}
INFO:model_data_nn.py:Epoch 95/100, metrics: {'avg_train_loss': 0.07808593493432571, 'avg_test_loss': 0.06081082122217791}
INFO:model_data_nn.py:Epoch 96/100, metrics: {'avg_train_loss': 0.07812492873637222, 'avg_test_loss': 0.06084547930220568}
INFO:model_data_nn.py:Epoch 97/100, metrics: {'avg_train_loss': 0.0780531324906658, 'avg_test_loss': 0.060667267038785166}
INFO:model_data_nn.py:Epoch 98/100, metrics: {'avg_train_loss': 0.07805973855150346, 'avg_test_loss': 0.06062732110396515}
INFO:model_data_nn.py:Epoch 99/100, metrics: {'avg_train_loss': 0.07795021840157496, 'avg_test_loss': 0.060713999715992825}
INFO:model_data_nn.py:Epoch 100/100, metrics: {'avg_train_loss': 0.07799905337966405, 'avg_test_loss': 0.060667783514980006}
INFO:main_restricted.py:Making prediction for data in year: 1994
INFO:main_restricted.py:Prediction data shape: (19550,)
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src/main_restricted.py:332: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  prediction_data['pred'] = predictions
INFO:main_restricted.py:Root Mean Squared Error for Prediction in 1994: 0.2459478326855948
INFO:main_restricted.py:Prediction Stats:                retq          pred
count  19550.000000  19550.000000
mean      -0.009021      0.006296
std        0.246687      0.028731
min       -0.941176     -1.480543
25%       -0.125000     -0.009396
50%       -0.014632      0.000368
75%        0.082227      0.018182
max        6.294121      0.080523
INFO:main_restricted.py:

Transform data

INFO:transform_data_nn.py:Train data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994]
INFO:transform_data_nn.py:Train_data: (214296, 161)

INFO:transform_data_nn.py:Test data years: [1995]
INFO:transform_data_nn.py:Test_data: (22259, 161)

INFO:transform_data_nn.py:Retrain data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995]
INFO:transform_data_nn.py:Retrain_data: (236555, 161)

INFO:transform_data_nn.py:Prediction data years: [1996]
INFO:transform_data_nn.py:Prediction_data: (22619, 161)

INFO:main_restricted.py:

Generate X and y with train_data and test_data

/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide
  T = new_sum / new_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide
  new_unnormalized_variance -= correction**2 / new_sample_count
INFO:main_restricted.py:
            x_train_tf: torch.Size([214296, 138])
            y_train_tf: torch.Size([214296])

            x_test_tf: torch.Size([22259, 138])
            y_test_tf: torch.Size([22259])

        
INFO:main_restricted.py:

Generate X and y with retrain_data and prediction_data

/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide
  T = new_sum / new_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide
  new_unnormalized_variance -= correction**2 / new_sample_count
INFO:main_restricted.py:
            x_retrain_tf: torch.Size([236555, 138])
            y_retrain_tf: torch.Size([236555])

            x_prediction_tf: torch.Size([22619, 138])
            y_prediction_tf: torch.Size([22619])

        
INFO:main_restricted.py:

Create dataset

INFO:main_restricted.py:Create train_dataset
INFO:main_restricted.py:Create test_dataset
INFO:main_restricted.py:Create retrain_dataset
INFO:main_restricted.py:Create prediction_dataset
INFO:main_restricted.py:

Hyperparameters tuning with Ray Tune

INFO:main_restricted.py:Training data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994]
INFO:main_restricted.py:Testing data year: 1995
INFO:main_restricted.py:

            ray_results_path: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
            num_samples: 150
            max_num_epochs: 100
            num_cpus: 24
            cpus_per_trial: 1
            num_gpus: 0
            gpus_per_trial: 0
            continuous_dim: 137
            num_embeddings: 9180
            device: cpu
            
2024-08-13 17:55:02,443	INFO worker.py:1753 -- Started a local Ray instance.
2024-08-13 17:55:02,498	INFO packaging.py:530 -- Creating a file package for local directory '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src'.
2024-08-13 17:55:02,557	INFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_35fa27def23cedb5.zip' (5.11MiB) to Ray cluster...
2024-08-13 17:55:02,570	INFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_35fa27def23cedb5.zip'.
2024-08-13 17:55:04,107	WARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
2024-08-13 19:30:44,916	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-13_17-55-04' in 0.3710s.
INFO:model_data_nn.py:Best trial config: {'continuous_dim': 137, 'hidden_dim': 5, 'num_layers': 4, 'num_embeddings': 9180, 'embedding_dim': 5, 'dropout_rate': 0.37, 'lr': 8.054990123563976e-06, 'weight_decay': 4.981629723388031e-06, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 64}
INFO:model_data_nn.py:Best trial training loss: 0.0777020034827559
INFO:model_data_nn.py:Best trial testing loss: 0.0840010241599989
INFO:main_restricted.py:Ray Tune results have been saved to: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
INFO:main_restricted.py:Best trial directory: /tmp/ray/session_2024-08-13_17-54-59_824337_1685331/artifacts/2024-08-13_17-55-04/train_fnn_2024-08-13_17-55-04/driver_artifacts/train_fnn_d78eb_00094_94_batch_size=64,dropout_rate=0.3700,embedding_dim=5,hidden_dim=5,lr=0.0000,num_layers=4,weight_decay=0.0000_2024-08-13_17-55-04
INFO:main_restricted.py:

Retrain a new model with data in years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995]

            Using the optimized hyperparameters: {'continuous_dim': 137, 'hidden_dim': 5, 'num_layers': 4, 'num_embeddings': 10061, 'embedding_dim': 5, 'dropout_rate': 0.37, 'lr': 8.054990123563976e-06, 'weight_decay': 4.981629723388031e-06, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 64}

INFO:model_data_nn.py:Epoch 1/100, metrics: {'avg_train_loss': 0.08022183704228257, 'avg_test_loss': 0.08446694134161045}
INFO:model_data_nn.py:Epoch 2/100, metrics: {'avg_train_loss': 0.08000690567668012, 'avg_test_loss': 0.08422822227417412}
INFO:model_data_nn.py:Epoch 3/100, metrics: {'avg_train_loss': 0.07987192456783863, 'avg_test_loss': 0.08410969644385037}
INFO:model_data_nn.py:Epoch 4/100, metrics: {'avg_train_loss': 0.0798134962570535, 'avg_test_loss': 0.08403197316305533}
INFO:model_data_nn.py:Epoch 5/100, metrics: {'avg_train_loss': 0.07977193470558482, 'avg_test_loss': 0.08394687182643572}
INFO:model_data_nn.py:Epoch 6/100, metrics: {'avg_train_loss': 0.07975846911363255, 'avg_test_loss': 0.0839127631500195}
INFO:model_data_nn.py:Epoch 7/100, metrics: {'avg_train_loss': 0.07973627032343202, 'avg_test_loss': 0.08388782467556286}
INFO:model_data_nn.py:Epoch 8/100, metrics: {'avg_train_loss': 0.07972356837516997, 'avg_test_loss': 0.08386462827418316}
INFO:model_data_nn.py:Epoch 9/100, metrics: {'avg_train_loss': 0.07971156590005375, 'avg_test_loss': 0.08385016218269781}
INFO:model_data_nn.py:Epoch 10/100, metrics: {'avg_train_loss': 0.0797137588195027, 'avg_test_loss': 0.08383424815558697}
INFO:model_data_nn.py:Epoch 11/100, metrics: {'avg_train_loss': 0.07969805449791639, 'avg_test_loss': 0.08382059061520938}
INFO:model_data_nn.py:Epoch 12/100, metrics: {'avg_train_loss': 0.07970882429705038, 'avg_test_loss': 0.08381779407187875}
INFO:model_data_nn.py:Epoch 13/100, metrics: {'avg_train_loss': 0.07969842084080739, 'avg_test_loss': 0.08381138344974083}
INFO:model_data_nn.py:Epoch 14/100, metrics: {'avg_train_loss': 0.07970497575870743, 'avg_test_loss': 0.08380148000489016}
INFO:model_data_nn.py:Epoch 15/100, metrics: {'avg_train_loss': 0.07969996486528418, 'avg_test_loss': 0.08379382946091772}
INFO:model_data_nn.py:Epoch 16/100, metrics: {'avg_train_loss': 0.07969313966830006, 'avg_test_loss': 0.08377684575195114}
INFO:model_data_nn.py:Epoch 17/100, metrics: {'avg_train_loss': 0.07968477833536312, 'avg_test_loss': 0.08378469695910643}
INFO:model_data_nn.py:Epoch 18/100, metrics: {'avg_train_loss': 0.07968136397023076, 'avg_test_loss': 0.0837734476452704}
INFO:model_data_nn.py:Epoch 19/100, metrics: {'avg_train_loss': 0.07966420490363234, 'avg_test_loss': 0.08376175195431221}
INFO:model_data_nn.py:Epoch 20/100, metrics: {'avg_train_loss': 0.07967605367020676, 'avg_test_loss': 0.08376620742255601}
INFO:model_data_nn.py:Epoch 21/100, metrics: {'avg_train_loss': 0.07966423500984407, 'avg_test_loss': 0.083751338373575}
INFO:model_data_nn.py:Epoch 22/100, metrics: {'avg_train_loss': 0.0796635115037378, 'avg_test_loss': 0.08374465138014764}
INFO:model_data_nn.py:Epoch 23/100, metrics: {'avg_train_loss': 0.07966852124258311, 'avg_test_loss': 0.08374960081767564}
INFO:model_data_nn.py:Epoch 24/100, metrics: {'avg_train_loss': 0.07965542404464894, 'avg_test_loss': 0.08373118626574676}
INFO:model_data_nn.py:Epoch 25/100, metrics: {'avg_train_loss': 0.07963272464739812, 'avg_test_loss': 0.08371860526323234}
INFO:model_data_nn.py:Epoch 26/100, metrics: {'avg_train_loss': 0.07964287481565045, 'avg_test_loss': 0.08371397092054456}
INFO:model_data_nn.py:Epoch 27/100, metrics: {'avg_train_loss': 0.07961338129523512, 'avg_test_loss': 0.0837040730820453}
INFO:model_data_nn.py:Epoch 28/100, metrics: {'avg_train_loss': 0.0796226746119454, 'avg_test_loss': 0.0836845937048185}
INFO:model_data_nn.py:Epoch 29/100, metrics: {'avg_train_loss': 0.07962253460412627, 'avg_test_loss': 0.08365782694943712}
INFO:model_data_nn.py:Epoch 30/100, metrics: {'avg_train_loss': 0.07961160104743958, 'avg_test_loss': 0.08366188629777671}
INFO:model_data_nn.py:Epoch 31/100, metrics: {'avg_train_loss': 0.07961742579987377, 'avg_test_loss': 0.08365710005742935}
INFO:model_data_nn.py:Epoch 32/100, metrics: {'avg_train_loss': 0.0796020367455939, 'avg_test_loss': 0.08365439406022598}
INFO:model_data_nn.py:Epoch 33/100, metrics: {'avg_train_loss': 0.07958593655446165, 'avg_test_loss': 0.08362165989754143}
INFO:model_data_nn.py:Epoch 34/100, metrics: {'avg_train_loss': 0.07958280747187893, 'avg_test_loss': 0.08362875208995268}
INFO:model_data_nn.py:Epoch 35/100, metrics: {'avg_train_loss': 0.07957684693987042, 'avg_test_loss': 0.08359180913322557}
INFO:model_data_nn.py:Epoch 36/100, metrics: {'avg_train_loss': 0.07955133248205212, 'avg_test_loss': 0.08359707187135089}
INFO:model_data_nn.py:Epoch 37/100, metrics: {'avg_train_loss': 0.07953766427502777, 'avg_test_loss': 0.08356840567831687}
INFO:model_data_nn.py:Epoch 38/100, metrics: {'avg_train_loss': 0.07951464137622836, 'avg_test_loss': 0.0835463610993393}
INFO:model_data_nn.py:Epoch 39/100, metrics: {'avg_train_loss': 0.07949190492312387, 'avg_test_loss': 0.08350678871380492}
INFO:model_data_nn.py:Epoch 40/100, metrics: {'avg_train_loss': 0.07947640005021368, 'avg_test_loss': 0.08346886010735301}
INFO:model_data_nn.py:Epoch 41/100, metrics: {'avg_train_loss': 0.07949392173390885, 'avg_test_loss': 0.08349587965367289}
INFO:model_data_nn.py:Epoch 42/100, metrics: {'avg_train_loss': 0.07946224106491838, 'avg_test_loss': 0.08349141361991648}
INFO:model_data_nn.py:Epoch 43/100, metrics: {'avg_train_loss': 0.0794537250901012, 'avg_test_loss': 0.08348343730772619}
INFO:model_data_nn.py:Epoch 44/100, metrics: {'avg_train_loss': 0.07945557665815617, 'avg_test_loss': 0.08344990426495587}
INFO:model_data_nn.py:Epoch 45/100, metrics: {'avg_train_loss': 0.07946970282894564, 'avg_test_loss': 0.08344687732189136}
INFO:model_data_nn.py:Epoch 46/100, metrics: {'avg_train_loss': 0.07945394757288424, 'avg_test_loss': 0.08343216879977344}
INFO:model_data_nn.py:Epoch 47/100, metrics: {'avg_train_loss': 0.07943709851927991, 'avg_test_loss': 0.08341411395145759}
INFO:model_data_nn.py:Epoch 48/100, metrics: {'avg_train_loss': 0.07943421939349617, 'avg_test_loss': 0.08341135490043773}
INFO:model_data_nn.py:Epoch 49/100, metrics: {'avg_train_loss': 0.07939839469333425, 'avg_test_loss': 0.08338459315683461}
INFO:model_data_nn.py:Epoch 50/100, metrics: {'avg_train_loss': 0.07936693181876432, 'avg_test_loss': 0.08336740105260311}
INFO:model_data_nn.py:Epoch 51/100, metrics: {'avg_train_loss': 0.07935630821661209, 'avg_test_loss': 0.08335516697564031}
INFO:model_data_nn.py:Epoch 52/100, metrics: {'avg_train_loss': 0.07934214370788853, 'avg_test_loss': 0.08332987938149922}
INFO:model_data_nn.py:Epoch 53/100, metrics: {'avg_train_loss': 0.07936111768481857, 'avg_test_loss': 0.08330572774044454}
INFO:model_data_nn.py:Epoch 54/100, metrics: {'avg_train_loss': 0.07935101646593333, 'avg_test_loss': 0.08333303994041379}
INFO:model_data_nn.py:Epoch 55/100, metrics: {'avg_train_loss': 0.0792969677761576, 'avg_test_loss': 0.08331801137218704}
INFO:model_data_nn.py:Epoch 56/100, metrics: {'avg_train_loss': 0.07926419242013052, 'avg_test_loss': 0.08326693047574685}
INFO:model_data_nn.py:Epoch 57/100, metrics: {'avg_train_loss': 0.07925989182446216, 'avg_test_loss': 0.083228396372817}
INFO:model_data_nn.py:Epoch 58/100, metrics: {'avg_train_loss': 0.07927385963564053, 'avg_test_loss': 0.08327694459013261}
INFO:model_data_nn.py:Epoch 59/100, metrics: {'avg_train_loss': 0.07927325226162919, 'avg_test_loss': 0.0832548936155472}
INFO:model_data_nn.py:Epoch 60/100, metrics: {'avg_train_loss': 0.07924682533598275, 'avg_test_loss': 0.0832283829186259}
INFO:model_data_nn.py:Epoch 61/100, metrics: {'avg_train_loss': 0.07920771815211339, 'avg_test_loss': 0.0832029307303203}
INFO:model_data_nn.py:Epoch 62/100, metrics: {'avg_train_loss': 0.07919025868207652, 'avg_test_loss': 0.08321765110970049}
INFO:model_data_nn.py:Epoch 63/100, metrics: {'avg_train_loss': 0.0791932086438118, 'avg_test_loss': 0.08320868892679359}
INFO:model_data_nn.py:Epoch 64/100, metrics: {'avg_train_loss': 0.07919731043587595, 'avg_test_loss': 0.08322042310189477}
INFO:model_data_nn.py:Epoch 65/100, metrics: {'avg_train_loss': 0.07918269787733624, 'avg_test_loss': 0.08321613670026852}
INFO:model_data_nn.py:Epoch 66/100, metrics: {'avg_train_loss': 0.07913057234499088, 'avg_test_loss': 0.0831584749154031}
INFO:model_data_nn.py:Epoch 67/100, metrics: {'avg_train_loss': 0.079113640610302, 'avg_test_loss': 0.08316962614571308}
INFO:model_data_nn.py:Epoch 68/100, metrics: {'avg_train_loss': 0.0790991742855333, 'avg_test_loss': 0.08313463961095208}
INFO:model_data_nn.py:Epoch 69/100, metrics: {'avg_train_loss': 0.07913460831830149, 'avg_test_loss': 0.08318277988530233}
INFO:model_data_nn.py:Epoch 70/100, metrics: {'avg_train_loss': 0.07907981400879995, 'avg_test_loss': 0.08319022610394211}
INFO:model_data_nn.py:Epoch 71/100, metrics: {'avg_train_loss': 0.07908448369445852, 'avg_test_loss': 0.08318364455254149}
INFO:model_data_nn.py:Epoch 72/100, metrics: {'avg_train_loss': 0.07901718307818685, 'avg_test_loss': 0.08312757409277693}
INFO:model_data_nn.py:Epoch 73/100, metrics: {'avg_train_loss': 0.07904320429593276, 'avg_test_loss': 0.08309461327669564}
INFO:model_data_nn.py:Epoch 74/100, metrics: {'avg_train_loss': 0.07903364875748979, 'avg_test_loss': 0.08311784014600397}
INFO:model_data_nn.py:Epoch 75/100, metrics: {'avg_train_loss': 0.07901026231430278, 'avg_test_loss': 0.08313500471570986}
INFO:model_data_nn.py:Epoch 76/100, metrics: {'avg_train_loss': 0.07897964414124461, 'avg_test_loss': 0.08313092032689495}
INFO:model_data_nn.py:Epoch 77/100, metrics: {'avg_train_loss': 0.07896031830782368, 'avg_test_loss': 0.08307528769397467}
INFO:model_data_nn.py:Epoch 78/100, metrics: {'avg_train_loss': 0.07903348600282233, 'avg_test_loss': 0.083127372724525}
INFO:model_data_nn.py:Epoch 79/100, metrics: {'avg_train_loss': 0.0789426725692402, 'avg_test_loss': 0.0830566224820996}
INFO:model_data_nn.py:Epoch 80/100, metrics: {'avg_train_loss': 0.07896542354452614, 'avg_test_loss': 0.08307616403694712}
INFO:model_data_nn.py:Epoch 81/100, metrics: {'avg_train_loss': 0.0789479392230938, 'avg_test_loss': 0.08310140840614498}
INFO:model_data_nn.py:Epoch 82/100, metrics: {'avg_train_loss': 0.07894032209349627, 'avg_test_loss': 0.08309274651425874}
INFO:model_data_nn.py:Epoch 83/100, metrics: {'avg_train_loss': 0.07886759729479395, 'avg_test_loss': 0.08307597274749966}
INFO:model_data_nn.py:Epoch 84/100, metrics: {'avg_train_loss': 0.07889760900601277, 'avg_test_loss': 0.08305533323436975}
INFO:model_data_nn.py:Epoch 85/100, metrics: {'avg_train_loss': 0.07884756955560054, 'avg_test_loss': 0.08310188164429391}
INFO:model_data_nn.py:Epoch 86/100, metrics: {'avg_train_loss': 0.07882490496905077, 'avg_test_loss': 0.08312680540701091}
INFO:model_data_nn.py:Epoch 87/100, metrics: {'avg_train_loss': 0.07888029060362801, 'avg_test_loss': 0.08307102855326513}
INFO:model_data_nn.py:Epoch 88/100, metrics: {'avg_train_loss': 0.07888370495414547, 'avg_test_loss': 0.08314248616149449}
INFO:model_data_nn.py:Epoch 89/100, metrics: {'avg_train_loss': 0.07883114175864966, 'avg_test_loss': 0.08304990812515219}
INFO:model_data_nn.py:Epoch 90/100, metrics: {'avg_train_loss': 0.07879048449721074, 'avg_test_loss': 0.08305054859884378}
INFO:model_data_nn.py:Epoch 91/100, metrics: {'avg_train_loss': 0.07881255120994499, 'avg_test_loss': 0.08310005213476002}
INFO:model_data_nn.py:Epoch 92/100, metrics: {'avg_train_loss': 0.07881578443838018, 'avg_test_loss': 0.08304337805957865}
INFO:model_data_nn.py:Epoch 93/100, metrics: {'avg_train_loss': 0.07874421008310212, 'avg_test_loss': 0.08313596584849943}
INFO:model_data_nn.py:Epoch 94/100, metrics: {'avg_train_loss': 0.07875911782554137, 'avg_test_loss': 0.08314414803559582}
INFO:model_data_nn.py:Epoch 95/100, metrics: {'avg_train_loss': 0.07871958999027744, 'avg_test_loss': 0.08305222366668158}
INFO:model_data_nn.py:Epoch 96/100, metrics: {'avg_train_loss': 0.07874445745558176, 'avg_test_loss': 0.0830968008429275}
INFO:model_data_nn.py:Epoch 97/100, metrics: {'avg_train_loss': 0.07866942197552104, 'avg_test_loss': 0.0830754027202052}
INFO:model_data_nn.py:Epoch 98/100, metrics: {'avg_train_loss': 0.07866218203005433, 'avg_test_loss': 0.08310440420252034}
INFO:model_data_nn.py:Epoch 99/100, metrics: {'avg_train_loss': 0.07868333445565606, 'avg_test_loss': 0.08309161082162696}
INFO:model_data_nn.py:Epoch 100/100, metrics: {'avg_train_loss': 0.07865127696891545, 'avg_test_loss': 0.08309813549657916}
INFO:main_restricted.py:Making prediction for data in year: 1996
INFO:main_restricted.py:Prediction data shape: (22619,)
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src/main_restricted.py:332: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  prediction_data['pred'] = predictions
INFO:main_restricted.py:Root Mean Squared Error for Prediction in 1996: 0.28821023035054727
INFO:main_restricted.py:Prediction Stats:                retq          pred
count  22619.000000  22619.000000
mean       0.044741      0.021395
std        0.289333      0.025255
min       -0.961538     -0.135655
25%       -0.085714      0.006087
50%        0.018182      0.018252
75%        0.140416      0.044296
max       10.111111      0.105463
INFO:main_restricted.py:

Transform data

INFO:transform_data_nn.py:Train data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998]
INFO:transform_data_nn.py:Train_data: (307585, 161)

INFO:transform_data_nn.py:Test data years: [1999]
INFO:transform_data_nn.py:Test_data: (23257, 161)

INFO:transform_data_nn.py:Retrain data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]
INFO:transform_data_nn.py:Retrain_data: (330842, 161)

INFO:transform_data_nn.py:Prediction data years: [2000]
INFO:transform_data_nn.py:Prediction_data: (22167, 161)

INFO:main_restricted.py:

Generate X and y with train_data and test_data

/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide
  T = new_sum / new_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide
  new_unnormalized_variance -= correction**2 / new_sample_count
INFO:main_restricted.py:
            x_train_tf: torch.Size([307585, 138])
            y_train_tf: torch.Size([307585])

            x_test_tf: torch.Size([23257, 138])
            y_test_tf: torch.Size([23257])

        
INFO:main_restricted.py:

Generate X and y with retrain_data and prediction_data

/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide
  T = new_sum / new_sample_count
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide
  new_unnormalized_variance -= correction**2 / new_sample_count
INFO:main_restricted.py:
            x_retrain_tf: torch.Size([330842, 138])
            y_retrain_tf: torch.Size([330842])

            x_prediction_tf: torch.Size([22167, 138])
            y_prediction_tf: torch.Size([22167])

        
INFO:main_restricted.py:

Create dataset

INFO:main_restricted.py:Create train_dataset
INFO:main_restricted.py:Create test_dataset
INFO:main_restricted.py:Create retrain_dataset
INFO:main_restricted.py:Create prediction_dataset
INFO:main_restricted.py:

Hyperparameters tuning with Ray Tune

INFO:main_restricted.py:Training data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998]
INFO:main_restricted.py:Testing data year: 1999
INFO:main_restricted.py:

            ray_results_path: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
            num_samples: 150
            max_num_epochs: 100
            num_cpus: 24
            cpus_per_trial: 1
            num_gpus: 0
            gpus_per_trial: 0
            continuous_dim: 137
            num_embeddings: 12245
            device: cpu
            
2024-08-13 20:33:17,249	INFO worker.py:1753 -- Started a local Ray instance.
2024-08-13 20:33:17,298	INFO packaging.py:530 -- Creating a file package for local directory '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src'.
2024-08-13 20:33:17,351	INFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_35fa27def23cedb5.zip' (5.11MiB) to Ray cluster...
2024-08-13 20:33:17,363	INFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_35fa27def23cedb5.zip'.
2024-08-13 20:33:19,270	WARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
[36m(train_fnn pid=1662316)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1662316)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1683418)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1683418)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1662319)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1662319)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1683824)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1683824)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1711489)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1711489)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1730309)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1730309)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1778250)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1778250)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1777104)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1777104)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1796200)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1796200)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1777591)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1777591)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1795344)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1795344)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1823252)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1823252)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1813080)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1813080)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1841974)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1841974)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1834515)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1834515)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1842039)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1842039)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=1862916)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=1862916)[0m   return F.mse_loss(input, target, reduction=self.reduction)
2024-08-13 22:10:32,347	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-13_20-33-19' in 0.3294s.
INFO:model_data_nn.py:Best trial config: {'continuous_dim': 137, 'hidden_dim': 115, 'num_layers': 3, 'num_embeddings': 12245, 'embedding_dim': 10, 'dropout_rate': 0.48, 'lr': 0.0036658467366800394, 'weight_decay': 0.0006901805905148956, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 32}
INFO:model_data_nn.py:Best trial training loss: 0.08607635726470886
INFO:model_data_nn.py:Best trial testing loss: 0.2568951615579477
INFO:main_restricted.py:Ray Tune results have been saved to: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
INFO:main_restricted.py:Best trial directory: /tmp/ray/session_2024-08-13_20-33-14_679713_1685331/artifacts/2024-08-13_20-33-19/train_fnn_2024-08-13_20-33-19/driver_artifacts/train_fnn_f31d8_00140_140_batch_size=32,dropout_rate=0.4800,embedding_dim=10,hidden_dim=115,lr=0.0037,num_layers=3,weight_decay=0._2024-08-13_20-33-20
INFO:main_restricted.py:

Retrain a new model with data in years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]

            Using the optimized hyperparameters: {'continuous_dim': 137, 'hidden_dim': 115, 'num_layers': 3, 'num_embeddings': 12852, 'embedding_dim': 10, 'dropout_rate': 0.48, 'lr': 0.0036658467366800394, 'weight_decay': 0.0006901805905148956, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 32}

INFO:model_data_nn.py:Epoch 1/100, metrics: {'avg_train_loss': 0.09825679805460567, 'avg_test_loss': 0.20854901585830066}
INFO:model_data_nn.py:Epoch 2/100, metrics: {'avg_train_loss': 0.0981549210520308, 'avg_test_loss': 0.20619866043909804}
INFO:model_data_nn.py:Epoch 3/100, metrics: {'avg_train_loss': 0.09813965137889019, 'avg_test_loss': 0.20673505348270332}
INFO:model_data_nn.py:Epoch 4/100, metrics: {'avg_train_loss': 0.09812769895721452, 'avg_test_loss': 0.20765430189959413}
INFO:model_data_nn.py:Epoch 5/100, metrics: {'avg_train_loss': 0.09812917230619432, 'avg_test_loss': 0.20737505693413305}
INFO:model_data_nn.py:Epoch 6/100, metrics: {'avg_train_loss': 0.09813030304648104, 'avg_test_loss': 0.2061290214346214}
INFO:model_data_nn.py:Epoch 7/100, metrics: {'avg_train_loss': 0.09812993844053972, 'avg_test_loss': 0.20649180996458855}
INFO:model_data_nn.py:Epoch 8/100, metrics: {'avg_train_loss': 0.09813204518463307, 'avg_test_loss': 0.2064766272832606}
INFO:model_data_nn.py:Epoch 9/100, metrics: {'avg_train_loss': 0.09814378487720615, 'avg_test_loss': 0.20722788184193133}
INFO:model_data_nn.py:Epoch 10/100, metrics: {'avg_train_loss': 0.09813222129630855, 'avg_test_loss': 0.20596182185882356}
INFO:model_data_nn.py:Epoch 11/100, metrics: {'avg_train_loss': 0.09799153869196882, 'avg_test_loss': 0.20951538989898275}
INFO:model_data_nn.py:Epoch 12/100, metrics: {'avg_train_loss': 0.0981229759261234, 'avg_test_loss': 0.20847055955130128}
INFO:model_data_nn.py:Epoch 13/100, metrics: {'avg_train_loss': 0.09812691912824721, 'avg_test_loss': 0.20852638304523832}
INFO:model_data_nn.py:Epoch 14/100, metrics: {'avg_train_loss': 0.09813522028184174, 'avg_test_loss': 0.2067123908243138}
INFO:model_data_nn.py:Epoch 15/100, metrics: {'avg_train_loss': 0.09813918752745687, 'avg_test_loss': 0.2074029967108201}
INFO:model_data_nn.py:Epoch 16/100, metrics: {'avg_train_loss': 0.09803510697891485, 'avg_test_loss': 0.20783398377817947}
INFO:model_data_nn.py:Epoch 17/100, metrics: {'avg_train_loss': 0.09812139147372971, 'avg_test_loss': 0.20759855607500324}
INFO:model_data_nn.py:Epoch 18/100, metrics: {'avg_train_loss': 0.09811796036154871, 'avg_test_loss': 0.20750334054435918}
INFO:model_data_nn.py:Epoch 19/100, metrics: {'avg_train_loss': 0.09813343611724054, 'avg_test_loss': 0.20752338364365555}
INFO:model_data_nn.py:Epoch 20/100, metrics: {'avg_train_loss': 0.09812317840941646, 'avg_test_loss': 0.20734884767842843}
INFO:model_data_nn.py:Epoch 21/100, metrics: {'avg_train_loss': 0.09813034204158246, 'avg_test_loss': 0.20742227979176403}
INFO:model_data_nn.py:Epoch 22/100, metrics: {'avg_train_loss': 0.09812854626184464, 'avg_test_loss': 0.20706050541966853}
INFO:model_data_nn.py:Epoch 23/100, metrics: {'avg_train_loss': 0.09812825715023729, 'avg_test_loss': 0.20632022047014895}
INFO:model_data_nn.py:Epoch 24/100, metrics: {'avg_train_loss': 0.09812529599767926, 'avg_test_loss': 0.20706732820821616}
INFO:model_data_nn.py:Epoch 25/100, metrics: {'avg_train_loss': 0.09813662413954533, 'avg_test_loss': 0.20729807296077066}
INFO:model_data_nn.py:Epoch 26/100, metrics: {'avg_train_loss': 0.09813488636242972, 'avg_test_loss': 0.20747451661598115}
INFO:model_data_nn.py:Epoch 27/100, metrics: {'avg_train_loss': 0.09811689249274275, 'avg_test_loss': 0.20872553527720736}
INFO:model_data_nn.py:Epoch 28/100, metrics: {'avg_train_loss': 0.09812456594348029, 'avg_test_loss': 0.20627525875890496}
INFO:model_data_nn.py:Epoch 29/100, metrics: {'avg_train_loss': 0.09814284753770033, 'avg_test_loss': 0.20798810724636693}
INFO:model_data_nn.py:Epoch 30/100, metrics: {'avg_train_loss': 0.09813266397947704, 'avg_test_loss': 0.20759374402398928}
INFO:model_data_nn.py:Epoch 31/100, metrics: {'avg_train_loss': 0.09812449386651818, 'avg_test_loss': 0.20768115597187098}
INFO:model_data_nn.py:Epoch 32/100, metrics: {'avg_train_loss': 0.09814200660206261, 'avg_test_loss': 0.2085066143756606}
INFO:model_data_nn.py:Epoch 33/100, metrics: {'avg_train_loss': 0.09813812418770017, 'avg_test_loss': 0.20676924149582396}
INFO:model_data_nn.py:Epoch 34/100, metrics: {'avg_train_loss': 0.09812846045692834, 'avg_test_loss': 0.20952372582465367}
INFO:model_data_nn.py:Epoch 35/100, metrics: {'avg_train_loss': 0.09812523048483866, 'avg_test_loss': 0.20734540601549897}
INFO:model_data_nn.py:Epoch 36/100, metrics: {'avg_train_loss': 0.09814328543921476, 'avg_test_loss': 0.20629173001707202}
INFO:model_data_nn.py:Epoch 37/100, metrics: {'avg_train_loss': 0.09811877270221413, 'avg_test_loss': 0.20756766092822407}
INFO:model_data_nn.py:Epoch 38/100, metrics: {'avg_train_loss': 0.09813569672693999, 'avg_test_loss': 0.20696054595491672}
INFO:model_data_nn.py:Epoch 39/100, metrics: {'avg_train_loss': 0.0981314063760832, 'avg_test_loss': 0.2090648030499359}
INFO:model_data_nn.py:Epoch 40/100, metrics: {'avg_train_loss': 0.09813041170699745, 'avg_test_loss': 0.20650387239275556}
INFO:model_data_nn.py:Epoch 41/100, metrics: {'avg_train_loss': 0.09813502949179098, 'avg_test_loss': 0.2079812813319083}
INFO:model_data_nn.py:Epoch 42/100, metrics: {'avg_train_loss': 0.09813132723879871, 'avg_test_loss': 0.20713428407101145}
INFO:model_data_nn.py:Epoch 43/100, metrics: {'avg_train_loss': 0.09804861750190656, 'avg_test_loss': 0.20759103937184742}
INFO:model_data_nn.py:Epoch 44/100, metrics: {'avg_train_loss': 0.09812702589197538, 'avg_test_loss': 0.20718367570879484}
INFO:model_data_nn.py:Epoch 45/100, metrics: {'avg_train_loss': 0.09813784601278193, 'avg_test_loss': 0.2069235092235936}
INFO:model_data_nn.py:Epoch 46/100, metrics: {'avg_train_loss': 0.09813711957243526, 'avg_test_loss': 0.20790227296430225}
INFO:model_data_nn.py:Epoch 47/100, metrics: {'avg_train_loss': 0.09813723999096673, 'avg_test_loss': 0.20671718205831957}
INFO:model_data_nn.py:Epoch 48/100, metrics: {'avg_train_loss': 0.09813137200011834, 'avg_test_loss': 0.2068457066781636}
INFO:model_data_nn.py:Epoch 49/100, metrics: {'avg_train_loss': 0.09812546808137108, 'avg_test_loss': 0.2066470410373777}
INFO:model_data_nn.py:Epoch 50/100, metrics: {'avg_train_loss': 0.09813614271180825, 'avg_test_loss': 0.20720574467793687}
INFO:model_data_nn.py:Epoch 51/100, metrics: {'avg_train_loss': 0.09812778728916985, 'avg_test_loss': 0.20722537042914446}
INFO:model_data_nn.py:Epoch 52/100, metrics: {'avg_train_loss': 0.09814128320621646, 'avg_test_loss': 0.207856527474557}
INFO:model_data_nn.py:Epoch 53/100, metrics: {'avg_train_loss': 0.09813523439059499, 'avg_test_loss': 0.20925527952428677}
INFO:model_data_nn.py:Epoch 54/100, metrics: {'avg_train_loss': 0.09813547834512916, 'avg_test_loss': 0.20675869863668475}
INFO:model_data_nn.py:Epoch 55/100, metrics: {'avg_train_loss': 0.09813768824297213, 'avg_test_loss': 0.20770464408578296}
INFO:model_data_nn.py:Epoch 56/100, metrics: {'avg_train_loss': 0.09811687109196257, 'avg_test_loss': 0.2072357421775831}
INFO:model_data_nn.py:Epoch 57/100, metrics: {'avg_train_loss': 0.09812887348407622, 'avg_test_loss': 0.2070266961282681}
INFO:model_data_nn.py:Epoch 58/100, metrics: {'avg_train_loss': 0.09813689798054344, 'avg_test_loss': 0.20582700428024772}
INFO:model_data_nn.py:Epoch 59/100, metrics: {'avg_train_loss': 0.0981439689265643, 'avg_test_loss': 0.2079200762637164}
INFO:model_data_nn.py:Epoch 60/100, metrics: {'avg_train_loss': 0.09813074160689403, 'avg_test_loss': 0.20626347846906595}
INFO:model_data_nn.py:Epoch 61/100, metrics: {'avg_train_loss': 0.09813810721182831, 'avg_test_loss': 0.20680574001945976}
INFO:model_data_nn.py:Epoch 62/100, metrics: {'avg_train_loss': 0.0981173451035324, 'avg_test_loss': 0.2059191107013482}
INFO:model_data_nn.py:Epoch 63/100, metrics: {'avg_train_loss': 0.09813686980186458, 'avg_test_loss': 0.20634891225823335}
INFO:model_data_nn.py:Epoch 64/100, metrics: {'avg_train_loss': 0.09813192661622462, 'avg_test_loss': 0.2071765334967626}
INFO:model_data_nn.py:Epoch 65/100, metrics: {'avg_train_loss': 0.09812634807021654, 'avg_test_loss': 0.20879266488474685}
INFO:model_data_nn.py:Epoch 66/100, metrics: {'avg_train_loss': 0.09810383413037442, 'avg_test_loss': 0.20763746345036732}
INFO:model_data_nn.py:Epoch 67/100, metrics: {'avg_train_loss': 0.09813746374387285, 'avg_test_loss': 0.20818276834253538}
INFO:model_data_nn.py:Epoch 68/100, metrics: {'avg_train_loss': 0.09812514949959325, 'avg_test_loss': 0.20738905379051426}
INFO:model_data_nn.py:Epoch 69/100, metrics: {'avg_train_loss': 0.09814133084375352, 'avg_test_loss': 0.2064411570176934}
INFO:model_data_nn.py:Epoch 70/100, metrics: {'avg_train_loss': 0.0981245587220818, 'avg_test_loss': 0.2071844418741451}
INFO:model_data_nn.py:Epoch 71/100, metrics: {'avg_train_loss': 0.09813546098908887, 'avg_test_loss': 0.20639988507478785}
INFO:model_data_nn.py:Epoch 72/100, metrics: {'avg_train_loss': 0.09813237201273269, 'avg_test_loss': 0.20741129409075643}
INFO:model_data_nn.py:Epoch 73/100, metrics: {'avg_train_loss': 0.09812444348014714, 'avg_test_loss': 0.20653629609118895}
INFO:model_data_nn.py:Epoch 74/100, metrics: {'avg_train_loss': 0.09814552682320196, 'avg_test_loss': 0.20717160924355274}
INFO:model_data_nn.py:Epoch 75/100, metrics: {'avg_train_loss': 0.09814386320433549, 'avg_test_loss': 0.2065689516365313}
INFO:model_data_nn.py:Epoch 76/100, metrics: {'avg_train_loss': 0.09812837221082621, 'avg_test_loss': 0.2058257461803687}
INFO:model_data_nn.py:Epoch 77/100, metrics: {'avg_train_loss': 0.0981267940856244, 'avg_test_loss': 0.2072204232624427}
INFO:model_data_nn.py:Epoch 78/100, metrics: {'avg_train_loss': 0.09813672719555021, 'avg_test_loss': 0.20659112147610598}
INFO:model_data_nn.py:Epoch 79/100, metrics: {'avg_train_loss': 0.0981433750458154, 'avg_test_loss': 0.20641520604878277}
INFO:model_data_nn.py:Epoch 80/100, metrics: {'avg_train_loss': 0.09812796015301775, 'avg_test_loss': 0.2071603178590923}
INFO:model_data_nn.py:Epoch 81/100, metrics: {'avg_train_loss': 0.09813197021983228, 'avg_test_loss': 0.20899446217227635}
INFO:model_data_nn.py:Epoch 82/100, metrics: {'avg_train_loss': 0.09813992706181338, 'avg_test_loss': 0.207801938094575}
INFO:model_data_nn.py:Epoch 83/100, metrics: {'avg_train_loss': 0.09811419900083325, 'avg_test_loss': 0.20800909945878374}
INFO:model_data_nn.py:Epoch 84/100, metrics: {'avg_train_loss': 0.09812728226810771, 'avg_test_loss': 0.20732835301804164}
INFO:model_data_nn.py:Epoch 85/100, metrics: {'avg_train_loss': 0.09813850278645238, 'avg_test_loss': 0.208373198874327}
INFO:model_data_nn.py:Epoch 86/100, metrics: {'avg_train_loss': 0.09812740303554732, 'avg_test_loss': 0.20660725226800508}
INFO:model_data_nn.py:Epoch 87/100, metrics: {'avg_train_loss': 0.09813659164514396, 'avg_test_loss': 0.20833391477159005}
INFO:model_data_nn.py:Epoch 88/100, metrics: {'avg_train_loss': 0.09812485973755557, 'avg_test_loss': 0.2079334995221524}
INFO:model_data_nn.py:Epoch 89/100, metrics: {'avg_train_loss': 0.0981365204940992, 'avg_test_loss': 0.2099187173981429}
INFO:model_data_nn.py:Epoch 90/100, metrics: {'avg_train_loss': 0.09813470138715424, 'avg_test_loss': 0.20595803665747117}
INFO:model_data_nn.py:Epoch 91/100, metrics: {'avg_train_loss': 0.098120923112706, 'avg_test_loss': 0.20614834702042875}
INFO:model_data_nn.py:Epoch 92/100, metrics: {'avg_train_loss': 0.09813010640516964, 'avg_test_loss': 0.20682273338270651}
INFO:model_data_nn.py:Epoch 93/100, metrics: {'avg_train_loss': 0.098142144426813, 'avg_test_loss': 0.20660793768916638}
INFO:model_data_nn.py:Epoch 94/100, metrics: {'avg_train_loss': 0.09813870097528354, 'avg_test_loss': 0.20803567975985282}
INFO:model_data_nn.py:Epoch 95/100, metrics: {'avg_train_loss': 0.09813952001628247, 'avg_test_loss': 0.20588805796350063}
INFO:model_data_nn.py:Epoch 96/100, metrics: {'avg_train_loss': 0.09812681356015779, 'avg_test_loss': 0.20617730093617287}
INFO:model_data_nn.py:Epoch 97/100, metrics: {'avg_train_loss': 0.09813663207659738, 'avg_test_loss': 0.20680215336586663}
INFO:model_data_nn.py:Epoch 98/100, metrics: {'avg_train_loss': 0.09814160233122075, 'avg_test_loss': 0.20792972569556809}
INFO:model_data_nn.py:Epoch 99/100, metrics: {'avg_train_loss': 0.0981284218793816, 'avg_test_loss': 0.2064057295392086}
INFO:model_data_nn.py:Epoch 100/100, metrics: {'avg_train_loss': 0.09813556573432083, 'avg_test_loss': 0.2070942089542166}
INFO:main_restricted.py:Making prediction for data in year: 2000
INFO:main_restricted.py:Prediction data shape: (22167,)
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src/main_restricted.py:332: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  prediction_data['pred'] = predictions
INFO:main_restricted.py:Root Mean Squared Error for Prediction in 2000: 0.45513639208457274
INFO:main_restricted.py:Prediction Stats:                retq         pred
count  22167.000000  22167.00000
mean      -0.000670      0.03898
std        0.453416      0.00000
min       -0.980000      0.03898
25%       -0.222436      0.03898
50%       -0.022528      0.03898
75%        0.141851      0.03898
max       10.941179      0.03898
INFO:main_restricted.py:

Transform data

INFO:transform_data_nn.py:Train data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007]
INFO:transform_data_nn.py:Train_data: (483505, 161)

INFO:transform_data_nn.py:Test data years: [2008]
INFO:transform_data_nn.py:Test_data: (16465, 161)

INFO:transform_data_nn.py:Retrain data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008]
INFO:transform_data_nn.py:Retrain_data: (499970, 161)

INFO:transform_data_nn.py:Prediction data years: [2009]
INFO:transform_data_nn.py:Prediction_data: (16061, 161)

INFO:main_restricted.py:

Generate X and y with train_data and test_data

INFO:main_restricted.py:
            x_train_tf: torch.Size([483505, 138])
            y_train_tf: torch.Size([483505])

            x_test_tf: torch.Size([16465, 138])
            y_test_tf: torch.Size([16465])

        
INFO:main_restricted.py:

Generate X and y with retrain_data and prediction_data

INFO:main_restricted.py:
            x_retrain_tf: torch.Size([499970, 138])
            y_retrain_tf: torch.Size([499970])

            x_prediction_tf: torch.Size([16061, 138])
            y_prediction_tf: torch.Size([16061])

        
INFO:main_restricted.py:

Create dataset

INFO:main_restricted.py:Create train_dataset
INFO:main_restricted.py:Create test_dataset
INFO:main_restricted.py:Create retrain_dataset
INFO:main_restricted.py:Create prediction_dataset
INFO:main_restricted.py:

Hyperparameters tuning with Ray Tune

INFO:main_restricted.py:Training data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007]
INFO:main_restricted.py:Testing data year: 2008
INFO:main_restricted.py:

            ray_results_path: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
            num_samples: 150
            max_num_epochs: 100
            num_cpus: 24
            cpus_per_trial: 1
            num_gpus: 0
            gpus_per_trial: 0
            continuous_dim: 137
            num_embeddings: 15361
            device: cpu
            
2024-08-14 00:14:29,591	INFO worker.py:1753 -- Started a local Ray instance.
2024-08-14 00:14:29,642	INFO packaging.py:530 -- Creating a file package for local directory '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src'.
2024-08-14 00:14:29,698	INFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_35fa27def23cedb5.zip' (5.11MiB) to Ray cluster...
2024-08-14 00:14:29,711	INFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_35fa27def23cedb5.zip'.
2024-08-14 00:14:31,555	WARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
[36m(train_fnn pid=42974)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=42974)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43911)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43911)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43905)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43905)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43916)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43916)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43913)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43913)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43918)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43918)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43823)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43823)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43258)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43258)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43019)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43019)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43909)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43909)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=42934)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=42934)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43912)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43912)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43259)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43259)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=71717)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=71717)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=72041)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=72041)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=89325)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=89325)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=90991)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=90991)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=91376)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=91376)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43908)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43908)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=97960)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=97960)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=43364)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=43364)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=91605)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=91605)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=110083)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=110083)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=136545)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=136545)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=110747)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=110747)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=136787)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=136787)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=135071)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=135071)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=154862)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=154862)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=172208)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=172208)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=137036)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=137036)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=172386)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=172386)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=199395)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=199395)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=172871)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=172871)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=198842)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=198842)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=198297)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=198297)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=217170)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=217170)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=216923)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=216923)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=201776)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=201776)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=234983)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=234983)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=261359)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=261359)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=275281)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=275281)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=260981)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=260981)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=217344)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=217344)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=260737)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=260737)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=261358)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=261358)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=278383)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=278383)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=296189)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=296189)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=295445)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=295445)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=295823)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=295823)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=321553)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=321553)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=339231)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=339231)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=332817)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=332817)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=357024)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=357024)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=357578)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=357578)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=356532)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=356532)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=400224)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=400224)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=382896)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=382896)[0m   return F.mse_loss(input, target, reduction=self.reduction)
[36m(train_fnn pid=417528)[0m /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
[36m(train_fnn pid=417528)[0m   return F.mse_loss(input, target, reduction=self.reduction)
2024-08-14 02:29:55,341	WARNING experiment_state.py:233 -- Saving the experiment state (which holds a global view of trial statuses and is used to restore the experiment) has already taken 30.19 seconds, which may cause consistency issues upon restoration if your driver script ungracefully exits.
This could be due to a large number of trials, large logfiles from lots of reported metrics, or throttling from the remote storage if uploading too frequently.
You may want to consider switching the `RunConfig(storage_filesystem)` to a more performant storage backend such as s3fs for a S3 storage path.
You can suppress this error by setting the environment variable TUNE_WARN_SLOW_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a higher value than the current threshold (30.0).
2024-08-14 02:32:09,998	WARNING experiment_state.py:233 -- Saving the experiment state (which holds a global view of trial statuses and is used to restore the experiment) has already taken 30.16 seconds, which may cause consistency issues upon restoration if your driver script ungracefully exits.
This could be due to a large number of trials, large logfiles from lots of reported metrics, or throttling from the remote storage if uploading too frequently.
You may want to consider switching the `RunConfig(storage_filesystem)` to a more performant storage backend such as s3fs for a S3 storage path.
You can suppress this error by setting the environment variable TUNE_WARN_SLOW_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a higher value than the current threshold (30.0).
2024-08-14 02:32:23,097	WARNING experiment_state.py:233 -- Saving the experiment state (which holds a global view of trial statuses and is used to restore the experiment) has already taken 43.26 seconds, which may cause consistency issues upon restoration if your driver script ungracefully exits.
This could be due to a large number of trials, large logfiles from lots of reported metrics, or throttling from the remote storage if uploading too frequently.
You may want to consider switching the `RunConfig(storage_filesystem)` to a more performant storage backend such as s3fs for a S3 storage path.
You can suppress this error by setting the environment variable TUNE_WARN_SLOW_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a higher value than the current threshold (30.0).
2024-08-14 02:32:33,165	WARNING experiment_state.py:233 -- Saving the experiment state (which holds a global view of trial statuses and is used to restore the experiment) has already taken 53.32 seconds, which may cause consistency issues upon restoration if your driver script ungracefully exits.
This could be due to a large number of trials, large logfiles from lots of reported metrics, or throttling from the remote storage if uploading too frequently.
You may want to consider switching the `RunConfig(storage_filesystem)` to a more performant storage backend such as s3fs for a S3 storage path.
You can suppress this error by setting the environment variable TUNE_WARN_SLOW_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a higher value than the current threshold (30.0).
2024-08-14 02:32:43,334	WARNING experiment_state.py:233 -- Saving the experiment state (which holds a global view of trial statuses and is used to restore the experiment) has already taken 63.49 seconds, which may cause consistency issues upon restoration if your driver script ungracefully exits.
This could be due to a large number of trials, large logfiles from lots of reported metrics, or throttling from the remote storage if uploading too frequently.
You may want to consider switching the `RunConfig(storage_filesystem)` to a more performant storage backend such as s3fs for a S3 storage path.
You can suppress this error by setting the environment variable TUNE_WARN_SLOW_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a higher value than the current threshold (30.0).
2024-08-14 04:48:25,182	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-14_00-14-31' in 0.4028s.
INFO:model_data_nn.py:Best trial config: {'continuous_dim': 137, 'hidden_dim': 115, 'num_layers': 5, 'num_embeddings': 15361, 'embedding_dim': 8, 'dropout_rate': 0.39, 'lr': 0.007649771574229914, 'weight_decay': 0.0001456083695580807, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 16}
INFO:model_data_nn.py:Best trial training loss: 0.10630798106429085
INFO:model_data_nn.py:Best trial testing loss: 0.12344613582171608
INFO:main_restricted.py:Ray Tune results have been saved to: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
INFO:main_restricted.py:Best trial directory: /tmp/ray/session_2024-08-14_00-14-27_036021_1685331/artifacts/2024-08-14_00-14-31/train_fnn_2024-08-14_00-14-31/driver_artifacts/train_fnn_da039_00110_110_batch_size=16,dropout_rate=0.3900,embedding_dim=8,hidden_dim=115,lr=0.0076,num_layers=5,weight_decay=0.0_2024-08-14_00-14-32
INFO:main_restricted.py:

Retrain a new model with data in years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008]

            Using the optimized hyperparameters: {'continuous_dim': 137, 'hidden_dim': 115, 'num_layers': 5, 'num_embeddings': 15661, 'embedding_dim': 8, 'dropout_rate': 0.39, 'lr': 0.007649771574229914, 'weight_decay': 0.0001456083695580807, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 16}

INFO:model_data_nn.py:Epoch 1/100, metrics: {'avg_train_loss': 0.10727481306397608, 'avg_test_loss': 0.2779760105281222}
INFO:model_data_nn.py:Epoch 2/100, metrics: {'avg_train_loss': 0.10698530922302255, 'avg_test_loss': 0.27201602007893183}
INFO:model_data_nn.py:Epoch 3/100, metrics: {'avg_train_loss': 0.10699949789445319, 'avg_test_loss': 0.26957876654109914}
INFO:model_data_nn.py:Epoch 4/100, metrics: {'avg_train_loss': 0.10700227197268189, 'avg_test_loss': 0.2661861149071014}
INFO:model_data_nn.py:Epoch 5/100, metrics: {'avg_train_loss': 0.10699117400622842, 'avg_test_loss': 0.27010764958303557}
INFO:model_data_nn.py:Epoch 6/100, metrics: {'avg_train_loss': 0.10698834726328475, 'avg_test_loss': 0.2765943214076523}
INFO:model_data_nn.py:Epoch 7/100, metrics: {'avg_train_loss': 0.10698745908725056, 'avg_test_loss': 0.26989707482637343}
INFO:model_data_nn.py:Epoch 8/100, metrics: {'avg_train_loss': 0.10699100878992257, 'avg_test_loss': 0.27620102223138737}
INFO:model_data_nn.py:Epoch 9/100, metrics: {'avg_train_loss': 0.10698122112527518, 'avg_test_loss': 0.27861292514694014}
INFO:model_data_nn.py:Epoch 10/100, metrics: {'avg_train_loss': 0.1069728084695926, 'avg_test_loss': 0.2752425403388002}
INFO:model_data_nn.py:Epoch 11/100, metrics: {'avg_train_loss': 0.1069690241358034, 'avg_test_loss': 0.2740538294795359}
INFO:model_data_nn.py:Epoch 12/100, metrics: {'avg_train_loss': 0.106987924927706, 'avg_test_loss': 0.2798888534520831}
INFO:model_data_nn.py:Epoch 13/100, metrics: {'avg_train_loss': 0.10697292745023901, 'avg_test_loss': 0.27147396359281}
INFO:model_data_nn.py:Epoch 14/100, metrics: {'avg_train_loss': 0.10697534778882908, 'avg_test_loss': 0.2796613036230971}
INFO:model_data_nn.py:Epoch 15/100, metrics: {'avg_train_loss': 0.10697354720131705, 'avg_test_loss': 0.26894157556529374}
INFO:model_data_nn.py:Epoch 16/100, metrics: {'avg_train_loss': 0.10698402814014339, 'avg_test_loss': 0.2731859392038476}
INFO:model_data_nn.py:Epoch 17/100, metrics: {'avg_train_loss': 0.10697709883428982, 'avg_test_loss': 0.2797293205345717}
INFO:model_data_nn.py:Epoch 18/100, metrics: {'avg_train_loss': 0.10698736337554132, 'avg_test_loss': 0.26937030805636614}
INFO:model_data_nn.py:Epoch 19/100, metrics: {'avg_train_loss': 0.10698569888019309, 'avg_test_loss': 0.2717572714817113}
INFO:model_data_nn.py:Epoch 20/100, metrics: {'avg_train_loss': 0.10698397400071516, 'avg_test_loss': 0.284852684677701}
INFO:model_data_nn.py:Epoch 21/100, metrics: {'avg_train_loss': 0.10697748150777048, 'avg_test_loss': 0.2768818736322172}
INFO:model_data_nn.py:Epoch 22/100, metrics: {'avg_train_loss': 0.10697255219291506, 'avg_test_loss': 0.2775533162831956}
INFO:model_data_nn.py:Epoch 23/100, metrics: {'avg_train_loss': 0.10697461441513025, 'avg_test_loss': 0.2761951933050921}
INFO:model_data_nn.py:Epoch 24/100, metrics: {'avg_train_loss': 0.1069838689274377, 'avg_test_loss': 0.28357033169386814}
INFO:model_data_nn.py:Epoch 25/100, metrics: {'avg_train_loss': 0.10695742583179492, 'avg_test_loss': 0.27137324960941295}
INFO:model_data_nn.py:Epoch 26/100, metrics: {'avg_train_loss': 0.10698048486306962, 'avg_test_loss': 0.27491915987134796}
INFO:model_data_nn.py:Epoch 27/100, metrics: {'avg_train_loss': 0.10697858164884975, 'avg_test_loss': 0.27434083517915403}
INFO:model_data_nn.py:Epoch 28/100, metrics: {'avg_train_loss': 0.10698770378862092, 'avg_test_loss': 0.2692675952288504}
INFO:model_data_nn.py:Epoch 29/100, metrics: {'avg_train_loss': 0.10699558119851446, 'avg_test_loss': 0.277186523160092}
INFO:model_data_nn.py:Epoch 30/100, metrics: {'avg_train_loss': 0.10696273737261304, 'avg_test_loss': 0.2805297759962658}
INFO:model_data_nn.py:Epoch 31/100, metrics: {'avg_train_loss': 0.1069932374703486, 'avg_test_loss': 0.280310158609446}
INFO:model_data_nn.py:Epoch 32/100, metrics: {'avg_train_loss': 0.10698787281354968, 'avg_test_loss': 0.27710612458306777}
INFO:model_data_nn.py:Epoch 33/100, metrics: {'avg_train_loss': 0.10697522923401061, 'avg_test_loss': 0.2690090280373124}
INFO:model_data_nn.py:Epoch 34/100, metrics: {'avg_train_loss': 0.10699569285201449, 'avg_test_loss': 0.27122423429444686}
INFO:model_data_nn.py:Epoch 35/100, metrics: {'avg_train_loss': 0.10700615415946522, 'avg_test_loss': 0.27952066900216016}
INFO:model_data_nn.py:Epoch 36/100, metrics: {'avg_train_loss': 0.10697053647856132, 'avg_test_loss': 0.27884422930744124}
INFO:model_data_nn.py:Epoch 37/100, metrics: {'avg_train_loss': 0.10699685156126663, 'avg_test_loss': 0.27485512252535255}
INFO:model_data_nn.py:Epoch 38/100, metrics: {'avg_train_loss': 0.10697869950285156, 'avg_test_loss': 0.27874713278731766}
INFO:model_data_nn.py:Epoch 39/100, metrics: {'avg_train_loss': 0.10696712925688781, 'avg_test_loss': 0.2696303103631177}
INFO:model_data_nn.py:Epoch 40/100, metrics: {'avg_train_loss': 0.10695888190200606, 'avg_test_loss': 0.27644583137067724}
INFO:model_data_nn.py:Epoch 41/100, metrics: {'avg_train_loss': 0.10697830707823161, 'avg_test_loss': 0.2684267668820643}
INFO:model_data_nn.py:Epoch 42/100, metrics: {'avg_train_loss': 0.10698518739883653, 'avg_test_loss': 0.27543387009226067}
INFO:model_data_nn.py:Epoch 43/100, metrics: {'avg_train_loss': 0.10697141271815794, 'avg_test_loss': 0.27805731467999134}
INFO:model_data_nn.py:Epoch 44/100, metrics: {'avg_train_loss': 0.10698135947077288, 'avg_test_loss': 0.27504978006505276}
INFO:model_data_nn.py:Epoch 45/100, metrics: {'avg_train_loss': 0.10696674858720513, 'avg_test_loss': 0.27698567912234845}
INFO:model_data_nn.py:Epoch 46/100, metrics: {'avg_train_loss': 0.10697399798431047, 'avg_test_loss': 0.27730978476124785}
INFO:model_data_nn.py:Epoch 47/100, metrics: {'avg_train_loss': 0.10699707665244475, 'avg_test_loss': 0.2718984105422967}
INFO:model_data_nn.py:Epoch 48/100, metrics: {'avg_train_loss': 0.10699393576747167, 'avg_test_loss': 0.27497837175911966}
INFO:model_data_nn.py:Epoch 49/100, metrics: {'avg_train_loss': 0.10697727818282261, 'avg_test_loss': 0.2748004341673336}
INFO:model_data_nn.py:Epoch 50/100, metrics: {'avg_train_loss': 0.10698646241547449, 'avg_test_loss': 0.2746462160842011}
INFO:model_data_nn.py:Epoch 51/100, metrics: {'avg_train_loss': 0.10699006972890321, 'avg_test_loss': 0.27388139891640406}
INFO:model_data_nn.py:Epoch 52/100, metrics: {'avg_train_loss': 0.10698207373820191, 'avg_test_loss': 0.2711983137528423}
INFO:model_data_nn.py:Epoch 53/100, metrics: {'avg_train_loss': 0.1069808107017765, 'avg_test_loss': 0.2723608085304959}
INFO:model_data_nn.py:Epoch 54/100, metrics: {'avg_train_loss': 0.10696951419381993, 'avg_test_loss': 0.27781084583899696}
INFO:model_data_nn.py:Early stopping at epoch 54
INFO:main_restricted.py:Making prediction for data in year: 2009
INFO:main_restricted.py:Prediction data shape: (16061,)
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src/main_restricted.py:332: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  prediction_data['pred'] = predictions
INFO:main_restricted.py:Root Mean Squared Error for Prediction in 2009: 0.5271213203523849
INFO:main_restricted.py:Prediction Stats:                retq          pred
count  16061.000000  16061.000000
mean       0.139171      0.016976
std        0.512778      0.000000
min       -0.941129      0.016976
25%       -0.088888      0.016976
50%        0.057852      0.016976
75%        0.252000      0.016976
max       18.331762      0.016976
INFO:main_restricted.py:

Transform data

INFO:transform_data_nn.py:Train data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011]
INFO:transform_data_nn.py:Train_data: (545716, 161)

INFO:transform_data_nn.py:Test data years: [2012]
INFO:transform_data_nn.py:Test_data: (14104, 161)

INFO:transform_data_nn.py:Retrain data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012]
INFO:transform_data_nn.py:Retrain_data: (559820, 161)

INFO:transform_data_nn.py:Prediction data years: [2013]
INFO:transform_data_nn.py:Prediction_data: (13650, 161)

INFO:main_restricted.py:

Generate X and y with train_data and test_data

INFO:main_restricted.py:
            x_train_tf: torch.Size([545716, 138])
            y_train_tf: torch.Size([545716])

            x_test_tf: torch.Size([14104, 138])
            y_test_tf: torch.Size([14104])

        
INFO:main_restricted.py:

Generate X and y with retrain_data and prediction_data

INFO:main_restricted.py:
            x_retrain_tf: torch.Size([559820, 138])
            y_retrain_tf: torch.Size([559820])

            x_prediction_tf: torch.Size([13650, 138])
            y_prediction_tf: torch.Size([13650])

        
INFO:main_restricted.py:

Create dataset

INFO:main_restricted.py:Create train_dataset
INFO:main_restricted.py:Create test_dataset
INFO:main_restricted.py:Create retrain_dataset
INFO:main_restricted.py:Create prediction_dataset
INFO:main_restricted.py:

Hyperparameters tuning with Ray Tune

INFO:main_restricted.py:Training data years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011]
INFO:main_restricted.py:Testing data year: 2012
INFO:main_restricted.py:

            ray_results_path: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
            num_samples: 150
            max_num_epochs: 100
            num_cpus: 24
            cpus_per_trial: 1
            num_gpus: 0
            gpus_per_trial: 0
            continuous_dim: 137
            num_embeddings: 16081
            device: cpu
            
2024-08-14 08:13:36,939	INFO worker.py:1753 -- Started a local Ray instance.
2024-08-14 08:13:36,998	INFO packaging.py:530 -- Creating a file package for local directory '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src'.
2024-08-14 08:13:37,053	INFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_35fa27def23cedb5.zip' (5.11MiB) to Ray cluster...
2024-08-14 08:13:37,069	INFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_35fa27def23cedb5.zip'.
2024-08-14 08:13:39,026	WARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
2024-08-15 03:00:44,054	WARNING experiment_state.py:233 -- Saving the experiment state (which holds a global view of trial statuses and is used to restore the experiment) has already taken 30.23 seconds, which may cause consistency issues upon restoration if your driver script ungracefully exits.
This could be due to a large number of trials, large logfiles from lots of reported metrics, or throttling from the remote storage if uploading too frequently.
You may want to consider switching the `RunConfig(storage_filesystem)` to a more performant storage backend such as s3fs for a S3 storage path.
You can suppress this error by setting the environment variable TUNE_WARN_SLOW_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a higher value than the current threshold (30.0).
2024-08-15 04:43:04,850	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-14_08-13-39' in 0.3211s.
INFO:model_data_nn.py:Best trial config: {'continuous_dim': 137, 'hidden_dim': 45, 'num_layers': 5, 'num_embeddings': 16081, 'embedding_dim': 3, 'dropout_rate': 0.11, 'lr': 0.006630043897114068, 'weight_decay': 7.254118594730665e-05, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 16}
INFO:model_data_nn.py:Best trial training loss: 0.10993981607768995
INFO:model_data_nn.py:Best trial testing loss: 0.07401840334553314
INFO:main_restricted.py:Ray Tune results have been saved to: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results
INFO:main_restricted.py:Best trial directory: /tmp/ray/session_2024-08-14_08-13-34_289367_1685331/artifacts/2024-08-14_08-13-39/train_fnn_2024-08-14_08-13-39/driver_artifacts/train_fnn_c8d78_00121_121_batch_size=16,dropout_rate=0.1100,embedding_dim=3,hidden_dim=45,lr=0.0066,num_layers=5,weight_decay=0.00_2024-08-14_08-13-39
INFO:main_restricted.py:

Retrain a new model with data in years: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012]

            Using the optimized hyperparameters: {'continuous_dim': 137, 'hidden_dim': 45, 'num_layers': 5, 'num_embeddings': 16225, 'embedding_dim': 3, 'dropout_rate': 0.11, 'lr': 0.006630043897114068, 'weight_decay': 7.254118594730665e-05, 'num_epochs': 100, 'num_gpus': 0, 'batch_size': 16}

INFO:model_data_nn.py:Epoch 1/100, metrics: {'avg_train_loss': 0.10911084366736323, 'avg_test_loss': 0.060552890210759235}
INFO:model_data_nn.py:Epoch 2/100, metrics: {'avg_train_loss': 0.10897317662351412, 'avg_test_loss': 0.0590393924371359}
INFO:model_data_nn.py:Epoch 3/100, metrics: {'avg_train_loss': 0.10903045941911688, 'avg_test_loss': 0.05577700730714188}
INFO:model_data_nn.py:Epoch 4/100, metrics: {'avg_train_loss': 0.10902900054884591, 'avg_test_loss': 0.055071691767066125}
INFO:model_data_nn.py:Epoch 5/100, metrics: {'avg_train_loss': 0.10899842617473719, 'avg_test_loss': 0.060052768147901676}
INFO:model_data_nn.py:Epoch 6/100, metrics: {'avg_train_loss': 0.10903851125341478, 'avg_test_loss': 0.0576972614606271}
INFO:model_data_nn.py:Epoch 7/100, metrics: {'avg_train_loss': 0.10901401411251715, 'avg_test_loss': 0.060057447053082025}
INFO:model_data_nn.py:Epoch 8/100, metrics: {'avg_train_loss': 0.10902166372570268, 'avg_test_loss': 0.058747528649788064}
INFO:model_data_nn.py:Epoch 9/100, metrics: {'avg_train_loss': 0.10903991827957886, 'avg_test_loss': 0.05721858472768348}
INFO:model_data_nn.py:Epoch 10/100, metrics: {'avg_train_loss': 0.10904367206678293, 'avg_test_loss': 0.061014001794264104}
INFO:model_data_nn.py:Epoch 11/100, metrics: {'avg_train_loss': 0.10903898905144191, 'avg_test_loss': 0.05582153100239012}
INFO:model_data_nn.py:Epoch 12/100, metrics: {'avg_train_loss': 0.10902046370477336, 'avg_test_loss': 0.05902908670615658}
INFO:model_data_nn.py:Epoch 13/100, metrics: {'avg_train_loss': 0.10905484430474037, 'avg_test_loss': 0.058209911293614074}
INFO:model_data_nn.py:Epoch 14/100, metrics: {'avg_train_loss': 0.10904299482213219, 'avg_test_loss': 0.056725473524849926}
INFO:model_data_nn.py:Epoch 15/100, metrics: {'avg_train_loss': 0.10903362213090195, 'avg_test_loss': 0.05811101040013344}
INFO:model_data_nn.py:Epoch 16/100, metrics: {'avg_train_loss': 0.10902278716491472, 'avg_test_loss': 0.05815894825578137}
INFO:model_data_nn.py:Epoch 17/100, metrics: {'avg_train_loss': 0.10902403789172398, 'avg_test_loss': 0.058008544658478656}
INFO:model_data_nn.py:Epoch 18/100, metrics: {'avg_train_loss': 0.10904371649589796, 'avg_test_loss': 0.057542008462861456}
INFO:model_data_nn.py:Epoch 19/100, metrics: {'avg_train_loss': 0.10902252333932715, 'avg_test_loss': 0.056488826079730305}
INFO:model_data_nn.py:Epoch 20/100, metrics: {'avg_train_loss': 0.10902345854897834, 'avg_test_loss': 0.05944747716107731}
INFO:model_data_nn.py:Epoch 21/100, metrics: {'avg_train_loss': 0.10902602910280301, 'avg_test_loss': 0.055177325228517066}
INFO:model_data_nn.py:Epoch 22/100, metrics: {'avg_train_loss': 0.10903181625738066, 'avg_test_loss': 0.05870119795591442}
INFO:model_data_nn.py:Epoch 23/100, metrics: {'avg_train_loss': 0.10903882925659295, 'avg_test_loss': 0.057213790596416986}
INFO:model_data_nn.py:Epoch 24/100, metrics: {'avg_train_loss': 0.10903801937371871, 'avg_test_loss': 0.05976342731831591}
INFO:model_data_nn.py:Epoch 25/100, metrics: {'avg_train_loss': 0.10902740962475053, 'avg_test_loss': 0.057058942506953515}
INFO:model_data_nn.py:Epoch 26/100, metrics: {'avg_train_loss': 0.10903758826987449, 'avg_test_loss': 0.05960468552457016}
INFO:model_data_nn.py:Epoch 27/100, metrics: {'avg_train_loss': 0.10901704874918804, 'avg_test_loss': 0.05889838679248698}
INFO:model_data_nn.py:Epoch 28/100, metrics: {'avg_train_loss': 0.10903404928130339, 'avg_test_loss': 0.05904000984893052}
INFO:model_data_nn.py:Epoch 29/100, metrics: {'avg_train_loss': 0.10902558545968974, 'avg_test_loss': 0.058182795608385664}
INFO:model_data_nn.py:Epoch 30/100, metrics: {'avg_train_loss': 0.1090208284318738, 'avg_test_loss': 0.056372297419544824}
INFO:model_data_nn.py:Epoch 31/100, metrics: {'avg_train_loss': 0.1090230665731596, 'avg_test_loss': 0.05741356702824614}
INFO:model_data_nn.py:Epoch 32/100, metrics: {'avg_train_loss': 0.10903409889434065, 'avg_test_loss': 0.05824810583297102}
INFO:model_data_nn.py:Epoch 33/100, metrics: {'avg_train_loss': 0.10901376312137609, 'avg_test_loss': 0.05702235938684548}
INFO:model_data_nn.py:Epoch 34/100, metrics: {'avg_train_loss': 0.1090406559721701, 'avg_test_loss': 0.05588316753456495}
INFO:model_data_nn.py:Epoch 35/100, metrics: {'avg_train_loss': 0.10902448298991564, 'avg_test_loss': 0.05617773250417143}
INFO:model_data_nn.py:Epoch 36/100, metrics: {'avg_train_loss': 0.10902642594396236, 'avg_test_loss': 0.05841677610007762}
INFO:model_data_nn.py:Epoch 37/100, metrics: {'avg_train_loss': 0.10902255031818868, 'avg_test_loss': 0.05921709062902374}
INFO:model_data_nn.py:Epoch 38/100, metrics: {'avg_train_loss': 0.10904253740256255, 'avg_test_loss': 0.057377197467274876}
INFO:model_data_nn.py:Epoch 39/100, metrics: {'avg_train_loss': 0.10900546337107442, 'avg_test_loss': 0.05548437887397038}
INFO:model_data_nn.py:Epoch 40/100, metrics: {'avg_train_loss': 0.10902192487401735, 'avg_test_loss': 0.058532793022500265}
INFO:model_data_nn.py:Epoch 41/100, metrics: {'avg_train_loss': 0.10903493343230176, 'avg_test_loss': 0.057772162230249134}
INFO:model_data_nn.py:Epoch 42/100, metrics: {'avg_train_loss': 0.10899362879524391, 'avg_test_loss': 0.05758724296552759}
INFO:model_data_nn.py:Epoch 43/100, metrics: {'avg_train_loss': 0.10905505582181084, 'avg_test_loss': 0.058438207220779054}
INFO:model_data_nn.py:Epoch 44/100, metrics: {'avg_train_loss': 0.10902518837012802, 'avg_test_loss': 0.05625797617979854}
INFO:model_data_nn.py:Epoch 45/100, metrics: {'avg_train_loss': 0.10903182344467924, 'avg_test_loss': 0.05592179993730239}
INFO:model_data_nn.py:Epoch 46/100, metrics: {'avg_train_loss': 0.10902262717092062, 'avg_test_loss': 0.056976711809355984}
INFO:model_data_nn.py:Epoch 47/100, metrics: {'avg_train_loss': 0.1090182495063541, 'avg_test_loss': 0.05554027612478117}
INFO:model_data_nn.py:Epoch 48/100, metrics: {'avg_train_loss': 0.10902829752944097, 'avg_test_loss': 0.05959704614340369}
INFO:model_data_nn.py:Epoch 49/100, metrics: {'avg_train_loss': 0.10902822385873227, 'avg_test_loss': 0.058013243848279085}
INFO:model_data_nn.py:Epoch 50/100, metrics: {'avg_train_loss': 0.1090308559684194, 'avg_test_loss': 0.05453737910980887}
INFO:model_data_nn.py:Epoch 51/100, metrics: {'avg_train_loss': 0.1090238842110684, 'avg_test_loss': 0.05808544634902453}
INFO:model_data_nn.py:Epoch 52/100, metrics: {'avg_train_loss': 0.10904111029202042, 'avg_test_loss': 0.061736766979604334}
INFO:model_data_nn.py:Epoch 53/100, metrics: {'avg_train_loss': 0.10902505069930092, 'avg_test_loss': 0.055438044892113646}
INFO:model_data_nn.py:Epoch 54/100, metrics: {'avg_train_loss': 0.10903759939059883, 'avg_test_loss': 0.05519813401689993}
INFO:model_data_nn.py:Epoch 55/100, metrics: {'avg_train_loss': 0.10900973658845171, 'avg_test_loss': 0.056647830421925116}
INFO:model_data_nn.py:Epoch 56/100, metrics: {'avg_train_loss': 0.1090323514416799, 'avg_test_loss': 0.05528029937905628}
INFO:model_data_nn.py:Epoch 57/100, metrics: {'avg_train_loss': 0.10902625708019079, 'avg_test_loss': 0.05773781413982341}
INFO:model_data_nn.py:Epoch 58/100, metrics: {'avg_train_loss': 0.10903155975202365, 'avg_test_loss': 0.05788246534036285}
INFO:model_data_nn.py:Epoch 59/100, metrics: {'avg_train_loss': 0.1090415645244561, 'avg_test_loss': 0.060162509445306045}
INFO:model_data_nn.py:Epoch 60/100, metrics: {'avg_train_loss': 0.10904418506267718, 'avg_test_loss': 0.05958395428296868}
INFO:model_data_nn.py:Epoch 61/100, metrics: {'avg_train_loss': 0.10903189414926608, 'avg_test_loss': 0.057828169070681515}
INFO:model_data_nn.py:Epoch 62/100, metrics: {'avg_train_loss': 0.10902779487366156, 'avg_test_loss': 0.05606853162632073}
INFO:model_data_nn.py:Epoch 63/100, metrics: {'avg_train_loss': 0.10902864701153778, 'avg_test_loss': 0.05574872338243562}
INFO:model_data_nn.py:Epoch 64/100, metrics: {'avg_train_loss': 0.10903265275883717, 'avg_test_loss': 0.056702322367495867}
INFO:model_data_nn.py:Epoch 65/100, metrics: {'avg_train_loss': 0.10902662257358008, 'avg_test_loss': 0.05808337796937491}
INFO:model_data_nn.py:Epoch 66/100, metrics: {'avg_train_loss': 0.10903728168696353, 'avg_test_loss': 0.05498956878335854}
INFO:model_data_nn.py:Epoch 67/100, metrics: {'avg_train_loss': 0.10902568921052316, 'avg_test_loss': 0.056450326663095164}
INFO:model_data_nn.py:Epoch 68/100, metrics: {'avg_train_loss': 0.1090278960503149, 'avg_test_loss': 0.055650192809637976}
INFO:model_data_nn.py:Epoch 69/100, metrics: {'avg_train_loss': 0.10903907625871583, 'avg_test_loss': 0.05668978460418798}
INFO:model_data_nn.py:Epoch 70/100, metrics: {'avg_train_loss': 0.1090323619604903, 'avg_test_loss': 0.05989318795554532}
INFO:model_data_nn.py:Epoch 71/100, metrics: {'avg_train_loss': 0.10902589501967601, 'avg_test_loss': 0.056340719267302816}
INFO:model_data_nn.py:Epoch 72/100, metrics: {'avg_train_loss': 0.1090369927077608, 'avg_test_loss': 0.05896079728807338}
INFO:model_data_nn.py:Epoch 73/100, metrics: {'avg_train_loss': 0.1090225642089176, 'avg_test_loss': 0.059579293634000934}
INFO:model_data_nn.py:Epoch 74/100, metrics: {'avg_train_loss': 0.10903542801583585, 'avg_test_loss': 0.057416372326697794}
INFO:model_data_nn.py:Epoch 75/100, metrics: {'avg_train_loss': 0.10902222026427455, 'avg_test_loss': 0.06073377558861181}
INFO:model_data_nn.py:Epoch 76/100, metrics: {'avg_train_loss': 0.10900664037915547, 'avg_test_loss': 0.056120730494857884}
INFO:model_data_nn.py:Epoch 77/100, metrics: {'avg_train_loss': 0.10902862159818082, 'avg_test_loss': 0.056576466204738135}
INFO:model_data_nn.py:Epoch 78/100, metrics: {'avg_train_loss': 0.10903914470608717, 'avg_test_loss': 0.05713244944001685}
INFO:model_data_nn.py:Epoch 79/100, metrics: {'avg_train_loss': 0.10901382330309323, 'avg_test_loss': 0.0579475698980614}
INFO:model_data_nn.py:Epoch 80/100, metrics: {'avg_train_loss': 0.10902746106318056, 'avg_test_loss': 0.056964738920453145}
INFO:model_data_nn.py:Epoch 81/100, metrics: {'avg_train_loss': 0.10903258521179134, 'avg_test_loss': 0.06059728937869154}
INFO:model_data_nn.py:Epoch 82/100, metrics: {'avg_train_loss': 0.10901109685556397, 'avg_test_loss': 0.05820907236281913}
INFO:model_data_nn.py:Epoch 83/100, metrics: {'avg_train_loss': 0.10902911186336128, 'avg_test_loss': 0.058622911543557005}
INFO:model_data_nn.py:Epoch 84/100, metrics: {'avg_train_loss': 0.10902770085947185, 'avg_test_loss': 0.056843053328148166}
INFO:model_data_nn.py:Epoch 85/100, metrics: {'avg_train_loss': 0.10902482995771035, 'avg_test_loss': 0.061613214890356996}
INFO:model_data_nn.py:Epoch 86/100, metrics: {'avg_train_loss': 0.10902690145574004, 'avg_test_loss': 0.05682325845342173}
INFO:model_data_nn.py:Epoch 87/100, metrics: {'avg_train_loss': 0.10902548085840026, 'avg_test_loss': 0.05589877959696327}
INFO:model_data_nn.py:Epoch 88/100, metrics: {'avg_train_loss': 0.10901852332156611, 'avg_test_loss': 0.05756651531507979}
INFO:model_data_nn.py:Epoch 89/100, metrics: {'avg_train_loss': 0.10903419253339805, 'avg_test_loss': 0.05841940054800841}
INFO:model_data_nn.py:Epoch 90/100, metrics: {'avg_train_loss': 0.10902522149051999, 'avg_test_loss': 0.05945872520511006}
INFO:model_data_nn.py:Epoch 91/100, metrics: {'avg_train_loss': 0.10902650573468056, 'avg_test_loss': 0.05617175099278519}
INFO:model_data_nn.py:Epoch 92/100, metrics: {'avg_train_loss': 0.10903000280304853, 'avg_test_loss': 0.05715692619383073}
INFO:model_data_nn.py:Epoch 93/100, metrics: {'avg_train_loss': 0.10902277781796353, 'avg_test_loss': 0.055560048641767834}
INFO:model_data_nn.py:Epoch 94/100, metrics: {'avg_train_loss': 0.10900987558893158, 'avg_test_loss': 0.05837830363836061}
INFO:model_data_nn.py:Epoch 95/100, metrics: {'avg_train_loss': 0.1090228010891295, 'avg_test_loss': 0.05551016060864461}
INFO:model_data_nn.py:Epoch 96/100, metrics: {'avg_train_loss': 0.10903245290798075, 'avg_test_loss': 0.055194085900643425}
INFO:model_data_nn.py:Epoch 97/100, metrics: {'avg_train_loss': 0.10900675462219428, 'avg_test_loss': 0.05862293138323609}
INFO:model_data_nn.py:Epoch 98/100, metrics: {'avg_train_loss': 0.10902985327823494, 'avg_test_loss': 0.05868591070425996}
INFO:model_data_nn.py:Epoch 99/100, metrics: {'avg_train_loss': 0.10903306700275621, 'avg_test_loss': 0.05654866342973706}
INFO:model_data_nn.py:Epoch 100/100, metrics: {'avg_train_loss': 0.10903635504030008, 'avg_test_loss': 0.058222278104157164}
INFO:model_data_nn.py:Early stopping at epoch 100
INFO:main_restricted.py:Making prediction for data in year: 2013
INFO:main_restricted.py:Prediction data shape: (13650,)
/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/src/main_restricted.py:332: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  prediction_data['pred'] = predictions
INFO:main_restricted.py:Root Mean Squared Error for Prediction in 2013: 0.2413027775661718
INFO:main_restricted.py:Prediction Stats:                retq          pred
count  13650.000000  13650.000000
mean       0.095489      0.034142
std        0.233383      0.000000
min       -0.927594      0.034142
25%       -0.012730      0.034142
50%        0.068853      0.034142
75%        0.174490      0.034142
max        3.696775      0.034142

 Configuration for experiment     train_fnn_2024-08-13_14-49-50   

 Search algorithm                 BasicVariantGenerator           
 Scheduler                        AsyncHyperBandScheduler         
 Number of trials                 150                             


View detailed results here: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-13_14-49-50
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-08-13_14-49-45_079161_1685331/artifacts/2024-08-13_14-49-50/train_fnn_2024-08-13_14-49-50/driver_artifacts`


 Configuration for experiment     train_fnn_2024-08-13_16-35-49   

 Search algorithm                 BasicVariantGenerator           
 Scheduler                        AsyncHyperBandScheduler         
 Number of trials                 150                             


View detailed results here: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-13_16-35-49
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-08-13_16-35-45_712615_1685331/artifacts/2024-08-13_16-35-49/train_fnn_2024-08-13_16-35-49/driver_artifacts`


 Configuration for experiment     train_fnn_2024-08-13_17-55-04   

 Search algorithm                 BasicVariantGenerator           
 Scheduler                        AsyncHyperBandScheduler         
 Number of trials                 150                             


View detailed results here: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-13_17-55-04
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-08-13_17-54-59_824337_1685331/artifacts/2024-08-13_17-55-04/train_fnn_2024-08-13_17-55-04/driver_artifacts`


 Configuration for experiment     train_fnn_2024-08-13_20-33-19   

 Search algorithm                 BasicVariantGenerator           
 Scheduler                        AsyncHyperBandScheduler         
 Number of trials                 150                             


View detailed results here: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-13_20-33-19
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-08-13_20-33-14_679713_1685331/artifacts/2024-08-13_20-33-19/train_fnn_2024-08-13_20-33-19/driver_artifacts`


 Configuration for experiment     train_fnn_2024-08-14_00-14-31   

 Search algorithm                 BasicVariantGenerator           
 Scheduler                        AsyncHyperBandScheduler         
 Number of trials                 150                             


View detailed results here: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-14_00-14-31
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-08-14_00-14-27_036021_1685331/artifacts/2024-08-14_00-14-31/train_fnn_2024-08-14_00-14-31/driver_artifacts`


 Configuration for experiment     train_fnn_2024-08-14_08-13-39   

 Search algorithm                 BasicVariantGenerator           
 Scheduler                        AsyncHyperBandScheduler         
 Number of trials                 150                             


View detailed results here: /zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/ray_results/train_fnn_2024-08-14_08-13-39
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-08-14_08-13-34_289367_1685331/artifacts/2024-08-14_08-13-39/train_fnn_2024-08-14_08-13-39/driver_artifacts`

INFO:postprocess_predictions.py:Post processing prediction files
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1985.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1986.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1987.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1988.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1989.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1990.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1991.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1992.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1993.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1994.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1995.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1996.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1997.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1998.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_1999.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2000.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2001.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2002.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2003.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2004.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2005.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2006.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2007.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2008.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2009.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2010.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2011.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2012.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2013.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2014.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2015.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2016.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2017.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2018.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2019.csv
INFO:postprocess_predictions.py:Postprocessing data from path: kevin/output/prediction/quarterly_new_restricted/quarterly_prediction_2020.csv
INFO:postprocess_predictions.py:Sort the result by date and rank both ascendingly
INFO:postprocess_predictions.py:Saved the result file: result.csv
to the directory: kevin/output/prediction/quarterly_new_restricted
