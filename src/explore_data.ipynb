{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa1d1dec-85a8-428b-a95f-3afa2ba20878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee384ec1-90f5-45ee-942d-7344fdb3d637",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5b4d4f-0026-41cf-b2c0-a3d22e0a41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c54ac0-f43e-4205-a34d-ee76ab6775fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare global variables\n",
    "global con_list\n",
    "global dum_list\n",
    "global deps\n",
    "global header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6beb749f-dbab-45ec-9612-f54db61550bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of continuous variables\n",
    "con_list = ['absacc', 'acc', 'aeavol', 'age', 'agr', 'baspread', 'beta', \n",
    "            'betasq', 'bm', 'bm_ia', 'cash', 'cashdebt', 'cashpr','cfp', \n",
    "            'cfp_ia', 'chatoia', 'chcsho', 'chempia', 'chfeps', 'chinv', \n",
    "            'chmom', 'chnanalyst', 'chpmia', 'chtx', 'cinvest', 'currat', \n",
    "            'depr', 'disp', 'dolvol', 'dy', 'ear', 'egr', 'ep', 'fgr5yr', \n",
    "            'gma', 'grcapx', 'grltnoa', 'herf', 'hire', 'idiovol', 'ill', \n",
    "            'indmom', 'invest', 'lev', 'lgr', 'maxret', 'mom12m', 'mom1m', \n",
    "            'mom36m', 'mom6m', 'ms', 'mve', 'mve_ia', 'nanalyst', 'nincr', \n",
    "            'operprof', 'orgcap', 'pchcapx_ia', 'pchcurrat', 'pchdepr', \n",
    "            'pchgm_pchsale', 'pchquick', 'pchsale_pchinvt', 'pchsale_pchrect', \n",
    "            'pchsale_pchxsga', 'pchsaleinv', 'pctacc', 'pricedelay', 'ps', \n",
    "            'quick', 'rd_mve', 'rd_sale', 'realestate', 'retvol', 'roaq', \n",
    "            'roavol', 'roeq', 'roic', 'rsup', 'salecash', 'saleinv', \n",
    "            'salerec', 'secured', 'sfe', 'sgr', 'sp', 'std_dolvol', \n",
    "            'std_turn', 'stdacc', 'stdcf', 'sue', 'tang', 'tb', 'turn', \n",
    "            'zerotrade']\n",
    "\n",
    "\n",
    "# List of dummy variables\n",
    "dum_list = ['convind', 'divi', 'divo', 'ipo', 'rd', 'securedind', 'sin'] # Categorical variable binary \n",
    "\n",
    "# List of dependent variable\n",
    "deps = con_list + dum_list +['date']\n",
    "\n",
    "# Headers\n",
    "header = ['permno','pyear']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71e677b-814b-42b6-9137-270a8dc05524",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149cff4b-9c5f-43fe-b566-ea32997cab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path, period):\n",
    "    \n",
    "    \"\"\"\n",
    "    Loads and preprocesses the input data.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The path to the CSV file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Preprocessed pandas DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = [e.lower() for e in df.columns]\n",
    "    \n",
    "    df['date'] = df['date'].copy()\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n",
    "    # df['date'] = df['date'].dt.strftime('%m-%d-%Y')\n",
    "\n",
    "    # Extract year\n",
    "    df['pyear'] = df['date'].dt.year\n",
    "    # Remove months if quarterly, otherwise, monthly, keep all months\n",
    "    if period == 'quarter':\n",
    "        df = df[df['date'].dt.month.isin([1,4,7,10])]\n",
    "\n",
    "    # df.sort_values(['permno','date'], inplace=True)\n",
    "    df.sort_values(['date', 'permno'], inplace=True)\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m')\n",
    "    del df['fpedats']\n",
    "    \n",
    "    print(df[['date', 'permno']].head())\n",
    "    print('-' * 50)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13cf36fd-32cb-4d0c-a9d0-6ad86784d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWinsorizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"\n",
    "    A custom transformer for Winsorizing numeric data.\n",
    "\n",
    "    Attributes:\n",
    "    lower_percentile (int): The lower percentile for clipping data.\n",
    "    upper_percentile (int): The upper percentile for clipping data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lower_percentile, upper_percentile):\n",
    "        self.lower_percentile = lower_percentile\n",
    "        self.upper_percentile = upper_percentile\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.lower_bound_ = np.percentile(X, self.lower_percentile)\n",
    "        self.upper_bound_ = np.percentile(X, self.upper_percentile)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_clipped = np.clip(X, self.lower_bound_, self.upper_bound_)\n",
    "        \n",
    "        return X_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c78d2ff7-2147-45c5-848c-18d64d93b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timePeriodMeanTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"\n",
    "    A custom transformer for imputing missing data based on time period means.\n",
    "\n",
    "    Attributes:\n",
    "    date_column (str): The column name representing dates.\n",
    "    numeric_columns (list): List of numeric column names for which means are calculated.\n",
    "    period (str): The time period for grouping data, either 'quarter' or 'month'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, date_column, numeric_columns, period='quarter'):\n",
    "        self.date_column = date_column\n",
    "        self.numeric_columns = numeric_columns\n",
    "        self.period = period\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X[self.date_column] = pd.to_datetime(X[self.date_column])\n",
    "        if self.period == 'quarter':\n",
    "            X['Period'] = X[self.date_column].dt.quarter\n",
    "        elif self.period == 'month':\n",
    "            X['Period'] = X[self.date_column].dt.month\n",
    "        else:\n",
    "            raise ValueError(\"period must be 'quarter' or 'month'\")\n",
    "       \n",
    "       # Calculate and store the means of each numeric column for each time period\n",
    "        self.period_means_ = X.groupby('Period')[self.numeric_columns].mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[self.date_column] = pd.to_datetime(X[self.date_column])\n",
    "        if self.period == 'quarter':\n",
    "            X['Period'] = X[self.date_column].dt.quarter\n",
    "        elif self.period == 'month':\n",
    "            X['Period'] = X[self.date_column].dt.month\n",
    "        \n",
    "        for col in self.numeric_columns:\n",
    "            X[col] = X.apply(lambda row: row[col] if not pd.isna(row[col]) \n",
    "                             else self.period_means_.loc[row['Period'], col], axis=1)\n",
    "        # return X.drop(['Period'], axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99182d02-1d06-4258-abda-a3566a10dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(con_list, dum_list, lower_percentile, upper_percentile, period):\n",
    "    \n",
    "    \"\"\"\n",
    "    Builds a preprocessing pipeline for both numeric and categorical data.\n",
    "\n",
    "    Args:\n",
    "    con_list (list): List of continuous variable names.\n",
    "    dum_list (list): List of dummy (categorical) variable names.\n",
    "    lower_percentile (float): Lower percentile for winsorization.\n",
    "    upper_percentile (float): Upper percentile for winsorization.\n",
    "    period (string): Period for getting mean values (month vs quarter)\n",
    "\n",
    "    Returns:\n",
    "    Pipeline: A composed preprocessing pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    numeric_pipeline = Pipeline([\n",
    "        # ('fill_na', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)),\n",
    "        ('winsorizer', CustomWinsorizer(lower_percentile=lower_percentile, upper_percentile=upper_percentile)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('impute_con', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0))\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('impute_cat', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)),\n",
    "    ])\n",
    "\n",
    "    preprocessing = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_pipeline, con_list),\n",
    "            ('cat', categorical_pipeline, dum_list)\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('Time_period_mean_imputation', timePeriodMeanTransformer('date', con_list, period)),\n",
    "        ('Preprocessing', preprocessing),\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d3b469-3062-44af-95f7-80e8af10ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_path = 'Info Processing and Mutual Funds/masterv14.csv'\n",
    "period = 'month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd7e8f7-df1f-46e3-83bf-a3f800a98de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if period == 'quarter':\n",
    "    target = 'retq'\n",
    "elif period == 'month':\n",
    "    target = 'ret'\n",
    "else:\n",
    "    raise ValueError(\"period must be 'quarter' or 'month'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b2bc2f-14db-4965-add8-4c651fdc8175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and preprocessing data...\n",
      "\n",
      "      date  permno\n",
      "0  1980-01   10006\n",
      "1  1980-01   10057\n",
      "2  1980-01   10103\n",
      "3  1980-01   10137\n",
      "4  1980-01   10145\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "print('\\nLoading and preprocessing data...\\n')\n",
    "df = load_and_preprocess_data(infile_path, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b51617d-4f82-4e63-9a01-a5099bfb277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values in the target column and get years 2020 or prior\n",
    "df1 = df.dropna(subset=[target])\n",
    "df1 = df1[df1['pyear'] <= 2020]\n",
    "df1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "759cb5f5-5087-4c66-99a7-76ee89d6d023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>adatadate</th>\n",
       "      <th>fyear</th>\n",
       "      <th>sic2</th>\n",
       "      <th>spi</th>\n",
       "      <th>mve_f</th>\n",
       "      <th>bm</th>\n",
       "      <th>ep</th>\n",
       "      <th>cashpr</th>\n",
       "      <th>...</th>\n",
       "      <th>std_dolvol</th>\n",
       "      <th>std_turn</th>\n",
       "      <th>ill</th>\n",
       "      <th>zerotrade</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>rsq1</th>\n",
       "      <th>pricedelay</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>pyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>1010</td>\n",
       "      <td>12/31/1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>269.308500</td>\n",
       "      <td>1.180962</td>\n",
       "      <td>0.153022</td>\n",
       "      <td>-32.218678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881844</td>\n",
       "      <td>0.635898</td>\n",
       "      <td>2.565667e-08</td>\n",
       "      <td>1.115306e-07</td>\n",
       "      <td>1.060420</td>\n",
       "      <td>1.124491</td>\n",
       "      <td>0.343408</td>\n",
       "      <td>0.029859</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10057</td>\n",
       "      <td>1098</td>\n",
       "      <td>09/30/1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>97.372000</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>0.135131</td>\n",
       "      <td>-4.408581</td>\n",
       "      <td>...</td>\n",
       "      <td>1.368363</td>\n",
       "      <td>2.546787</td>\n",
       "      <td>2.719812e-07</td>\n",
       "      <td>6.199128e-08</td>\n",
       "      <td>1.526013</td>\n",
       "      <td>2.328716</td>\n",
       "      <td>0.307905</td>\n",
       "      <td>0.092667</td>\n",
       "      <td>0.037473</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.697500</td>\n",
       "      <td>3.362003</td>\n",
       "      <td>0.338144</td>\n",
       "      <td>-17.143817</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.759493</td>\n",
       "      <td>3.095816</td>\n",
       "      <td>0.096753</td>\n",
       "      <td>0.221851</td>\n",
       "      <td>0.087020</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10137</td>\n",
       "      <td>1279</td>\n",
       "      <td>12/31/1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537.524500</td>\n",
       "      <td>1.330341</td>\n",
       "      <td>0.153238</td>\n",
       "      <td>-87.819837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553246</td>\n",
       "      <td>0.740017</td>\n",
       "      <td>1.765620e-08</td>\n",
       "      <td>9.726790e-08</td>\n",
       "      <td>0.492885</td>\n",
       "      <td>0.242936</td>\n",
       "      <td>0.189693</td>\n",
       "      <td>0.125777</td>\n",
       "      <td>0.017540</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10145</td>\n",
       "      <td>1300</td>\n",
       "      <td>12/31/1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>99</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>805.633282</td>\n",
       "      <td>1.579284</td>\n",
       "      <td>0.149248</td>\n",
       "      <td>-22.050470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427617</td>\n",
       "      <td>0.657563</td>\n",
       "      <td>2.898901e-09</td>\n",
       "      <td>6.190654e-08</td>\n",
       "      <td>1.139163</td>\n",
       "      <td>1.297691</td>\n",
       "      <td>0.279437</td>\n",
       "      <td>0.024228</td>\n",
       "      <td>0.031201</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165510</th>\n",
       "      <td>93422</td>\n",
       "      <td>154357</td>\n",
       "      <td>12/31/2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.0090</td>\n",
       "      <td>1069.650000</td>\n",
       "      <td>2.487356</td>\n",
       "      <td>-0.090964</td>\n",
       "      <td>-14.117559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797001</td>\n",
       "      <td>12.233361</td>\n",
       "      <td>7.505129e-09</td>\n",
       "      <td>5.571619e-09</td>\n",
       "      <td>2.691027</td>\n",
       "      <td>7.241625</td>\n",
       "      <td>0.265207</td>\n",
       "      <td>0.257939</td>\n",
       "      <td>0.132692</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165511</th>\n",
       "      <td>93423</td>\n",
       "      <td>10567</td>\n",
       "      <td>12/31/2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>3817.839740</td>\n",
       "      <td>-0.187572</td>\n",
       "      <td>0.046902</td>\n",
       "      <td>19.464647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519033</td>\n",
       "      <td>17.649093</td>\n",
       "      <td>4.462048e-10</td>\n",
       "      <td>3.803709e-09</td>\n",
       "      <td>1.921529</td>\n",
       "      <td>3.692274</td>\n",
       "      <td>0.485215</td>\n",
       "      <td>0.068369</td>\n",
       "      <td>0.061119</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165512</th>\n",
       "      <td>93426</td>\n",
       "      <td>185138</td>\n",
       "      <td>12/31/2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.0108</td>\n",
       "      <td>459.782000</td>\n",
       "      <td>0.524944</td>\n",
       "      <td>0.048258</td>\n",
       "      <td>1.095352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473367</td>\n",
       "      <td>2.144264</td>\n",
       "      <td>2.296462e-08</td>\n",
       "      <td>3.236729e-08</td>\n",
       "      <td>1.302016</td>\n",
       "      <td>1.695247</td>\n",
       "      <td>0.472220</td>\n",
       "      <td>0.037482</td>\n",
       "      <td>0.043174</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165513</th>\n",
       "      <td>93434</td>\n",
       "      <td>184259</td>\n",
       "      <td>06/30/2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1349</td>\n",
       "      <td>87.853920</td>\n",
       "      <td>1.138777</td>\n",
       "      <td>-0.105914</td>\n",
       "      <td>-13.505851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935967</td>\n",
       "      <td>0.897075</td>\n",
       "      <td>3.435272e-07</td>\n",
       "      <td>1.037670e-07</td>\n",
       "      <td>0.389842</td>\n",
       "      <td>0.151977</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>-0.694649</td>\n",
       "      <td>0.073887</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165514</th>\n",
       "      <td>93436</td>\n",
       "      <td>184996</td>\n",
       "      <td>12/31/2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>75717.730000</td>\n",
       "      <td>0.087404</td>\n",
       "      <td>-0.011384</td>\n",
       "      <td>8.295322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531632</td>\n",
       "      <td>18.110463</td>\n",
       "      <td>1.820359e-12</td>\n",
       "      <td>2.654462e-09</td>\n",
       "      <td>1.349577</td>\n",
       "      <td>1.821357</td>\n",
       "      <td>0.207462</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.083041</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2165515 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         permno   gvkey   adatadate  fyear  sic2     spi         mve_f  \\\n",
       "0         10006    1010  12/31/1978   1978    37  0.0000    269.308500   \n",
       "1         10057    1098  09/30/1978   1978    36  0.0000     97.372000   \n",
       "2         10103    1012  10/31/1978   1978    33     NaN      1.697500   \n",
       "3         10137    1279  12/31/1978   1978    49     NaN    537.524500   \n",
       "4         10145    1300  12/31/1978   1978    99 -0.0031    805.633282   \n",
       "...         ...     ...         ...    ...   ...     ...           ...   \n",
       "2165510   93422  154357  12/31/2019   2019    13 -0.0090   1069.650000   \n",
       "2165511   93423   10567  12/31/2019   2019    79  0.0004   3817.839740   \n",
       "2165512   93426  185138  12/31/2019   2019    36 -0.0108    459.782000   \n",
       "2165513   93434  184259  06/30/2019   2019     1 -0.1349     87.853920   \n",
       "2165514   93436  184996  12/31/2019   2019    37 -0.0047  75717.730000   \n",
       "\n",
       "               bm        ep     cashpr  ...  std_dolvol   std_turn  \\\n",
       "0        1.180962  0.153022 -32.218678  ...    0.881844   0.635898   \n",
       "1        0.956692  0.135131  -4.408581  ...    1.368363   2.546787   \n",
       "2        3.362003  0.338144 -17.143817  ...         NaN        NaN   \n",
       "3        1.330341  0.153238 -87.819837  ...    0.553246   0.740017   \n",
       "4        1.579284  0.149248 -22.050470  ...    0.427617   0.657563   \n",
       "...           ...       ...        ...  ...         ...        ...   \n",
       "2165510  2.487356 -0.090964 -14.117559  ...    0.797001  12.233361   \n",
       "2165511 -0.187572  0.046902  19.464647  ...    0.519033  17.649093   \n",
       "2165512  0.524944  0.048258   1.095352  ...    0.473367   2.144264   \n",
       "2165513  1.138777 -0.105914 -13.505851  ...    0.935967   0.897075   \n",
       "2165514  0.087404 -0.011384   8.295322  ...    0.531632  18.110463   \n",
       "\n",
       "                  ill     zerotrade      beta    betasq      rsq1  pricedelay  \\\n",
       "0        2.565667e-08  1.115306e-07  1.060420  1.124491  0.343408    0.029859   \n",
       "1        2.719812e-07  6.199128e-08  1.526013  2.328716  0.307905    0.092667   \n",
       "2                 NaN           NaN  1.759493  3.095816  0.096753    0.221851   \n",
       "3        1.765620e-08  9.726790e-08  0.492885  0.242936  0.189693    0.125777   \n",
       "4        2.898901e-09  6.190654e-08  1.139163  1.297691  0.279437    0.024228   \n",
       "...               ...           ...       ...       ...       ...         ...   \n",
       "2165510  7.505129e-09  5.571619e-09  2.691027  7.241625  0.265207    0.257939   \n",
       "2165511  4.462048e-10  3.803709e-09  1.921529  3.692274  0.485215    0.068369   \n",
       "2165512  2.296462e-08  3.236729e-08  1.302016  1.695247  0.472220    0.037482   \n",
       "2165513  3.435272e-07  1.037670e-07  0.389842  0.151977  0.021429   -0.694649   \n",
       "2165514  1.820359e-12  2.654462e-09  1.349577  1.821357  0.207462    0.027211   \n",
       "\n",
       "          idiovol  pyear  \n",
       "0        0.025576   1980  \n",
       "1        0.037473   1980  \n",
       "2        0.087020   1980  \n",
       "3        0.017540   1980  \n",
       "4        0.031201   1980  \n",
       "...           ...    ...  \n",
       "2165510  0.132692   2020  \n",
       "2165511  0.061119   2020  \n",
       "2165512  0.043174   2020  \n",
       "2165513  0.073887   2020  \n",
       "2165514  0.083041   2020  \n",
       "\n",
       "[2165515 rows x 158 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "396cfefd-08e2-44ea-be14-fc0092c8b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df1.loc[df1['permno']==10103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01b04f7f-4b49-4c5a-a59c-ef16303167a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10103</td>\n",
       "      <td>1980-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>10103</td>\n",
       "      <td>1980-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6932</th>\n",
       "      <td>10103</td>\n",
       "      <td>1980-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441</th>\n",
       "      <td>10103</td>\n",
       "      <td>1980-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13941</th>\n",
       "      <td>10103</td>\n",
       "      <td>1980-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479711</th>\n",
       "      <td>10103</td>\n",
       "      <td>1989-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484311</th>\n",
       "      <td>10103</td>\n",
       "      <td>1989-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488942</th>\n",
       "      <td>10103</td>\n",
       "      <td>1989-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493659</th>\n",
       "      <td>10103</td>\n",
       "      <td>1989-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498362</th>\n",
       "      <td>10103</td>\n",
       "      <td>1989-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        permno     date\n",
       "2        10103  1980-01\n",
       "3462     10103  1980-02\n",
       "6932     10103  1980-03\n",
       "10441    10103  1980-04\n",
       "13941    10103  1980-05\n",
       "...        ...      ...\n",
       "479711   10103  1989-07\n",
       "484311   10103  1989-08\n",
       "488942   10103  1989-09\n",
       "493659   10103  1989-10\n",
       "498362   10103  1989-11\n",
       "\n",
       "[119 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[['permno', 'date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f42a7b-4be0-4ef0-beb4-60d50bd4f4d2",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b1101b7-ed38-4fc8-a68b-43569e30e8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training in progress...\\n')\n",
    "# Build a training pipeline\n",
    "pipeline = build_pipeline(con_list, dum_list, 5, 95, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa12eebe-1bf5-41cb-9751-0d9ae9dc1f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Time_period_mean_imputation&#x27;,\n",
       "                 timePeriodMeanTransformer(date_column=&#x27;date&#x27;,\n",
       "                                           numeric_columns=[&#x27;absacc&#x27;, &#x27;acc&#x27;,\n",
       "                                                            &#x27;aeavol&#x27;, &#x27;age&#x27;,\n",
       "                                                            &#x27;agr&#x27;, &#x27;baspread&#x27;,\n",
       "                                                            &#x27;beta&#x27;, &#x27;betasq&#x27;,\n",
       "                                                            &#x27;bm&#x27;, &#x27;bm_ia&#x27;,\n",
       "                                                            &#x27;cash&#x27;, &#x27;cashdebt&#x27;,\n",
       "                                                            &#x27;cashpr&#x27;, &#x27;cfp&#x27;,\n",
       "                                                            &#x27;cfp_ia&#x27;, &#x27;chatoia&#x27;,\n",
       "                                                            &#x27;chcsho&#x27;, &#x27;chempia&#x27;,\n",
       "                                                            &#x27;chfeps&#x27;, &#x27;chinv&#x27;,\n",
       "                                                            &#x27;chmom&#x27;,\n",
       "                                                            &#x27;chnanalyst&#x27;,\n",
       "                                                            &#x27;chpmia&#x27;, &#x27;chtx&#x27;,\n",
       "                                                            &#x27;cinvest&#x27;, &#x27;currat&#x27;,\n",
       "                                                            &#x27;depr&#x27;, &#x27;disp&#x27;,\n",
       "                                                            &#x27;dolvol...\n",
       "                                                   &#x27;beta&#x27;, &#x27;betasq&#x27;, &#x27;bm&#x27;,\n",
       "                                                   &#x27;bm_ia&#x27;, &#x27;cash&#x27;, &#x27;cashdebt&#x27;,\n",
       "                                                   &#x27;cashpr&#x27;, &#x27;cfp&#x27;, &#x27;cfp_ia&#x27;,\n",
       "                                                   &#x27;chatoia&#x27;, &#x27;chcsho&#x27;,\n",
       "                                                   &#x27;chempia&#x27;, &#x27;chfeps&#x27;, &#x27;chinv&#x27;,\n",
       "                                                   &#x27;chmom&#x27;, &#x27;chnanalyst&#x27;,\n",
       "                                                   &#x27;chpmia&#x27;, &#x27;chtx&#x27;, &#x27;cinvest&#x27;,\n",
       "                                                   &#x27;currat&#x27;, &#x27;depr&#x27;, &#x27;disp&#x27;,\n",
       "                                                   &#x27;dolvol&#x27;, &#x27;dy&#x27;, ...]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute_cat&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy=&#x27;constant&#x27;))]),\n",
       "                                                  [&#x27;convind&#x27;, &#x27;divi&#x27;, &#x27;divo&#x27;,\n",
       "                                                   &#x27;ipo&#x27;, &#x27;rd&#x27;, &#x27;securedind&#x27;,\n",
       "                                                   &#x27;sin&#x27;])]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;Time_period_mean_imputation&#x27;,\n",
       "                 timePeriodMeanTransformer(date_column=&#x27;date&#x27;,\n",
       "                                           numeric_columns=[&#x27;absacc&#x27;, &#x27;acc&#x27;,\n",
       "                                                            &#x27;aeavol&#x27;, &#x27;age&#x27;,\n",
       "                                                            &#x27;agr&#x27;, &#x27;baspread&#x27;,\n",
       "                                                            &#x27;beta&#x27;, &#x27;betasq&#x27;,\n",
       "                                                            &#x27;bm&#x27;, &#x27;bm_ia&#x27;,\n",
       "                                                            &#x27;cash&#x27;, &#x27;cashdebt&#x27;,\n",
       "                                                            &#x27;cashpr&#x27;, &#x27;cfp&#x27;,\n",
       "                                                            &#x27;cfp_ia&#x27;, &#x27;chatoia&#x27;,\n",
       "                                                            &#x27;chcsho&#x27;, &#x27;chempia&#x27;,\n",
       "                                                            &#x27;chfeps&#x27;, &#x27;chinv&#x27;,\n",
       "                                                            &#x27;chmom&#x27;,\n",
       "                                                            &#x27;chnanalyst&#x27;,\n",
       "                                                            &#x27;chpmia&#x27;, &#x27;chtx&#x27;,\n",
       "                                                            &#x27;cinvest&#x27;, &#x27;currat&#x27;,\n",
       "                                                            &#x27;depr&#x27;, &#x27;disp&#x27;,\n",
       "                                                            &#x27;dolvol...\n",
       "                                                   &#x27;beta&#x27;, &#x27;betasq&#x27;, &#x27;bm&#x27;,\n",
       "                                                   &#x27;bm_ia&#x27;, &#x27;cash&#x27;, &#x27;cashdebt&#x27;,\n",
       "                                                   &#x27;cashpr&#x27;, &#x27;cfp&#x27;, &#x27;cfp_ia&#x27;,\n",
       "                                                   &#x27;chatoia&#x27;, &#x27;chcsho&#x27;,\n",
       "                                                   &#x27;chempia&#x27;, &#x27;chfeps&#x27;, &#x27;chinv&#x27;,\n",
       "                                                   &#x27;chmom&#x27;, &#x27;chnanalyst&#x27;,\n",
       "                                                   &#x27;chpmia&#x27;, &#x27;chtx&#x27;, &#x27;cinvest&#x27;,\n",
       "                                                   &#x27;currat&#x27;, &#x27;depr&#x27;, &#x27;disp&#x27;,\n",
       "                                                   &#x27;dolvol&#x27;, &#x27;dy&#x27;, ...]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute_cat&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy=&#x27;constant&#x27;))]),\n",
       "                                                  [&#x27;convind&#x27;, &#x27;divi&#x27;, &#x27;divo&#x27;,\n",
       "                                                   &#x27;ipo&#x27;, &#x27;rd&#x27;, &#x27;securedind&#x27;,\n",
       "                                                   &#x27;sin&#x27;])]))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">timePeriodMeanTransformer</label><div class=\"sk-toggleable__content \"><pre>timePeriodMeanTransformer(date_column=&#x27;date&#x27;,\n",
       "                          numeric_columns=[&#x27;absacc&#x27;, &#x27;acc&#x27;, &#x27;aeavol&#x27;, &#x27;age&#x27;,\n",
       "                                           &#x27;agr&#x27;, &#x27;baspread&#x27;, &#x27;beta&#x27;, &#x27;betasq&#x27;,\n",
       "                                           &#x27;bm&#x27;, &#x27;bm_ia&#x27;, &#x27;cash&#x27;, &#x27;cashdebt&#x27;,\n",
       "                                           &#x27;cashpr&#x27;, &#x27;cfp&#x27;, &#x27;cfp_ia&#x27;, &#x27;chatoia&#x27;,\n",
       "                                           &#x27;chcsho&#x27;, &#x27;chempia&#x27;, &#x27;chfeps&#x27;,\n",
       "                                           &#x27;chinv&#x27;, &#x27;chmom&#x27;, &#x27;chnanalyst&#x27;,\n",
       "                                           &#x27;chpmia&#x27;, &#x27;chtx&#x27;, &#x27;cinvest&#x27;,\n",
       "                                           &#x27;currat&#x27;, &#x27;depr&#x27;, &#x27;disp&#x27;, &#x27;dolvol&#x27;,\n",
       "                                           &#x27;dy&#x27;, ...],\n",
       "                          period=&#x27;month&#x27;)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;Preprocessing: ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for Preprocessing: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;winsorizer&#x27;,\n",
       "                                                  CustomWinsorizer(lower_percentile=5,\n",
       "                                                                   upper_percentile=95)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                                 (&#x27;impute_con&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;))]),\n",
       "                                 [&#x27;absacc&#x27;, &#x27;acc&#x27;, &#x27;aeavol&#x27;, &#x27;age&#x27;, &#x27;agr&#x27;,\n",
       "                                  &#x27;baspread&#x27;, &#x27;beta&#x27;, &#x27;betasq&#x27;, &#x27;bm&#x27;, &#x27;bm_ia&#x27;,\n",
       "                                  &#x27;cash&#x27;, &#x27;cashdebt&#x27;, &#x27;cashpr&#x27;, &#x27;cfp&#x27;, &#x27;cfp_ia&#x27;,\n",
       "                                  &#x27;chatoia&#x27;, &#x27;chcsho&#x27;, &#x27;chempia&#x27;, &#x27;chfeps&#x27;,\n",
       "                                  &#x27;chinv&#x27;, &#x27;chmom&#x27;, &#x27;chnanalyst&#x27;, &#x27;chpmia&#x27;,\n",
       "                                  &#x27;chtx&#x27;, &#x27;cinvest&#x27;, &#x27;currat&#x27;, &#x27;depr&#x27;, &#x27;disp&#x27;,\n",
       "                                  &#x27;dolvol&#x27;, &#x27;dy&#x27;, ...]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute_cat&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;))]),\n",
       "                                 [&#x27;convind&#x27;, &#x27;divi&#x27;, &#x27;divo&#x27;, &#x27;ipo&#x27;, &#x27;rd&#x27;,\n",
       "                                  &#x27;securedind&#x27;, &#x27;sin&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">num</label><div class=\"sk-toggleable__content \"><pre>[&#x27;absacc&#x27;, &#x27;acc&#x27;, &#x27;aeavol&#x27;, &#x27;age&#x27;, &#x27;agr&#x27;, &#x27;baspread&#x27;, &#x27;beta&#x27;, &#x27;betasq&#x27;, &#x27;bm&#x27;, &#x27;bm_ia&#x27;, &#x27;cash&#x27;, &#x27;cashdebt&#x27;, &#x27;cashpr&#x27;, &#x27;cfp&#x27;, &#x27;cfp_ia&#x27;, &#x27;chatoia&#x27;, &#x27;chcsho&#x27;, &#x27;chempia&#x27;, &#x27;chfeps&#x27;, &#x27;chinv&#x27;, &#x27;chmom&#x27;, &#x27;chnanalyst&#x27;, &#x27;chpmia&#x27;, &#x27;chtx&#x27;, &#x27;cinvest&#x27;, &#x27;currat&#x27;, &#x27;depr&#x27;, &#x27;disp&#x27;, &#x27;dolvol&#x27;, &#x27;dy&#x27;, &#x27;ear&#x27;, &#x27;egr&#x27;, &#x27;ep&#x27;, &#x27;fgr5yr&#x27;, &#x27;gma&#x27;, &#x27;grcapx&#x27;, &#x27;grltnoa&#x27;, &#x27;herf&#x27;, &#x27;hire&#x27;, &#x27;idiovol&#x27;, &#x27;ill&#x27;, &#x27;indmom&#x27;, &#x27;invest&#x27;, &#x27;lev&#x27;, &#x27;lgr&#x27;, &#x27;maxret&#x27;, &#x27;mom12m&#x27;, &#x27;mom1m&#x27;, &#x27;mom36m&#x27;, &#x27;mom6m&#x27;, &#x27;ms&#x27;, &#x27;mve&#x27;, &#x27;mve_ia&#x27;, &#x27;nanalyst&#x27;, &#x27;nincr&#x27;, &#x27;operprof&#x27;, &#x27;orgcap&#x27;, &#x27;pchcapx_ia&#x27;, &#x27;pchcurrat&#x27;, &#x27;pchdepr&#x27;, &#x27;pchgm_pchsale&#x27;, &#x27;pchquick&#x27;, &#x27;pchsale_pchinvt&#x27;, &#x27;pchsale_pchrect&#x27;, &#x27;pchsale_pchxsga&#x27;, &#x27;pchsaleinv&#x27;, &#x27;pctacc&#x27;, &#x27;pricedelay&#x27;, &#x27;ps&#x27;, &#x27;quick&#x27;, &#x27;rd_mve&#x27;, &#x27;rd_sale&#x27;, &#x27;realestate&#x27;, &#x27;retvol&#x27;, &#x27;roaq&#x27;, &#x27;roavol&#x27;, &#x27;roeq&#x27;, &#x27;roic&#x27;, &#x27;rsup&#x27;, &#x27;salecash&#x27;, &#x27;saleinv&#x27;, &#x27;salerec&#x27;, &#x27;secured&#x27;, &#x27;sfe&#x27;, &#x27;sgr&#x27;, &#x27;sp&#x27;, &#x27;std_dolvol&#x27;, &#x27;std_turn&#x27;, &#x27;stdacc&#x27;, &#x27;stdcf&#x27;, &#x27;sue&#x27;, &#x27;tang&#x27;, &#x27;tb&#x27;, &#x27;turn&#x27;, &#x27;zerotrade&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">CustomWinsorizer</label><div class=\"sk-toggleable__content \"><pre>CustomWinsorizer(lower_percentile=5, upper_percentile=95)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">cat</label><div class=\"sk-toggleable__content \"><pre>[&#x27;convind&#x27;, &#x27;divi&#x27;, &#x27;divo&#x27;, &#x27;ipo&#x27;, &#x27;rd&#x27;, &#x27;securedind&#x27;, &#x27;sin&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">remainder</label><div class=\"sk-toggleable__content \"><pre></pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">passthrough</label><div class=\"sk-toggleable__content \"><pre>passthrough</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Time_period_mean_imputation',\n",
       "                 timePeriodMeanTransformer(date_column='date',\n",
       "                                           numeric_columns=['absacc', 'acc',\n",
       "                                                            'aeavol', 'age',\n",
       "                                                            'agr', 'baspread',\n",
       "                                                            'beta', 'betasq',\n",
       "                                                            'bm', 'bm_ia',\n",
       "                                                            'cash', 'cashdebt',\n",
       "                                                            'cashpr', 'cfp',\n",
       "                                                            'cfp_ia', 'chatoia',\n",
       "                                                            'chcsho', 'chempia',\n",
       "                                                            'chfeps', 'chinv',\n",
       "                                                            'chmom',\n",
       "                                                            'chnanalyst',\n",
       "                                                            'chpmia', 'chtx',\n",
       "                                                            'cinvest', 'currat',\n",
       "                                                            'depr', 'disp',\n",
       "                                                            'dolvol...\n",
       "                                                   'beta', 'betasq', 'bm',\n",
       "                                                   'bm_ia', 'cash', 'cashdebt',\n",
       "                                                   'cashpr', 'cfp', 'cfp_ia',\n",
       "                                                   'chatoia', 'chcsho',\n",
       "                                                   'chempia', 'chfeps', 'chinv',\n",
       "                                                   'chmom', 'chnanalyst',\n",
       "                                                   'chpmia', 'chtx', 'cinvest',\n",
       "                                                   'currat', 'depr', 'disp',\n",
       "                                                   'dolvol', 'dy', ...]),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('impute_cat',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant'))]),\n",
       "                                                  ['convind', 'divi', 'divo',\n",
       "                                                   'ipo', 'rd', 'securedind',\n",
       "                                                   'sin'])]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7ee9346-4d3a-48aa-ba40-01876bf22a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set year range of the sample\n",
    "years = list(sample['pyear'].drop_duplicates().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1d745c2-9321-40df-8a7d-c68c8d9c21d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a141a7e-aa14-446a-8831-3de0fbbb6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dee710e1-779f-421e-8d60-836ea53d8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sample.loc[(sample['pyear']<=year)]\n",
    "test_data = sample.loc[(sample['pyear']==year+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "150838b3-3e02-4de7-b239-6faf19fc4bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Years: [1980, 1981, 1982, 1983, 1984, 1985, 1986]\n",
      "\n",
      "Testing Year: [1987]\n"
     ]
    }
   ],
   "source": [
    "# Training and testing data\n",
    "training_years = sorted(train_data.pyear.unique())\n",
    "print(f'Training Years: {training_years}\\n')\n",
    "print(f'Testing Year: {test_data.pyear.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418e2bca-401a-475f-a35d-3fe7a41ede7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>adatadate</th>\n",
       "      <th>fyear</th>\n",
       "      <th>sic2</th>\n",
       "      <th>spi</th>\n",
       "      <th>mve_f</th>\n",
       "      <th>bm</th>\n",
       "      <th>ep</th>\n",
       "      <th>cashpr</th>\n",
       "      <th>...</th>\n",
       "      <th>std_dolvol</th>\n",
       "      <th>std_turn</th>\n",
       "      <th>ill</th>\n",
       "      <th>zerotrade</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>rsq1</th>\n",
       "      <th>pricedelay</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>pyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.697500</td>\n",
       "      <td>3.362003</td>\n",
       "      <td>0.338144</td>\n",
       "      <td>-17.143817</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.759493</td>\n",
       "      <td>3.095816</td>\n",
       "      <td>0.096753</td>\n",
       "      <td>0.221851</td>\n",
       "      <td>0.087020</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.697500</td>\n",
       "      <td>3.362003</td>\n",
       "      <td>0.338144</td>\n",
       "      <td>-17.143817</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.736435</td>\n",
       "      <td>3.015207</td>\n",
       "      <td>0.088872</td>\n",
       "      <td>0.124053</td>\n",
       "      <td>0.090373</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6932</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.697500</td>\n",
       "      <td>3.362003</td>\n",
       "      <td>0.338144</td>\n",
       "      <td>-17.143817</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.546370</td>\n",
       "      <td>2.391259</td>\n",
       "      <td>0.065518</td>\n",
       "      <td>-0.026851</td>\n",
       "      <td>0.096490</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1978</td>\n",
       "      <td>1978</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.697500</td>\n",
       "      <td>3.362003</td>\n",
       "      <td>0.338144</td>\n",
       "      <td>-17.143817</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.544397</td>\n",
       "      <td>2.385163</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>0.024635</td>\n",
       "      <td>0.096057</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13941</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0537</td>\n",
       "      <td>1.196125</td>\n",
       "      <td>3.833059</td>\n",
       "      <td>-0.434737</td>\n",
       "      <td>-40.641964</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.353537</td>\n",
       "      <td>1.832062</td>\n",
       "      <td>0.069685</td>\n",
       "      <td>-0.237500</td>\n",
       "      <td>0.097406</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319599</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>3.654000</td>\n",
       "      <td>2.275041</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-20.234694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970630</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>4.102243e-06</td>\n",
       "      <td>12.409091</td>\n",
       "      <td>0.255926</td>\n",
       "      <td>0.065498</td>\n",
       "      <td>-0.004113</td>\n",
       "      <td>0.565691</td>\n",
       "      <td>0.070953</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324006</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>3.654000</td>\n",
       "      <td>2.275041</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-20.234694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693619</td>\n",
       "      <td>0.102686</td>\n",
       "      <td>4.734849e-06</td>\n",
       "      <td>13.000002</td>\n",
       "      <td>0.295377</td>\n",
       "      <td>0.087248</td>\n",
       "      <td>-0.003160</td>\n",
       "      <td>0.761472</td>\n",
       "      <td>0.071049</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328503</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>3.654000</td>\n",
       "      <td>2.275041</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-20.234694</td>\n",
       "      <td>...</td>\n",
       "      <td>1.260025</td>\n",
       "      <td>0.589355</td>\n",
       "      <td>6.410256e-07</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.311741</td>\n",
       "      <td>0.097183</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>0.756879</td>\n",
       "      <td>0.070830</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332973</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>3.654000</td>\n",
       "      <td>2.275041</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-20.234694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575778</td>\n",
       "      <td>0.242380</td>\n",
       "      <td>5.204745e-06</td>\n",
       "      <td>15.521740</td>\n",
       "      <td>0.402515</td>\n",
       "      <td>0.162018</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>1.071883</td>\n",
       "      <td>0.070324</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337415</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>3.654000</td>\n",
       "      <td>2.275041</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-20.234694</td>\n",
       "      <td>...</td>\n",
       "      <td>1.123405</td>\n",
       "      <td>0.597261</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>14.368422</td>\n",
       "      <td>0.394794</td>\n",
       "      <td>0.155862</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.067267</td>\n",
       "      <td>0.069506</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        permno  gvkey   adatadate  fyear  sic2     spi     mve_f        bm  \\\n",
       "2        10103   1012  10/31/1978   1978    33     NaN  1.697500  3.362003   \n",
       "3462     10103   1012  10/31/1978   1978    33     NaN  1.697500  3.362003   \n",
       "6932     10103   1012  10/31/1978   1978    33     NaN  1.697500  3.362003   \n",
       "10441    10103   1012  10/31/1978   1978    33     NaN  1.697500  3.362003   \n",
       "13941    10103   1012  10/31/1979   1979    33 -0.0537  1.196125  3.833059   \n",
       "...        ...    ...         ...    ...   ...     ...       ...       ...   \n",
       "319599   10103   1012  10/31/1985   1985    33 -0.0306  3.654000  2.275041   \n",
       "324006   10103   1012  10/31/1985   1985    33 -0.0306  3.654000  2.275041   \n",
       "328503   10103   1012  10/31/1985   1985    33 -0.0306  3.654000  2.275041   \n",
       "332973   10103   1012  10/31/1985   1985    33 -0.0306  3.654000  2.275041   \n",
       "337415   10103   1012  10/31/1985   1985    33 -0.0306  3.654000  2.275041   \n",
       "\n",
       "              ep     cashpr  ...  std_dolvol  std_turn           ill  \\\n",
       "2       0.338144 -17.143817  ...         NaN       NaN           NaN   \n",
       "3462    0.338144 -17.143817  ...         NaN       NaN           NaN   \n",
       "6932    0.338144 -17.143817  ...         NaN       NaN           NaN   \n",
       "10441   0.338144 -17.143817  ...         NaN       NaN           NaN   \n",
       "13941  -0.434737 -40.641964  ...         NaN       NaN           NaN   \n",
       "...          ...        ...  ...         ...       ...           ...   \n",
       "319599  0.173508 -20.234694  ...    0.970630  0.430200  4.102243e-06   \n",
       "324006  0.173508 -20.234694  ...    0.693619  0.102686  4.734849e-06   \n",
       "328503  0.173508 -20.234694  ...    1.260025  0.589355  6.410256e-07   \n",
       "332973  0.173508 -20.234694  ...    0.575778  0.242380  5.204745e-06   \n",
       "337415  0.173508 -20.234694  ...    1.123405  0.597261  0.000000e+00   \n",
       "\n",
       "        zerotrade      beta    betasq      rsq1  pricedelay   idiovol  pyear  \n",
       "2             NaN  1.759493  3.095816  0.096753    0.221851  0.087020   1980  \n",
       "3462          NaN  1.736435  3.015207  0.088872    0.124053  0.090373   1980  \n",
       "6932          NaN  1.546370  2.391259  0.065518   -0.026851  0.096490   1980  \n",
       "10441         NaN  1.544397  2.385163  0.065431    0.024635  0.096057   1980  \n",
       "13941         NaN  1.353537  1.832062  0.069685   -0.237500  0.097406   1980  \n",
       "...           ...       ...       ...       ...         ...       ...    ...  \n",
       "319599  12.409091  0.255926  0.065498 -0.004113    0.565691  0.070953   1986  \n",
       "324006  13.000002  0.295377  0.087248 -0.003160    0.761472  0.071049   1986  \n",
       "328503  16.000000  0.311741  0.097183 -0.002642    0.756879  0.070830   1986  \n",
       "332973  15.521740  0.402515  0.162018  0.000413    1.071883  0.070324   1986  \n",
       "337415  14.368422  0.394794  0.155862  0.000167    1.067267  0.069506   1986  \n",
       "\n",
       "[84 rows x 158 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42f97786-eeef-461a-886e-55a30e621f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>adatadate</th>\n",
       "      <th>fyear</th>\n",
       "      <th>sic2</th>\n",
       "      <th>spi</th>\n",
       "      <th>mve_f</th>\n",
       "      <th>bm</th>\n",
       "      <th>ep</th>\n",
       "      <th>cashpr</th>\n",
       "      <th>...</th>\n",
       "      <th>std_dolvol</th>\n",
       "      <th>std_turn</th>\n",
       "      <th>ill</th>\n",
       "      <th>zerotrade</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>rsq1</th>\n",
       "      <th>pricedelay</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>pyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341802</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>3.65400</td>\n",
       "      <td>2.275041</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-20.234694</td>\n",
       "      <td>...</td>\n",
       "      <td>1.231006</td>\n",
       "      <td>1.800102</td>\n",
       "      <td>1.090449e-06</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.361593</td>\n",
       "      <td>0.130749</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>0.742484</td>\n",
       "      <td>0.069696</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346169</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>3.65400</td>\n",
       "      <td>2.275041</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-20.234694</td>\n",
       "      <td>...</td>\n",
       "      <td>1.335870</td>\n",
       "      <td>1.067087</td>\n",
       "      <td>2.457757e-06</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.416393</td>\n",
       "      <td>0.173383</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.478180</td>\n",
       "      <td>0.069820</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350559</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>3.65400</td>\n",
       "      <td>2.275041</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-20.234694</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151043</td>\n",
       "      <td>0.556207</td>\n",
       "      <td>1.305952e-06</td>\n",
       "      <td>7.736842</td>\n",
       "      <td>0.441242</td>\n",
       "      <td>0.194694</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.686020</td>\n",
       "      <td>0.069377</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354962</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>3.65400</td>\n",
       "      <td>2.275041</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-20.234694</td>\n",
       "      <td>...</td>\n",
       "      <td>1.176656</td>\n",
       "      <td>2.029221</td>\n",
       "      <td>3.228941e-06</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.455675</td>\n",
       "      <td>0.207640</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.675348</td>\n",
       "      <td>0.069471</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359356</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.71975</td>\n",
       "      <td>1.851793</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>-13.191343</td>\n",
       "      <td>...</td>\n",
       "      <td>1.617956</td>\n",
       "      <td>0.744302</td>\n",
       "      <td>4.896825e-06</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.304795</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.690085</td>\n",
       "      <td>0.073579</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363768</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.71975</td>\n",
       "      <td>1.851793</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>-13.191343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.416399</td>\n",
       "      <td>5.807201e-06</td>\n",
       "      <td>16.800001</td>\n",
       "      <td>0.593509</td>\n",
       "      <td>0.352253</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0.674006</td>\n",
       "      <td>0.073664</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368195</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.71975</td>\n",
       "      <td>1.851793</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>-13.191343</td>\n",
       "      <td>...</td>\n",
       "      <td>1.292959</td>\n",
       "      <td>0.536874</td>\n",
       "      <td>1.681607e-06</td>\n",
       "      <td>12.409091</td>\n",
       "      <td>0.602111</td>\n",
       "      <td>0.362537</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>0.595316</td>\n",
       "      <td>0.073786</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372635</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.71975</td>\n",
       "      <td>1.851793</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>-13.191343</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939971</td>\n",
       "      <td>0.857289</td>\n",
       "      <td>5.997901e-07</td>\n",
       "      <td>12.409091</td>\n",
       "      <td>0.585699</td>\n",
       "      <td>0.343043</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.712869</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377143</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.71975</td>\n",
       "      <td>1.851793</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>-13.191343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959727</td>\n",
       "      <td>0.384731</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>15.000001</td>\n",
       "      <td>0.619795</td>\n",
       "      <td>0.384145</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>0.683746</td>\n",
       "      <td>0.073250</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381798</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.71975</td>\n",
       "      <td>1.851793</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>-13.191343</td>\n",
       "      <td>...</td>\n",
       "      <td>1.514816</td>\n",
       "      <td>0.988957</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.611251</td>\n",
       "      <td>0.373628</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.715021</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386448</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.71975</td>\n",
       "      <td>1.851793</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>-13.191343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701219</td>\n",
       "      <td>0.235492</td>\n",
       "      <td>1.429100e-05</td>\n",
       "      <td>12.409092</td>\n",
       "      <td>0.604921</td>\n",
       "      <td>0.365929</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.735726</td>\n",
       "      <td>0.073248</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391093</th>\n",
       "      <td>10103</td>\n",
       "      <td>1012</td>\n",
       "      <td>10/31/1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.71975</td>\n",
       "      <td>1.851793</td>\n",
       "      <td>0.090471</td>\n",
       "      <td>-13.191343</td>\n",
       "      <td>...</td>\n",
       "      <td>1.769667</td>\n",
       "      <td>0.698555</td>\n",
       "      <td>6.233442e-07</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>0.539649</td>\n",
       "      <td>0.291221</td>\n",
       "      <td>0.016167</td>\n",
       "      <td>0.533242</td>\n",
       "      <td>0.073040</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        permno  gvkey   adatadate  fyear  sic2     spi    mve_f        bm  \\\n",
       "341802   10103   1012  10/31/1985   1985    33 -0.0306  3.65400  2.275041   \n",
       "346169   10103   1012  10/31/1985   1985    33 -0.0306  3.65400  2.275041   \n",
       "350559   10103   1012  10/31/1985   1985    33 -0.0306  3.65400  2.275041   \n",
       "354962   10103   1012  10/31/1985   1985    33 -0.0306  3.65400  2.275041   \n",
       "359356   10103   1012  10/31/1986   1986    33  0.0000  4.71975  1.851793   \n",
       "363768   10103   1012  10/31/1986   1986    33  0.0000  4.71975  1.851793   \n",
       "368195   10103   1012  10/31/1986   1986    33  0.0000  4.71975  1.851793   \n",
       "372635   10103   1012  10/31/1986   1986    33  0.0000  4.71975  1.851793   \n",
       "377143   10103   1012  10/31/1986   1986    33  0.0000  4.71975  1.851793   \n",
       "381798   10103   1012  10/31/1986   1986    33  0.0000  4.71975  1.851793   \n",
       "386448   10103   1012  10/31/1986   1986    33  0.0000  4.71975  1.851793   \n",
       "391093   10103   1012  10/31/1986   1986    33  0.0000  4.71975  1.851793   \n",
       "\n",
       "              ep     cashpr  ...  std_dolvol  std_turn           ill  \\\n",
       "341802  0.173508 -20.234694  ...    1.231006  1.800102  1.090449e-06   \n",
       "346169  0.173508 -20.234694  ...    1.335870  1.067087  2.457757e-06   \n",
       "350559  0.173508 -20.234694  ...    1.151043  0.556207  1.305952e-06   \n",
       "354962  0.173508 -20.234694  ...    1.176656  2.029221  3.228941e-06   \n",
       "359356  0.090471 -13.191343  ...    1.617956  0.744302  4.896825e-06   \n",
       "363768  0.090471 -13.191343  ...    0.961905  0.416399  5.807201e-06   \n",
       "368195  0.090471 -13.191343  ...    1.292959  0.536874  1.681607e-06   \n",
       "372635  0.090471 -13.191343  ...    1.939971  0.857289  5.997901e-07   \n",
       "377143  0.090471 -13.191343  ...    0.959727  0.384731  0.000000e+00   \n",
       "381798  0.090471 -13.191343  ...    1.514816  0.988957  0.000000e+00   \n",
       "386448  0.090471 -13.191343  ...    0.701219  0.235492  1.429100e-05   \n",
       "391093  0.090471 -13.191343  ...    1.769667  0.698555  6.233442e-07   \n",
       "\n",
       "        zerotrade      beta    betasq      rsq1  pricedelay   idiovol  pyear  \n",
       "341802  10.500000  0.361593  0.130749 -0.000917    0.742484  0.069696   1987  \n",
       "346169  14.000000  0.416393  0.173383  0.000707    0.478180  0.069820   1987  \n",
       "350559   7.736842  0.441242  0.194694  0.002159    0.686020  0.069377   1987  \n",
       "354962  10.500000  0.455675  0.207640  0.002806    0.675348  0.069471   1987  \n",
       "359356  10.000000  0.552083  0.304795  0.005441    0.690085  0.073579   1987  \n",
       "363768  16.800001  0.593509  0.352253  0.006986    0.674006  0.073664   1987  \n",
       "368195  12.409091  0.602111  0.362537  0.007328    0.595316  0.073786   1987  \n",
       "372635  12.409091  0.585699  0.343043  0.006230    0.712869  0.073638   1987  \n",
       "377143  15.000001  0.619795  0.384145  0.006747    0.683746  0.073250   1987  \n",
       "381798  13.000000  0.611251  0.373628  0.006330    0.715021  0.073300   1987  \n",
       "386448  12.409092  0.604921  0.365929  0.005927    0.735726  0.073248   1987  \n",
       "391093  14.700000  0.539649  0.291221  0.016167    0.533242  0.073040   1987  \n",
       "\n",
       "[12 rows x 158 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "844bd255-61fd-47ba-b400-59462d0ec0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data, test_data, features, target, pipeline):\n",
    "    # Train data\n",
    "    x_train = train_data.loc[:, features]\n",
    "    y_train = train_data.loc[:, target]\n",
    "    \n",
    "    # Fit the pipeline to the train data\n",
    "    pipeline.fit(x_train)\n",
    "    x_train_tf = pipeline.transform(x_train)\n",
    "    x_train_tf = x_train_tf[:, :-2]\n",
    "    \n",
    "    # Test data\n",
    "    x_test = test_data.loc[:, features]\n",
    "    y_test = test_data.loc[:, target]\n",
    "    \n",
    "    # Fit the pipeline to the test data\n",
    "    x_test_tf = pipeline.transform(x_test)\n",
    "    x_test_tf = x_test_tf[:, :-2]\n",
    "    \n",
    "    # Transform data into numpy array as type float32\n",
    "    x_train_tf = x_train_tf.astype(np.float32)\n",
    "    y_train_tf = y_train.to_numpy(np.float32)\n",
    "    x_test_tf = x_test_tf.astype(np.float32)\n",
    "    y_test_tf = y_test.to_numpy(np.float32)\n",
    "    \n",
    "    # # Transform them to tensor floats\n",
    "    x_train_tf = torch.tensor(x_train_tf).float()\n",
    "    y_train_tf = torch.tensor(y_train_tf).float()\n",
    "    x_test_tf = torch.tensor(x_test_tf).float()\n",
    "    y_test_tf = torch.tensor(y_test_tf).float()\n",
    "\n",
    "    print(f'x_train shape: {x_train_tf.shape}')\n",
    "    print(f'y_train shape: {y_train_tf.shape}\\n')\n",
    "    print(f'x_test shape: {x_test_tf.shape}')\n",
    "    print(f'y_test shape: {y_test_tf.shape}\\n')\n",
    "    \n",
    "    return x_train_tf, y_train_tf, x_test_tf, y_test_tf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca0097f4-9664-4654-91fd-0c260a9b118f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([84, 102])\n",
      "y_train shape: torch.Size([84])\n",
      "\n",
      "x_test shape: torch.Size([12, 102])\n",
      "y_test shape: torch.Size([12])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = transform_data(train_data, test_data, deps, target, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6458be-22f8-4502-90c5-004cc9f20dfd",
   "metadata": {},
   "source": [
    "## Finalize sequence data for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "823c2704-bf2c-4fd9-9087-17e12eccca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline inside Dataset\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, train_data, test_data, features, target, pipeline, sequence_length=5):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.pipeline = pipeline\n",
    "        self.sequence_length = sequence_length\n",
    "        self.x_train, self.y_train, self.x_test, self.y_test = self._transform_data()\n",
    "        \n",
    "    def _transform_data(self):\n",
    "        \"\"\"\n",
    "        Transform the data using provided pipeline\n",
    "        \"\"\"\n",
    "        x_train = self.train_data.loc[:, self.features]\n",
    "        y_train = self.train_data.loc[:, self.target]\n",
    "        \n",
    "        # Fit the pipeline to the training data\n",
    "        self.pipeline.fit(x_train)\n",
    "        x_train = self.pipeline.transform(x_train)\n",
    "        x_train = x_train[:, :-2]\n",
    "        \n",
    "        x_test = self.test_data.loc[:, self.features] \n",
    "        y_test = self.test_data.loc[:, self.target]\n",
    "        \n",
    "        # Fit the pipeline to the testing data  \n",
    "        x_test = self.pipeline.transform(x_test)\n",
    "        x_test = x_test[:, :-2]\n",
    "        \n",
    "        # Transform data into numpy array as type float32\n",
    "        x_train = x_train.astype(np.float32)\n",
    "        y_train = y_train.to_numpy(np.float32)\n",
    "        x_test = x_test.astype(np.float32)\n",
    "        y_test = y_test.to_numpy(np.float32)\n",
    "        \n",
    "        # # Transform them to tensor floats\n",
    "        x_train = torch.tensor(x_train).float()\n",
    "        y_train = torch.tensor(y_train).float()\n",
    "        x_test = torch.tensor(x_test).float()\n",
    "        y_test = torch.tensor(y_test).float()\n",
    "        \n",
    "        print(f'x_train shape: {x_train.shape}')\n",
    "        print(f'y_train shape: {y_train.shape}\\n')\n",
    "        print(f'x_test shape: {x_test.shape}')\n",
    "        print(f'y_test shape: {y_test.shape}\\n')\n",
    "        \n",
    "        return x_train, y_train, x_test, y_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return max(self.x_train.shape[0], self.x_test.shape[0])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Return the corresponding ith data for all x_train, y_train, x_test, y_test\n",
    "        \"\"\"\n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            x_train = self.x_train[i_start:(i + 1), :]\n",
    "            x_test = self.x_test[i_start:(i+1), :]\n",
    "        else:\n",
    "            # repeat the first row as many times to make up the gap\n",
    "            train_padding = self.x_train[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            test_padding = self.x_test[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            # concatenate the padding with the available rows\n",
    "            x_train = self.x_train[0:(i + 1), :]\n",
    "            x_train = torch.cat((train_padding, x_train), 0)\n",
    "            x_test = self.x_test[0:(i+1), :]\n",
    "            x_test = torch.cat((test_padding, x_test), 0)\n",
    "            \n",
    "        # Since train and test have different length, return None when index i exceeds max length\n",
    "        if i >= self.y_train.shape[0]:\n",
    "            x_train = None\n",
    "            y_train = None\n",
    "            pass\n",
    "        else:\n",
    "            y_train = self.y_train[i]\n",
    "            # print(f'x_train ith item shape: {x_train.shape}')\n",
    "            # print(f'y_train: {y_train}')\n",
    "            \n",
    "        if i >= self.y_test.shape[0]:\n",
    "            x_test = None\n",
    "            y_test = None\n",
    "            pass\n",
    "        else:\n",
    "            y_test = self.y_test[i]\n",
    "            # print(f'x_test ith item shape: {x_test.shape}')\n",
    "            # print(f'y_test: {y_test}')\n",
    "\n",
    "        return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0807afc6-fdd0-42d5-94d9-b4815173f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline outside Dataset\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, x, y, sequence_length=5):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.sequence_length = sequence_length\n",
    "        self.ith_x = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Return the corresponding ith data for x and y\n",
    "        \"\"\"\n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            self.ith_x = self.x[i_start:(i + 1), :]\n",
    "        else:\n",
    "            # repeat the first row as many times to make up the gap\n",
    "            data_padding = self.x[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            # concatenate the padding with the available rows\n",
    "            self.ith_x = self.x[0:(i + 1), :]\n",
    "            self.ith_x = torch.cat((data_padding, self.ith_x), 0)\n",
    "        \n",
    "        # print(f'x ith item shape: {self.ith_x.shape}')\n",
    "        # print(f'y : {self.y[i]}')\n",
    "            \n",
    "        return self.ith_x, self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1072d4fb-1406-4277-803d-31a8e00e0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequenceDataset(x_train, y_train, sequence_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af078f94-1c06-4343-bb71-61d0420498ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2477226-1e65-4946-8333-bbf94357f1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7499,  0.6793,  0.0000, -1.2978, -0.8048,  0.5358,  0.8377,  0.7715,\n",
       "           1.5869,  1.3162,  0.0000, -1.4420, -1.4628, -1.1093,  0.3620, -0.0222,\n",
       "           1.0113, -2.2560,  0.0000,  0.0262,  0.9260,  0.0000, -0.7407,  0.0000,\n",
       "           0.0000, -0.3796,  1.4237,  0.0000, -0.7733,  0.0000,  0.0000, -1.4784,\n",
       "          -2.2394,  0.0000, -0.3324,  0.1686, -1.6917,  1.1095, -2.0936,  0.6953,\n",
       "          -0.6628, -0.1735, -1.9973,  0.8968, -0.1511,  1.2059, -2.0602,  1.2980,\n",
       "          -0.1774, -0.8898,  0.0000, -1.6296,  0.7597,  0.0000,  0.0000, -0.8128,\n",
       "           1.0980, -1.3131,  1.5445,  2.1129, -0.4312,  1.3736, -0.1862, -1.6223,\n",
       "          -0.7674, -0.3479,  0.1157, -0.4810, -0.7717, -0.7289,  0.3529,  0.2666,\n",
       "           1.0377,  1.6535,  0.0000,  0.0000,  0.0000, -0.4560,  0.0000,  1.3541,\n",
       "          -1.2003, -1.1821, -0.1696,  0.0000, -0.4491,  1.1873,  0.7483, -0.0803,\n",
       "           0.0000,  0.0000,  0.0000, -1.7919,  0.8007, -0.4960,  1.3358,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7499,  0.6793,  0.0000, -1.2978, -0.8048,  0.9660,  0.9512,  0.9324,\n",
       "           1.4821,  1.3162,  0.0000, -1.4420, -1.4628, -1.1093,  0.3620, -0.0222,\n",
       "           1.0113, -2.2560,  0.0000,  0.0262, -0.1832,  0.0000, -0.7407,  0.0000,\n",
       "           0.0000, -0.3796,  1.4237,  0.0000, -0.7288,  0.0000,  0.0000, -1.4784,\n",
       "          -2.2394,  0.0000, -0.3324,  0.1686, -1.6917,  1.1095, -2.0936,  0.4508,\n",
       "          -0.3499,  0.0767, -1.9973,  0.8968, -0.1511,  0.1766, -1.0735, -0.9553,\n",
       "           1.1141, -0.6115,  0.0000, -1.9360,  0.7597,  0.0000,  0.0000, -0.8128,\n",
       "           1.0980, -1.3131,  1.5445,  2.1129, -0.4312,  1.3736, -0.1862, -1.6223,\n",
       "          -0.7674, -0.3479,  0.1157, -0.6249, -0.7717, -0.7289,  0.3529,  0.2666,\n",
       "           1.0377,  1.1775,  0.0000,  0.0000,  0.0000, -0.4560,  0.0000,  1.3541,\n",
       "          -1.2003, -1.1821, -0.1696,  0.0000, -0.4491,  1.1873, -0.2147,  0.0238,\n",
       "           0.0000,  0.0000,  0.0000, -1.7919,  0.8007, -0.5481,  0.5120,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7499,  0.6793,  0.0000, -1.2978, -0.8048,  0.6977,  0.7728,  0.6821,\n",
       "           1.3278,  1.3162,  0.0000, -1.4420, -1.4628, -1.1093,  0.3620, -0.0222,\n",
       "           1.0113, -2.2560,  0.0000,  0.0262,  1.2252,  0.0000, -0.7407,  0.0000,\n",
       "           0.0000, -0.3796,  1.4237,  0.0000, -0.0254,  0.0000,  0.0000, -1.4784,\n",
       "          -2.2394,  0.0000, -0.3324,  0.1686, -1.6917,  1.1095, -2.0936,  0.4436,\n",
       "           0.1096,  0.9890, -1.9973,  0.8968, -0.1511,  1.8491, -1.3902,  1.2010,\n",
       "          -0.0697, -0.1027,  0.0000, -1.4897,  0.7597,  0.0000,  0.0000, -0.8128,\n",
       "           1.0980, -1.3131,  1.5445,  2.1129, -0.4312,  1.3736, -0.1862, -1.6223,\n",
       "          -0.7674, -0.3479,  0.1157, -0.7264, -0.7717, -0.7289,  0.3529,  0.2666,\n",
       "           1.0377,  1.2539,  0.0000,  0.0000,  0.0000, -0.4560,  0.0000,  1.3541,\n",
       "          -1.2003, -1.1821, -0.1696,  0.0000, -0.4491,  1.1873, -0.3652, -0.0924,\n",
       "           0.0000,  0.0000,  0.0000, -1.7919,  0.8007, -0.1809, -1.1644,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor(0.2778))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d5cdfb8-0414-4aed-a895-c6e487b8000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SequenceDataset(x_test, y_test, sequence_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aff20242-c7b0-4680-b5b0-6fc1d97cde90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e2b89a0-bd00-4dab-a50e-5dd0dce1fc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7790, -0.2882,  0.0000,  2.1089,  0.1867, -1.0176, -0.5996, -0.7500,\n",
       "          -1.9747, -1.6214,  0.0000,  0.0761,  0.3986,  0.3700,  0.4044, -0.5454,\n",
       "           0.7151, -0.1158,  0.0000, -0.6152, -1.3226,  0.0000, -0.5243,  0.0000,\n",
       "           0.0000, -0.5307,  1.1604,  0.0000, -0.5064,  0.0000,  0.0000, -0.0720,\n",
       "          -0.0295,  0.0000,  0.0864, -0.3712,  0.5588, -0.8454, -0.1136, -0.7839,\n",
       "          -1.0359,  1.8623,  0.1328, -2.1055,  0.2256, -0.8526, -0.1731, -0.1566,\n",
       "           0.6422, -1.1562,  0.0000,  1.7011, -0.7639,  0.0000,  0.0000,  0.1290,\n",
       "          -0.7314,  2.8559, -0.8237, -0.7052, -0.4837, -0.3193,  0.2166, -1.3962,\n",
       "          -1.0295,  0.0364,  0.2109,  0.5669, -1.3720, -0.1979, -2.3064, -1.0309,\n",
       "           3.7404, -1.1598,  0.0000,  0.0000,  0.0000, -0.0262,  0.0000, -0.0964,\n",
       "           1.2174, -0.7592,  1.1483,  0.0000, -0.8033, -1.9130,  0.9559,  0.1062,\n",
       "           0.0000,  0.0000,  0.0000,  0.6131,  0.3906, -0.6011,  0.3920,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000],\n",
       "         [-0.7790, -0.2882,  0.0000,  2.1089,  0.1867, -0.5795, -0.6159, -0.7617,\n",
       "          -1.9747, -1.6214,  0.0000,  0.0761,  0.3986,  0.3700,  0.4044, -0.5454,\n",
       "           0.7151, -0.1158,  0.0000, -0.6152, -1.1329,  0.0000, -0.5243,  0.0000,\n",
       "           0.0000, -0.5307,  1.1604,  0.0000,  0.8932,  0.0000,  0.0000, -0.0720,\n",
       "          -0.0295,  0.0000,  0.0864, -0.3712,  0.5588, -0.8454, -0.1136, -0.7875,\n",
       "           2.6661,  1.8081,  0.1328, -2.1055,  0.2256, -0.8526, -0.0625, -1.0498,\n",
       "           0.4994, -0.7705,  0.0000,  1.3558, -0.7639,  0.0000,  0.0000,  0.1290,\n",
       "          -0.7314,  2.8559, -0.8237, -0.7052, -0.4837, -0.3193,  0.2166, -1.3962,\n",
       "          -1.0295,  0.0364,  0.2109,  0.5971, -1.3720, -0.1979, -2.3064, -1.0309,\n",
       "           3.7404, -0.3086,  0.0000,  0.0000,  0.0000, -0.0262,  0.0000, -0.0964,\n",
       "           1.2174, -0.7592,  1.1483,  0.0000, -0.8033, -1.9130, -1.5949, -1.0960,\n",
       "           0.0000,  0.0000,  0.0000,  0.6131,  0.3906, -1.0370,  0.1786,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000],\n",
       "         [-0.7790, -0.2882,  0.0000,  2.1089,  0.1867, -0.2229, -0.7832, -0.8753,\n",
       "          -1.9747, -1.6214,  0.0000,  0.0761,  0.3986,  0.3700,  0.4044, -0.5454,\n",
       "           0.7151, -0.1158,  0.0000, -0.6152, -1.0772,  0.0000, -0.5243,  0.0000,\n",
       "           0.0000, -0.5307,  1.1604,  0.0000, -0.8210,  0.0000,  0.0000, -0.0720,\n",
       "          -0.0295,  0.0000,  0.0864, -0.3712,  0.5588, -0.8454, -0.1136, -0.8020,\n",
       "          -0.8744, -0.1993,  0.1328, -2.1055,  0.2256, -0.8526, -0.5498, -0.7737,\n",
       "           0.6215, -1.0901,  0.0000,  1.1225, -0.7639,  0.0000,  0.0000,  0.1290,\n",
       "          -0.7314,  2.8559, -0.8237, -0.7052, -0.4837, -0.3193,  0.2166, -1.3962,\n",
       "          -1.0295,  0.0364,  0.2109,  0.3017, -1.3720, -0.1979, -2.3064, -1.0309,\n",
       "           3.7404, -0.4004,  0.0000,  0.0000,  0.0000, -0.0262,  0.0000, -0.0964,\n",
       "           1.2174, -0.7592,  1.1483,  0.0000, -0.8033, -1.9130,  1.7549, -0.3572,\n",
       "           0.0000,  0.0000,  0.0000,  0.6131,  0.3906, -0.8190,  1.0059,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000]]),\n",
       " tensor(0.0333))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ca80d42-509e-43b5-96b5-e2dc82c36be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = SequenceDataset(train_data, test_data, deps, target, pipeline, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1433bfea-5891-4392-8b7e-eef9e53ffdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "264cd303-645b-47fd-acbc-136da4cdf5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 10\n",
    "sequence_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "50dc8364-4a0a-431b-85ca-6219276b9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequenceDataset(x_train, y_train, sequence_length=sequence_length)\n",
    "test_dataset = SequenceDataset(x_test, y_test, sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b9552b6b-3f35-4733-904b-457d29bd419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "645a55f8-f385-415f-90e1-b67438fde9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "88d67ff9-ca81-4e17-aad0-5c86dc64aa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 102]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431fade6-f97d-4718-b05a-99d132716d31",
   "metadata": {},
   "source": [
    "## Modeling data with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "976983c7-19d7-49ab-93b2-63e57687f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # this is the number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 1\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        \n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "71cdfa80-031a-4d2f-899a-8188b1f9f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "    \n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d86594d0-6fdd-4f6b-af7d-d54f09a476cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "num_hidden_units = 20\n",
    "num_features = x_train.shape[1]\n",
    "\n",
    "model = ShallowRegressionLSTM(num_sensors=num_features, hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e097c294-6e77-4bd0-b62d-6eec6a657587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 0.011356751434504986\n",
      "\n",
      "Epoch 0\n",
      "---------\n",
      "Train loss: 0.052450623673697315\n",
      "Test loss: 0.011266466230154037\n",
      "\n",
      "Epoch 1\n",
      "---------\n",
      "Train loss: 0.05034064377347628\n",
      "Test loss: 0.01114532770588994\n",
      "\n",
      "Epoch 2\n",
      "---------\n",
      "Train loss: 0.04910269400311841\n",
      "Test loss: 0.011062025092542171\n",
      "\n",
      "Epoch 3\n",
      "---------\n",
      "Train loss: 0.048884342735012375\n",
      "Test loss: 0.010963602922856808\n",
      "\n",
      "Epoch 4\n",
      "---------\n",
      "Train loss: 0.05097706740101179\n",
      "Test loss: 0.010874413419514894\n",
      "\n",
      "Epoch 5\n",
      "---------\n",
      "Train loss: 0.04722758868916167\n",
      "Test loss: 0.010802621487528086\n",
      "\n",
      "Epoch 6\n",
      "---------\n",
      "Train loss: 0.04805703399082025\n",
      "Test loss: 0.01072681462392211\n",
      "\n",
      "Epoch 7\n",
      "---------\n",
      "Train loss: 0.04684620743824376\n",
      "Test loss: 0.010647937655448914\n",
      "\n",
      "Epoch 8\n",
      "---------\n",
      "Train loss: 0.04637658099333445\n",
      "Test loss: 0.01058495370671153\n",
      "\n",
      "Epoch 9\n",
      "---------\n",
      "Train loss: 0.0477271048973004\n",
      "Test loss: 0.01049366919323802\n",
      "\n",
      "Epoch 10\n",
      "---------\n",
      "Train loss: 0.04525076556536886\n",
      "Test loss: 0.010418680030852556\n",
      "\n",
      "Epoch 11\n",
      "---------\n",
      "Train loss: 0.044128568636046514\n",
      "Test loss: 0.010343748843297362\n",
      "\n",
      "Epoch 12\n",
      "---------\n",
      "Train loss: 0.045004551505876914\n",
      "Test loss: 0.010278539033606648\n",
      "\n",
      "Epoch 13\n",
      "---------\n",
      "Train loss: 0.04369344955517186\n",
      "Test loss: 0.01021722611039877\n",
      "\n",
      "Epoch 14\n",
      "---------\n",
      "Train loss: 0.04386266755561034\n",
      "Test loss: 0.010165940271690488\n",
      "\n",
      "Epoch 15\n",
      "---------\n",
      "Train loss: 0.04193886069373952\n",
      "Test loss: 0.010096014942973852\n",
      "\n",
      "Epoch 16\n",
      "---------\n",
      "Train loss: 0.042043345566425055\n",
      "Test loss: 0.010036668740212917\n",
      "\n",
      "Epoch 17\n",
      "---------\n",
      "Train loss: 0.04093906464469102\n",
      "Test loss: 0.00998903438448906\n",
      "\n",
      "Epoch 18\n",
      "---------\n",
      "Train loss: 0.04340669864581691\n",
      "Test loss: 0.0099393620621413\n",
      "\n",
      "Epoch 19\n",
      "---------\n",
      "Train loss: 0.041714326995942325\n",
      "Test loss: 0.009886885760352015\n",
      "\n",
      "Epoch 20\n",
      "---------\n",
      "Train loss: 0.043019486487739615\n",
      "Test loss: 0.009839205536991358\n",
      "\n",
      "Epoch 21\n",
      "---------\n",
      "Train loss: 0.039158863118953176\n",
      "Test loss: 0.009797091130167246\n",
      "\n",
      "Epoch 22\n",
      "---------\n",
      "Train loss: 0.03973935637623072\n",
      "Test loss: 0.0097543487790972\n",
      "\n",
      "Epoch 23\n",
      "---------\n",
      "Train loss: 0.04312207611898581\n",
      "Test loss: 0.009700094349682331\n",
      "\n",
      "Epoch 24\n",
      "---------\n",
      "Train loss: 0.039850264166792236\n",
      "Test loss: 0.009654143592342734\n",
      "\n",
      "Epoch 25\n",
      "---------\n",
      "Train loss: 0.041092987482746444\n",
      "Test loss: 0.009619166143238544\n",
      "\n",
      "Epoch 26\n",
      "---------\n",
      "Train loss: 0.0375979652421342\n",
      "Test loss: 0.009574557887390256\n",
      "\n",
      "Epoch 27\n",
      "---------\n",
      "Train loss: 0.03720085374597046\n",
      "Test loss: 0.009544220054522157\n",
      "\n",
      "Epoch 28\n",
      "---------\n",
      "Train loss: 0.03683918217817942\n",
      "Test loss: 0.009509331313893199\n",
      "\n",
      "Epoch 29\n",
      "---------\n",
      "Train loss: 0.03666385211464432\n",
      "Test loss: 0.009480515960603952\n",
      "\n",
      "Epoch 30\n",
      "---------\n",
      "Train loss: 0.03837393265631464\n",
      "Test loss: 0.009442646522074938\n",
      "\n",
      "Epoch 31\n",
      "---------\n",
      "Train loss: 0.037675241525802344\n",
      "Test loss: 0.009423930663615465\n",
      "\n",
      "Epoch 32\n",
      "---------\n",
      "Train loss: 0.03594718407839537\n",
      "Test loss: 0.009394786320626736\n",
      "\n",
      "Epoch 33\n",
      "---------\n",
      "Train loss: 0.03569133641819159\n",
      "Test loss: 0.009377127513289452\n",
      "\n",
      "Epoch 34\n",
      "---------\n",
      "Train loss: 0.038633482427232795\n",
      "Test loss: 0.009350784588605165\n",
      "\n",
      "Epoch 35\n",
      "---------\n",
      "Train loss: 0.034736751268307366\n",
      "Test loss: 0.009332116460427642\n",
      "\n",
      "Epoch 36\n",
      "---------\n",
      "Train loss: 0.03432027933498224\n",
      "Test loss: 0.00930766318924725\n",
      "\n",
      "Epoch 37\n",
      "---------\n",
      "Train loss: 0.034631754789087504\n",
      "Test loss: 0.009286478627473116\n",
      "\n",
      "Epoch 38\n",
      "---------\n",
      "Train loss: 0.039003598503768444\n",
      "Test loss: 0.009268312016502023\n",
      "\n",
      "Epoch 39\n",
      "---------\n",
      "Train loss: 0.052331298072304994\n",
      "Test loss: 0.009251611772924662\n",
      "\n",
      "Epoch 40\n",
      "---------\n",
      "Train loss: 0.03290104565935002\n",
      "Test loss: 0.00921651883982122\n",
      "\n",
      "Epoch 41\n",
      "---------\n",
      "Train loss: 0.033496173926525645\n",
      "Test loss: 0.009199821157380939\n",
      "\n",
      "Epoch 42\n",
      "---------\n",
      "Train loss: 0.03450713327361478\n",
      "Test loss: 0.009177196770906448\n",
      "\n",
      "Epoch 43\n",
      "---------\n",
      "Train loss: 0.03263752700554\n",
      "Test loss: 0.009157789871096611\n",
      "\n",
      "Epoch 44\n",
      "---------\n",
      "Train loss: 0.03219565055850479\n",
      "Test loss: 0.009149304125458002\n",
      "\n",
      "Epoch 45\n",
      "---------\n",
      "Train loss: 0.032640491094854146\n",
      "Test loss: 0.009140573674812913\n",
      "\n",
      "Epoch 46\n",
      "---------\n",
      "Train loss: 0.03140251535094447\n",
      "Test loss: 0.009134829975664616\n",
      "\n",
      "Epoch 47\n",
      "---------\n",
      "Train loss: 0.03278911651836501\n",
      "Test loss: 0.009129351936280727\n",
      "\n",
      "Epoch 48\n",
      "---------\n",
      "Train loss: 0.03155969362705946\n",
      "Test loss: 0.009117697831243277\n",
      "\n",
      "Epoch 49\n",
      "---------\n",
      "Train loss: 0.03206680849608448\n",
      "Test loss: 0.009110359940677881\n",
      "\n",
      "Epoch 50\n",
      "---------\n",
      "Train loss: 0.03553426969382498\n",
      "Test loss: 0.009101193863898516\n",
      "\n",
      "Epoch 51\n",
      "---------\n",
      "Train loss: 0.030786184335334435\n",
      "Test loss: 0.009092593099921942\n",
      "\n",
      "Epoch 52\n",
      "---------\n",
      "Train loss: 0.031329345889389515\n",
      "Test loss: 0.009093445725739002\n",
      "\n",
      "Epoch 53\n",
      "---------\n",
      "Train loss: 0.03034996794950631\n",
      "Test loss: 0.009096629917621613\n",
      "\n",
      "Epoch 54\n",
      "---------\n",
      "Train loss: 0.03100941123233901\n",
      "Test loss: 0.009091613115742803\n",
      "\n",
      "Epoch 55\n",
      "---------\n",
      "Train loss: 0.030034184714572296\n",
      "Test loss: 0.009085169294849038\n",
      "\n",
      "Epoch 56\n",
      "---------\n",
      "Train loss: 0.03158190432522032\n",
      "Test loss: 0.009078403003513813\n",
      "\n",
      "Epoch 57\n",
      "---------\n",
      "Train loss: 0.04720682940549321\n",
      "Test loss: 0.009084709454327822\n",
      "\n",
      "Epoch 58\n",
      "---------\n",
      "Train loss: 0.04642653351442681\n",
      "Test loss: 0.009078293573111296\n",
      "\n",
      "Epoch 59\n",
      "---------\n",
      "Train loss: 0.029831109723697107\n",
      "Test loss: 0.009056816576048732\n",
      "\n",
      "Epoch 60\n",
      "---------\n",
      "Train loss: 0.028774211519501276\n",
      "Test loss: 0.009048802545294166\n",
      "\n",
      "Epoch 61\n",
      "---------\n",
      "Train loss: 0.04566244574056731\n",
      "Test loss: 0.009049093583598733\n",
      "\n",
      "Epoch 62\n",
      "---------\n",
      "Train loss: 0.029558961900571983\n",
      "Test loss: 0.009038217831403017\n",
      "\n",
      "Epoch 63\n",
      "---------\n",
      "Train loss: 0.02914045171605216\n",
      "Test loss: 0.009037716779857874\n",
      "\n",
      "Epoch 64\n",
      "---------\n",
      "Train loss: 0.029495401514901057\n",
      "Test loss: 0.009031402645632625\n",
      "\n",
      "Epoch 65\n",
      "---------\n",
      "Train loss: 0.02881014895521932\n",
      "Test loss: 0.009029798675328493\n",
      "\n",
      "Epoch 66\n",
      "---------\n",
      "Train loss: 0.030360728088352416\n",
      "Test loss: 0.009032188216224313\n",
      "\n",
      "Epoch 67\n",
      "---------\n",
      "Train loss: 0.027923058459742203\n",
      "Test loss: 0.009040434146299958\n",
      "\n",
      "Epoch 68\n",
      "---------\n",
      "Train loss: 0.02954461404846774\n",
      "Test loss: 0.009044730104506016\n",
      "\n",
      "Epoch 69\n",
      "---------\n",
      "Train loss: 0.02862743070969979\n",
      "Test loss: 0.009052429348230362\n",
      "\n",
      "Epoch 70\n",
      "---------\n",
      "Train loss: 0.02835550893925958\n",
      "Test loss: 0.009053968358784914\n",
      "\n",
      "Epoch 71\n",
      "---------\n",
      "Train loss: 0.027800147318177752\n",
      "Test loss: 0.009061413584277034\n",
      "\n",
      "Epoch 72\n",
      "---------\n",
      "Train loss: 0.027340185466325946\n",
      "Test loss: 0.009065186372026801\n",
      "\n",
      "Epoch 73\n",
      "---------\n",
      "Train loss: 0.027641754700905748\n",
      "Test loss: 0.009072800632566214\n",
      "\n",
      "Epoch 74\n",
      "---------\n",
      "Train loss: 0.028663453956445057\n",
      "Test loss: 0.009081108961254358\n",
      "\n",
      "Epoch 75\n",
      "---------\n",
      "Train loss: 0.028427767256895702\n",
      "Test loss: 0.009089874336495996\n",
      "\n",
      "Epoch 76\n",
      "---------\n",
      "Train loss: 0.026821483961409993\n",
      "Test loss: 0.009096436202526093\n",
      "\n",
      "Epoch 77\n",
      "---------\n",
      "Train loss: 0.026860189365430012\n",
      "Test loss: 0.009104378055781126\n",
      "\n",
      "Epoch 78\n",
      "---------\n",
      "Train loss: 0.02714067914833625\n",
      "Test loss: 0.009113325271755457\n",
      "\n",
      "Epoch 79\n",
      "---------\n",
      "Train loss: 0.027479191207223468\n",
      "Test loss: 0.009122522082179785\n",
      "\n",
      "Epoch 80\n",
      "---------\n",
      "Train loss: 0.026440837782704167\n",
      "Test loss: 0.009136687498539686\n",
      "\n",
      "Epoch 81\n",
      "---------\n",
      "Train loss: 0.02586752228671685\n",
      "Test loss: 0.009146454744040966\n",
      "\n",
      "Epoch 82\n",
      "---------\n",
      "Train loss: 0.02755477952046527\n",
      "Test loss: 0.009155385429039598\n",
      "\n",
      "Epoch 83\n",
      "---------\n",
      "Train loss: 0.029885800658828683\n",
      "Test loss: 0.009168969467282295\n",
      "\n",
      "Epoch 84\n",
      "---------\n",
      "Train loss: 0.026484993648611836\n",
      "Test loss: 0.009177117375656962\n",
      "\n",
      "Epoch 85\n",
      "---------\n",
      "Train loss: 0.026804117382400565\n",
      "Test loss: 0.009182537673041224\n",
      "\n",
      "Epoch 86\n",
      "---------\n",
      "Train loss: 0.02675412331397335\n",
      "Test loss: 0.009193202713504434\n",
      "\n",
      "Epoch 87\n",
      "---------\n",
      "Train loss: 0.026333976588729355\n",
      "Test loss: 0.009200695203617215\n",
      "\n",
      "Epoch 88\n",
      "---------\n",
      "Train loss: 0.02657946835582455\n",
      "Test loss: 0.009213299257680774\n",
      "\n",
      "Epoch 89\n",
      "---------\n",
      "Train loss: 0.02654534749065836\n",
      "Test loss: 0.0092267538420856\n",
      "\n",
      "Epoch 90\n",
      "---------\n",
      "Train loss: 0.029033152024365134\n",
      "Test loss: 0.009239294566214085\n",
      "\n",
      "Epoch 91\n",
      "---------\n",
      "Train loss: 0.02499588334467262\n",
      "Test loss: 0.009242021245881915\n",
      "\n",
      "Epoch 92\n",
      "---------\n",
      "Train loss: 0.025363404924670856\n",
      "Test loss: 0.00925310468301177\n",
      "\n",
      "Epoch 93\n",
      "---------\n",
      "Train loss: 0.02722366914773981\n",
      "Test loss: 0.00927707552909851\n",
      "\n",
      "Epoch 94\n",
      "---------\n",
      "Train loss: 0.02502233710967832\n",
      "Test loss: 0.00928983697667718\n",
      "\n",
      "Epoch 95\n",
      "---------\n",
      "Train loss: 0.025546480849799182\n",
      "Test loss: 0.009304916020482779\n",
      "\n",
      "Epoch 96\n",
      "---------\n",
      "Train loss: 0.024802446210136015\n",
      "Test loss: 0.00932059739716351\n",
      "\n",
      "Epoch 97\n",
      "---------\n",
      "Train loss: 0.025643733330070972\n",
      "Test loss: 0.009333608439192176\n",
      "\n",
      "Epoch 98\n",
      "---------\n",
      "Train loss: 0.026430224482383993\n",
      "Test loss: 0.009340591030195355\n",
      "\n",
      "Epoch 99\n",
      "---------\n",
      "Train loss: 0.024895828631189134\n",
      "Test loss: 0.00935131753794849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Untrained test\\n--------\")\n",
    "test_model(test_loader, model, loss_function)\n",
    "print()\n",
    "\n",
    "for ix_epoch in range(100):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    test_model(test_loader, model, loss_function)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "af8d8d91-f045-4023-bcf3-f3e888ea2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7cdab3f3-4208-4e69-bc85-891799cd48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_final = train_data.copy()\n",
    "test_data_final = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a2e12470-150f-4d8b-a9a1-dfcfee238311",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_final['pred'] = predict(train_loader, model).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f9e5d91b-5d18-45e2-8f19-1f3d77b9af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_final['pred'] = predict(test_loader, model).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9a37fe28-16bc-4e94-ba9c-e318c6271cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ret</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341802</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.049192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346169</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.076202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350559</th>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.052103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354962</th>\n",
       "      <td>-0.106383</td>\n",
       "      <td>-0.054582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359356</th>\n",
       "      <td>-0.047619</td>\n",
       "      <td>0.024656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363768</th>\n",
       "      <td>-0.025000</td>\n",
       "      <td>-0.039809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368195</th>\n",
       "      <td>-0.025641</td>\n",
       "      <td>-0.088007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372635</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.040003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377143</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.024578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381798</th>\n",
       "      <td>-0.131579</td>\n",
       "      <td>0.011227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386448</th>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.037807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391093</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.042503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ret      pred\n",
       "341802  0.066667  0.049192\n",
       "346169  0.062500  0.076202\n",
       "350559  0.382353  0.052103\n",
       "354962 -0.106383 -0.054582\n",
       "359356 -0.047619  0.024656\n",
       "363768 -0.025000 -0.039809\n",
       "368195 -0.025641 -0.088007\n",
       "372635  0.000000 -0.040003\n",
       "377143  0.000000 -0.024578\n",
       "381798 -0.131579  0.011227\n",
       "386448 -0.090909 -0.037807\n",
       "391093  0.033333 -0.042503"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_final[[target, 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8d002e1e-2fa8-4613-acf9-3d4af6632f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11340566165809689"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(train_data_final[target], train_data_final['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9818e20e-376e-4dd9-8f67-7f7759b5421b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07491700457102062"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(test_data_final[target], test_data_final['pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e61a3e-9827-42dd-885c-00568ba09803",
   "metadata": {},
   "source": [
    "## QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3565bfc9-74ab-4ffc-a711-75e4f2462fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1140: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1145: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/zfs/projects/darc/wolee_edehaan_suzienoh-exploratory-ml/kevin/venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1165: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([84, 102])\n",
      "y_train shape: torch.Size([84])\n",
      "\n",
      "x_test shape: torch.Size([12, 102])\n",
      "y_test shape: torch.Size([12])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = SequenceDataset(train_data, test_data, deps, target, pipeline, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "483567ff-3f41-4ede-9645-2a14e8df82d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1187, -0.0967,  0.0000, -1.7844,  0.1356,  1.3458,  2.2846,  3.2693,\n",
       "           0.3142, -0.2635,  0.0000, -0.9551,  0.1306, -3.1040,  0.7440, -0.0222,\n",
       "          -0.0753, -0.0151,  0.0000,  0.0097,  0.0219,  0.0000, -0.2875,  0.0000,\n",
       "           0.0000, -2.4279, -2.1761,  0.0000, -0.7733,  0.0000,  0.0000, -0.0250,\n",
       "           1.0126,  0.0000, -0.0252,  0.1686,  0.1891,  1.2705,  0.0123,  0.4018,\n",
       "          -0.6628,  0.6060,  0.0885, -1.4486,  0.1700,  1.5489,  0.0231,  0.4091,\n",
       "          -0.1774, -0.0247,  0.0000, -0.5897,  2.0314,  0.0000,  0.0000, -0.1237,\n",
       "           0.1028,  0.1138, -0.1206, -0.0877, -0.1544, -0.0644, -0.0066, -0.0984,\n",
       "          -0.0579,  0.0137, -0.0554, -0.2955, -0.1715, -2.1826,  0.3529,  0.2666,\n",
       "           1.0377,  1.1406,  0.0000,  0.0000,  0.0000,  0.4648,  0.0000, -0.4367,\n",
       "          -1.0676,  1.1820, -0.1696,  0.0000,  0.0319, -1.0462,  0.7483, -0.0803,\n",
       "           0.0000,  0.0000,  0.0000, -0.8208,  0.2741, -0.4960,  1.3358,  0.0000,\n",
       "           0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.1187, -0.0967,  0.0000, -1.7844,  0.1356,  2.3424,  1.7974,  2.3200,\n",
       "           0.3142, -0.2635,  0.0000, -0.9551,  0.1306, -4.3382,  0.7440, -0.0222,\n",
       "          -0.0753, -0.0151,  0.0000,  0.0097,  0.5197,  0.0000, -0.2875,  0.0000,\n",
       "           0.0000, -2.4279, -2.1761,  0.0000, -0.7288,  0.0000,  0.0000, -0.0250,\n",
       "           1.0126,  0.0000, -0.0252,  0.1686,  0.1891,  1.2705,  0.0123,  0.8266,\n",
       "          -0.3499,  1.4885,  0.0885, -1.4486,  0.1700, -0.8526, -0.1014, -1.7232,\n",
       "           1.1141, -0.0550,  0.0000, -1.2319,  2.0314,  0.0000,  0.0000, -0.1237,\n",
       "           0.1028,  0.1138, -0.1206, -0.0877, -0.1544, -0.0644, -0.0066, -0.0984,\n",
       "          -0.0579,  0.0137, -0.0554, -0.5157, -0.1715, -2.1826,  0.3529,  0.2666,\n",
       "           1.0377,  0.3958,  0.0000,  0.0000,  0.0000,  0.4648,  0.0000, -0.4367,\n",
       "          -1.0676,  1.1820, -0.1696,  0.0000,  0.0319, -1.0462, -0.2147,  0.0238,\n",
       "           0.0000,  0.0000,  0.0000, -0.8208,  0.2741, -0.5481,  0.5120,  0.0000,\n",
       "           0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.1187, -0.0967,  0.0000, -1.7844,  0.1356,  2.5894,  1.7923,  2.3107,\n",
       "           0.3142, -0.2635,  0.0000, -0.9551,  0.1306, -4.0465,  0.7440, -0.0222,\n",
       "          -0.0753, -0.0151,  0.0000,  0.0097,  0.3031,  0.0000, -0.2875,  0.0000,\n",
       "           0.0000, -2.4279, -2.1761,  0.0000, -0.0254,  0.0000,  0.0000, -0.0250,\n",
       "           1.0126,  0.0000, -0.0252,  0.1686,  0.1891,  1.2705,  0.0123,  0.7965,\n",
       "           0.1096,  0.8604,  0.0885, -1.4486,  0.1700,  0.5883, -1.6047, -0.1566,\n",
       "          -0.0697, -0.7532,  0.0000, -1.2319,  2.0314,  0.0000,  0.0000, -0.1237,\n",
       "           0.1028,  0.1138, -0.1206, -0.0877, -0.1544, -0.0644, -0.0066, -0.0984,\n",
       "          -0.0579,  0.0137, -0.0554, -0.4405, -0.1715, -2.1826,  0.3529,  0.2666,\n",
       "           1.0377,  0.3686,  0.0000,  0.0000,  0.0000,  0.4648,  0.0000, -0.4367,\n",
       "          -1.0676,  1.1820, -0.1696,  0.0000,  0.0319, -1.0462, -0.3652, -0.0924,\n",
       "           0.0000,  0.0000,  0.0000, -0.8208,  0.2741, -0.1809, -1.1644,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7499,  0.6793,  0.0000, -1.2978, -0.8048,  2.2837,  1.3031,  1.4691,\n",
       "           1.0282,  1.0256,  0.0000, -1.4420, -1.4628, -1.1093,  0.3620,  0.0111,\n",
       "           1.0113, -2.2560,  0.0000,  0.0262,  1.4565,  0.0000, -0.7407,  0.0000,\n",
       "           0.0000, -0.3796,  1.4237,  0.0000,  0.6129,  0.0000,  0.0000, -1.4784,\n",
       "          -2.2394,  0.0000, -0.3324, -0.0843, -1.6917,  1.1095, -2.0936,  0.8902,\n",
       "           0.5162, -0.2518, -1.9973,  0.8968, -0.1511,  0.5883, -1.9026,  0.5222,\n",
       "          -0.4246,  0.0563,  0.0000, -0.9986,  0.7597,  0.0000,  0.0000, -0.8128,\n",
       "           1.0980, -1.3131,  1.5445,  2.1129, -0.4312,  1.3736, -0.1862, -1.6223,\n",
       "          -0.7674, -0.3479,  0.1157, -0.8231, -0.7717, -0.7289, -0.1765, -0.1333,\n",
       "          -0.5189, -0.0560,  0.0000,  0.0000,  0.0000, -0.4560,  0.0000,  1.3541,\n",
       "          -1.2003, -1.1821,  0.0848,  0.0000, -0.4491,  1.1873,  0.4574,  0.0934,\n",
       "           0.0000,  0.0000,  0.0000, -1.7919,  0.8007,  0.1524, -1.0726,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.7499,  0.6793,  0.0000, -1.2978, -0.8048,  2.2401,  1.3358,  1.5220,\n",
       "           1.2872,  1.1146,  0.0000, -1.4420, -1.4628, -1.1093,  0.3620,  0.0111,\n",
       "           1.0113, -2.2560,  0.0000,  0.0262,  1.8498,  0.0000, -0.7407,  0.0000,\n",
       "           0.0000, -0.3796,  1.4237,  0.0000,  0.6795,  0.0000,  0.0000, -1.4784,\n",
       "          -2.2394,  0.0000, -0.3324, -0.0843, -1.6917,  1.1095, -2.0936,  0.8942,\n",
       "          -0.0464, -0.1789, -1.9973,  0.8968, -0.1511, -0.8526, -1.5882, -0.1566,\n",
       "          -0.6114,  1.1136,  0.0000, -0.9986,  0.7597,  0.0000,  0.0000, -0.8128,\n",
       "           1.0980, -1.3131,  1.5445,  2.1129, -0.4312,  1.3736, -0.1862, -1.6223,\n",
       "          -0.7674, -0.3479,  0.1157, -0.8042, -0.7717, -0.7289, -0.1765, -0.1333,\n",
       "          -0.5189, -1.1598,  0.0000,  0.0000,  0.0000, -0.4560,  0.0000,  1.3541,\n",
       "          -1.2003, -1.1821,  0.0848,  0.0000, -0.4491,  1.1873,  0.6331,  0.5342,\n",
       "           0.0000,  0.0000,  0.0000, -1.7919,  0.8007,  0.6098, -0.7653,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor(-0.0909),\n",
       " tensor([[ 1.1275e+00,  9.1828e-01,  0.0000e+00,  1.6222e+00, -1.2881e+00,\n",
       "          -1.6754e-01, -1.0991e+00, -1.0546e+00, -1.3332e+00, -7.4956e-01,\n",
       "           0.0000e+00,  1.1152e-01, -7.9023e-02,  6.8575e-02,  4.0550e-01,\n",
       "           1.7753e-01,  7.1509e-01,  1.4308e-01,  0.0000e+00, -9.1869e-02,\n",
       "          -2.6257e-01,  0.0000e+00,  2.7314e+00,  0.0000e+00,  0.0000e+00,\n",
       "           2.6467e-01,  1.9252e+00,  0.0000e+00,  1.6154e+00,  0.0000e+00,\n",
       "           0.0000e+00,  2.3712e-01,  3.1988e-01,  0.0000e+00,  2.3906e-01,\n",
       "          -1.3486e+00, -1.7961e+00, -9.3573e-01, -1.1698e-01, -1.0256e+00,\n",
       "          -3.9921e-01, -6.5508e-01, -8.4083e-01, -1.9244e+00, -1.6151e+00,\n",
       "          -3.7231e-01, -4.8929e-01,  2.9592e-01, -2.9630e-01, -6.3937e-01,\n",
       "           0.0000e+00,  1.2805e+00, -5.2405e-01,  0.0000e+00,  0.0000e+00,\n",
       "           1.1749e+00, -9.7616e-01, -1.0815e+00,  1.1453e+00,  8.3344e-01,\n",
       "           1.4666e+00,  6.1219e-01,  6.3087e-02,  9.3486e-01,  5.5030e-01,\n",
       "          -1.3059e-01,  5.2652e-01,  2.2130e-01,  1.6292e+00, -2.7154e-01,\n",
       "          -2.2939e+00, -1.7329e+00, -2.0755e+00, -6.6074e-01,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.4074e+00,  0.0000e+00,  6.6529e-01,\n",
       "           6.8104e-01,  1.5015e+00,  1.1023e+00,  0.0000e+00, -3.0344e-01,\n",
       "          -8.8160e-01,  3.9486e-01,  2.3089e-01,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00, -1.0313e-01,  1.0415e+00, -1.3258e-04,  7.5311e-01,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00],\n",
       "         [ 1.1275e+00,  9.1828e-01,  0.0000e+00,  1.6222e+00, -1.2881e+00,\n",
       "          -8.0424e-01, -1.0354e+00, -1.0222e+00, -1.3332e+00, -7.4956e-01,\n",
       "           0.0000e+00,  1.1152e-01, -7.9023e-02,  6.8575e-02,  4.0550e-01,\n",
       "           1.7753e-01,  7.1509e-01,  1.4308e-01,  0.0000e+00, -9.1869e-02,\n",
       "          -2.8656e-01,  0.0000e+00,  2.7314e+00,  0.0000e+00,  0.0000e+00,\n",
       "           2.6467e-01,  1.9252e+00,  0.0000e+00,  2.2417e-01,  0.0000e+00,\n",
       "           0.0000e+00,  2.3712e-01,  3.1988e-01,  0.0000e+00,  2.3906e-01,\n",
       "          -1.3486e+00, -1.7961e+00, -9.3573e-01, -1.1698e-01, -1.0563e+00,\n",
       "          -6.9757e-01, -6.1474e-01, -8.4083e-01, -1.9244e+00, -1.6151e+00,\n",
       "          -4.0233e-01, -1.4607e-01,  2.6763e-01, -4.2892e-01, -4.5058e-01,\n",
       "           0.0000e+00,  1.4289e+00, -5.2405e-01,  0.0000e+00,  0.0000e+00,\n",
       "           1.1749e+00, -9.7616e-01, -1.0815e+00,  1.1453e+00,  8.3344e-01,\n",
       "           1.4666e+00,  6.1219e-01,  6.3087e-02,  9.3486e-01,  5.5030e-01,\n",
       "          -1.3059e-01,  5.2652e-01,  5.2460e-01,  1.6292e+00, -2.7154e-01,\n",
       "          -2.2939e+00, -1.7329e+00, -2.0755e+00, -6.6888e-01,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.4074e+00,  0.0000e+00,  6.6529e-01,\n",
       "           6.8104e-01,  1.5015e+00,  1.1023e+00,  0.0000e+00, -3.0344e-01,\n",
       "          -8.8160e-01, -1.8460e-01, -5.8429e-01,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00, -1.0313e-01,  1.0415e+00,  2.5909e-01, -1.5087e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00],\n",
       "         [ 1.1275e+00,  9.1828e-01,  0.0000e+00,  1.6222e+00, -1.2881e+00,\n",
       "          -1.0685e+00, -9.9843e-01, -1.0025e+00, -1.3332e+00, -7.4956e-01,\n",
       "           0.0000e+00,  1.1152e-01, -7.9023e-02,  6.8575e-02,  4.0550e-01,\n",
       "           1.7753e-01,  7.1509e-01,  1.4308e-01,  0.0000e+00, -9.1869e-02,\n",
       "           7.2956e-01,  0.0000e+00,  2.7314e+00,  0.0000e+00,  0.0000e+00,\n",
       "           2.6467e-01,  1.9252e+00,  0.0000e+00,  6.7822e-01,  0.0000e+00,\n",
       "           0.0000e+00,  2.3712e-01,  3.1988e-01,  0.0000e+00,  2.3906e-01,\n",
       "          -1.3486e+00, -1.7961e+00, -9.3573e-01, -1.1698e-01, -1.0498e+00,\n",
       "          -1.9944e-01, -4.6236e-01, -8.4083e-01, -1.9244e+00, -1.6151e+00,\n",
       "           1.6902e+00, -4.0056e-01,  2.4389e+00, -2.6747e-01, -3.2913e-01,\n",
       "           0.0000e+00,  2.2214e+00, -5.2405e-01,  0.0000e+00,  0.0000e+00,\n",
       "           1.1749e+00, -9.7616e-01, -1.0815e+00,  1.1453e+00,  8.3344e-01,\n",
       "           1.4666e+00,  6.1219e-01,  6.3087e-02,  9.3486e-01,  5.5030e-01,\n",
       "          -1.3059e-01,  5.2652e-01,  5.0903e-01,  1.6292e+00, -2.7154e-01,\n",
       "          -2.2939e+00, -1.7329e+00, -2.0755e+00,  1.3362e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.4074e+00,  0.0000e+00,  6.6529e-01,\n",
       "           6.8104e-01,  1.5015e+00,  1.1023e+00,  0.0000e+00, -3.0344e-01,\n",
       "          -8.8160e-01, -1.0430e-01,  1.7661e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00, -1.0313e-01,  1.0415e+00,  5.8312e-01, -5.1082e-01,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00],\n",
       "         [-7.7898e-01, -2.8820e-01,  0.0000e+00,  2.1089e+00,  1.8674e-01,\n",
       "          -9.0374e-01, -7.5130e-01, -8.5469e-01, -1.9747e+00, -1.6214e+00,\n",
       "           0.0000e+00,  7.6143e-02,  3.9857e-01,  3.6998e-01,  4.0438e-01,\n",
       "          -5.4538e-01,  7.1509e-01, -1.1583e-01,  0.0000e+00, -6.1525e-01,\n",
       "           8.0171e-01,  0.0000e+00, -5.2432e-01,  0.0000e+00,  0.0000e+00,\n",
       "          -5.3072e-01,  1.1604e+00,  0.0000e+00,  2.5781e+00,  0.0000e+00,\n",
       "           0.0000e+00, -7.1968e-02, -2.9515e-02,  0.0000e+00,  8.6409e-02,\n",
       "          -3.7120e-01,  5.5882e-01, -8.4538e-01, -1.1365e-01, -7.6453e-01,\n",
       "           2.3261e-01, -1.9095e-01,  1.3281e-01, -2.1055e+00,  2.2561e-01,\n",
       "          -5.0118e-01,  3.6920e-01, -8.7879e-01,  5.2099e-01,  1.3988e+00,\n",
       "           0.0000e+00,  1.9461e+00, -7.6393e-01,  0.0000e+00,  0.0000e+00,\n",
       "           1.2900e-01, -7.3140e-01,  2.8559e+00, -8.2366e-01, -7.0525e-01,\n",
       "          -4.8368e-01, -3.1927e-01,  2.1665e-01, -1.3962e+00, -1.0295e+00,\n",
       "           3.6401e-02,  2.1090e-01,  5.3053e-01, -1.3720e+00, -1.9794e-01,\n",
       "          -2.3064e+00, -1.0309e+00,  3.7404e+00, -4.4934e-01,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00, -2.6243e-02,  0.0000e+00, -9.6366e-02,\n",
       "           1.2174e+00, -7.5924e-01,  1.1483e+00,  0.0000e+00, -8.0326e-01,\n",
       "          -1.9130e+00,  1.2792e+00, -2.8416e-01,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  6.1315e-01,  3.9063e-01,  8.6002e-01, -6.9138e-01,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00],\n",
       "         [-7.7898e-01, -2.8820e-01,  0.0000e+00,  2.1089e+00,  1.8674e-01,\n",
       "          -1.1849e+00, -6.4511e-01, -7.8248e-01, -1.9747e+00, -1.6214e+00,\n",
       "           0.0000e+00,  7.6143e-02,  3.9857e-01,  3.6998e-01,  4.0438e-01,\n",
       "          -5.4538e-01,  7.1509e-01, -1.1583e-01,  0.0000e+00, -6.1525e-01,\n",
       "           7.2153e-01,  0.0000e+00, -5.2432e-01,  0.0000e+00,  0.0000e+00,\n",
       "          -5.3072e-01,  1.1604e+00,  0.0000e+00,  1.2852e+00,  0.0000e+00,\n",
       "           0.0000e+00, -7.1968e-02, -2.9515e-02,  0.0000e+00,  8.6409e-02,\n",
       "          -3.7120e-01,  5.5882e-01, -8.4538e-01, -1.1365e-01, -7.5862e-01,\n",
       "           4.6843e-01, -1.4485e-01,  1.3281e-01, -2.1055e+00,  2.2561e-01,\n",
       "          -5.0118e-01, -1.7052e-01, -4.7988e-01,  1.1421e+00,  7.8231e-01,\n",
       "           0.0000e+00,  1.8266e+00, -7.6393e-01,  0.0000e+00,  0.0000e+00,\n",
       "           1.2900e-01, -7.3140e-01,  2.8559e+00, -8.2366e-01, -7.0525e-01,\n",
       "          -4.8368e-01, -3.1927e-01,  2.1665e-01, -1.3962e+00, -1.0295e+00,\n",
       "           3.6401e-02,  2.1090e-01,  5.0707e-01, -1.3720e+00, -1.9794e-01,\n",
       "          -2.3064e+00, -1.0309e+00,  3.7404e+00, -6.1425e-01,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00, -2.6243e-02,  0.0000e+00, -9.6366e-02,\n",
       "           1.2174e+00, -7.5924e-01,  1.1483e+00,  0.0000e+00, -8.0326e-01,\n",
       "          -1.9130e+00, -7.7758e-01, -8.0737e-01,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  6.1315e-01,  3.9063e-01,  5.0064e-01,  1.7643e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00]]),\n",
       " tensor(-0.0250))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8333a5-4bb6-4f20-8391-c34ad030027b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wolee_edehaan_suzienoh_exploratory-ml",
   "language": "python",
   "name": "wolee_edehaan_suzienoh_exploratory-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
